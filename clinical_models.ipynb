{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, pickle, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import plot_roc_curves, plot_pr_curves, plot_calibration_curves, plot_alert_rate, plot_confusion_matrix, evaluate_all_outcomes, evaluate_multiple, plot_calibrated_regression_coefficients, confusion_matrix_multiplot, plot_shap_features_joint\n",
    "from hyperparameter_tuning import tune_lgbm, tune_logisticregression\n",
    "from utils.data_profiling import ensure_categorical_overlap, drop_exclusive_cols\n",
    "from dataset import SCIData, SCICols\n",
    "%aimport utils.evaluation, hyperparameter_tuning, dataset, utils.data_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    IMAGE_DIR = \"images/clinical_models_auc\"\n",
    "    SAVE_IMAGES = True\n",
    "\n",
    "    RUN_HYPERPARAMETERS = True\n",
    "    HYPERPARAMETER_TIMEOUT = 60 * 30\n",
    "    HYPERPARAMETER_TRIALS = 1000\n",
    "    HYPERPARAMETER_NJOBS = 16\n",
    "    HYPERPARAMETER_SCORE = 'roc_auc'\n",
    "\n",
    "    SHAP_PLOTS_MAXDISPLAY = 20\n",
    "    EVAL_N_RESAMPLES = 999\n",
    "\n",
    "    MODELS = {}\n",
    "    EXPLAINERS = {}\n",
    "    Y_PREDS = {}\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(Notebook.IMAGE_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sci = (\n",
    "    SCIData(SCIData.quickload(\"data/sci_processed.h5\").sort_values(\"AdmissionDateTime\"))\n",
    "    .mandate(SCICols.news_data_raw)\n",
    "    .omit_ae()\n",
    ")\n",
    "\n",
    "scii = (\n",
    "    sci.derive_critical_event(within=1, return_subcols=True)\n",
    "    .augment_shmi(onehot=True)\n",
    "    .omit_redundant()\n",
    "    .raw_news()\n",
    "    .categorize()\n",
    "    .onehot_encode_categories()\n",
    ")\n",
    "\n",
    "sci_train, sci_test, _, y_test_mortality, _, y_test_criticalcare = train_test_split(\n",
    "    scii.drop([\"DiedWithinThreshold\", \"CriticalCare\"], axis=1),\n",
    "    scii.DiedWithinThreshold,\n",
    "    scii.CriticalCare,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "\n",
    "test_set_n_days = (\n",
    "    sci.loc[sci_test.index].AdmissionDateTime.max() - sci.loc[sci_test.index].AdmissionDateTime.min()\n",
    ").days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_lr, y_train), (X_test_lr, y_test) = (\n",
    "    sci_train.impute_blood().xy(outcome=\"CriticalEvent\", dropna=False, fillna=True),\n",
    "    sci_test.impute_blood().xy(outcome=\"CriticalEvent\", dropna=False, fillna=True)\n",
    ")\n",
    "\n",
    "(X_train_lgbm, y_train), (X_test_lgbm, y_test) = (\n",
    "    sci_train.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "    sci_test.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False)\n",
    ")\n",
    "\n",
    "(X_train_news, _), (X_test_news, _) = (\n",
    "    sci_train#.impute_news().impute_blood()\n",
    "    .xy(\n",
    "        outcome=\"CriticalEvent\",\n",
    "        x=SCICols.news_data_raw,\n",
    "        dtype=float,\n",
    "        dropna=False,\n",
    "        fillna=False,\n",
    "    ),\n",
    "    sci_test#.impute_news().impute_blood()\n",
    "    .xy(\n",
    "        outcome=\"CriticalEvent\",\n",
    "        x=SCICols.news_data_raw,\n",
    "        dtype=float,\n",
    "        dropna=False,\n",
    "        fillna=False,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "def get_threshold(y_train, y_pred_proba, target=0.85):\n",
    "    \"\"\" Given prediction probabilities, sets the prediction threshold to approach the given target recall\n",
    "    \"\"\"\n",
    "\n",
    "    # Get candidate thresholds from the model, and find the one that gives the best fbeta score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "    closest = thresholds[np.abs(recall - target).argmin()]\n",
    "\n",
    "    return closest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(y_pred, y_pred_proba, modelkey, filekey, tuning=False):\n",
    "    evaluate_all_outcomes(\n",
    "        y_test,\n",
    "        y_test_mortality,\n",
    "        y_test_criticalcare,\n",
    "        y_pred,\n",
    "        y_pred_proba,\n",
    "        modelkey,\n",
    "        n_resamples=Notebook.EVAL_N_RESAMPLES,\n",
    "        save=f\"{Notebook.IMAGE_DIR}/eval_{filekey}.png\"\n",
    "        if Notebook.SAVE_IMAGES\n",
    "        else None,\n",
    "    )\n",
    "    plot_confusion_matrix(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        plot_title=modelkey,\n",
    "        save=f\"{Notebook.IMAGE_DIR}/matrix_{filekey}.png\"\n",
    "        if Notebook.SAVE_IMAGES\n",
    "        else None,\n",
    "    )\n",
    "\n",
    "    if not tuning:\n",
    "        Notebook.Y_PREDS[modelkey] = (y_pred, y_pred_proba)\n",
    "    else:\n",
    "        modelkey = f\"{modelkey} (tuned)\"\n",
    "        y_pred = np.where(y_pred_proba > get_threshold(y_test, y_pred_proba), 1, 0)\n",
    "        evaluate_all_outcomes(\n",
    "            y_test,\n",
    "            y_test_mortality,\n",
    "            y_test_criticalcare,\n",
    "            y_pred,\n",
    "            y_pred_proba,\n",
    "            modelkey,\n",
    "            n_resamples=Notebook.EVAL_N_RESAMPLES,\n",
    "            save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_{filekey}.png\"\n",
    "            if Notebook.SAVE_IMAGES\n",
    "            else None,\n",
    "        )\n",
    "        plot_confusion_matrix(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            plot_title=modelkey,\n",
    "            save=f\"{Notebook.IMAGE_DIR}/matrix_thresholded_{filekey}.png\"\n",
    "            if Notebook.SAVE_IMAGES\n",
    "            else None,\n",
    "        )\n",
    "        Notebook.Y_PREDS[modelkey] = (y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline (NEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    (sci.loc[sci_test.index].NEWS_score >= 7).to_numpy(),\n",
    "    sci.loc[sci_test.index].NEWS_score.to_numpy(),\n",
    "    \"Baseline (NEWS)\",\n",
    "    \"news\",\n",
    "    tuning=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (NEWS only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "lr_news_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 42,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'saga',\n",
    "    'C': 7.85,\n",
    "    'class_weight': 'balanced',\n",
    "}\n",
    "\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    lr_news_params.update(\n",
    "        tune_logisticregression(\n",
    "            X_train_news,\n",
    "            y_train,\n",
    "            timeout=Notebook.HYPERPARAMETER_TIMEOUT,\n",
    "            n_jobs=Notebook.HYPERPARAMETER_NJOBS,\n",
    "            n_trials=Notebook.HYPERPARAMETER_TRIALS,\n",
    "            score=Notebook.HYPERPARAMETER_SCORE\n",
    "        )\n",
    "    )\n",
    "\n",
    "modelkey = \"NEWS Logistic Regression\"\n",
    "model = (\n",
    "    CalibratedClassifierCV(\n",
    "        LogisticRegression().set_params(**lr_news_params), cv=5, method='isotonic', n_jobs=Notebook.HYPERPARAMETER_NJOBS\n",
    "    ).fit(X_train_news, y_train)\n",
    ")\n",
    "Notebook.MODELS[modelkey] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    model.predict(X_test_news),\n",
    "    model.predict_proba(X_test_news)[:, 1],\n",
    "    modelkey,\n",
    "    \"news_regression\",\n",
    "    tuning=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibrated_regression_coefficients(model, X_train_news.columns, topn=10, figsize=(8,4), save = f'{Notebook.IMAGE_DIR}/logistic_regression_coef.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers = [\n",
    "    shap.LinearExplainer(\n",
    "        _.base_estimator, X_train_news, feature_perturbation='correlation_dependent'\n",
    "    )(X_test_news)\n",
    "    for _ in model.calibrated_classifiers_\n",
    "]\n",
    "shap_values = shap.Explanation(\n",
    "    base_values = np.array([_.base_values for _ in explainers]).mean(axis=0),\n",
    "    values = np.array([_.values for _ in explainers]).mean(axis=0),\n",
    "    data = explainers[0].data,\n",
    "    feature_names = X_train_news.columns\n",
    ")\n",
    "Notebook.EXPLAINERS[modelkey] = shap_values\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False, color=plt.get_cmap('coolwarm')\n",
    ")\n",
    "plt.title(\"NEWS Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_news_regression.png\", bbox_inches=\"tight\", dpi=200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"NEWS Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_news_regression.png\", bbox_inches=\"tight\", dpi=200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_features_joint(\n",
    "    shap_values, \n",
    "    modelkey, \n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    figsize=(16,5),\n",
    "    wspace=-0.2,\n",
    "    save = f'{Notebook.IMAGE_DIR}/shap_features_news_regression.png' if Notebook.SAVE_IMAGES else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.calibration import CalibrationDisplay, CalibratedClassifierCV\n",
    "\n",
    "lr_params = {\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 42,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'saga',\n",
    "    'C': 9.16316,\n",
    "    'class_weight': 'balanced',\n",
    "}\n",
    "\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    lr_params.update(\n",
    "        tune_logisticregression(\n",
    "            X_train_lr,\n",
    "            y_train,\n",
    "            timeout=Notebook.HYPERPARAMETER_TIMEOUT,\n",
    "            n_jobs=Notebook.HYPERPARAMETER_NJOBS,\n",
    "            n_trials=Notebook.HYPERPARAMETER_TRIALS,\n",
    "            score=Notebook.HYPERPARAMETER_SCORE\n",
    "        )\n",
    "    )\n",
    "\n",
    "modelkey = \"Logistic Regression\"\n",
    "model = (\n",
    "    CalibratedClassifierCV(\n",
    "        LogisticRegression().set_params(**lr_params), cv=5, method='isotonic', n_jobs=Notebook.HYPERPARAMETER_NJOBS\n",
    "    ).fit(X_train_lr, y_train)\n",
    ")\n",
    "Notebook.MODELS[modelkey] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibrated_regression_coefficients(model, X_train_lr.columns, save = f'{Notebook.IMAGE_DIR}/logistic_regression_coef.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    model.predict(X_test_lr),\n",
    "    model.predict_proba(X_test_lr)[:, 1],\n",
    "    modelkey,\n",
    "    \"logistic_regression\",\n",
    "    tuning=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers = [\n",
    "    shap.LinearExplainer(\n",
    "        _.base_estimator, X_train_lr, feature_perturbation='correlation_dependent'\n",
    "    )(X_test_lr)\n",
    "    for _ in model.calibrated_classifiers_\n",
    "]\n",
    "shap_values = shap.Explanation(\n",
    "    base_values = np.array([_.base_values for _ in explainers]).mean(axis=0),\n",
    "    values = np.array([_.values for _ in explainers]).mean(axis=0),\n",
    "    data = explainers[0].data,\n",
    "    feature_names = X_train_lr.columns\n",
    ")\n",
    "Notebook.EXPLAINERS[modelkey] = shap_values\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False, color=plt.get_cmap('coolwarm')\n",
    ")\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_logistic_regression.png\", bbox_inches=\"tight\", dpi=200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_logsitic_regression.png\", bbox_inches=\"tight\", dpi=200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_features_joint(\n",
    "    shap_values, \n",
    "    modelkey, \n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    figsize=(16,8),\n",
    "    wspace=-0.3,\n",
    "    save = f'{Notebook.IMAGE_DIR}/shap_features_logistic_regression.png' if Notebook.SAVE_IMAGES else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "lgbm_params = {\n",
    "    'LGBM__objective': 'binary',\n",
    "    'LGBM__verbose_eval': -1,\n",
    "    'LGBM__random_state': 42,\n",
    "    'LGBM__metrics': ['l2', 'auc'],\n",
    "    'LGBM__boosting_type': 'gbdt',\n",
    "    'LGBM__is_unbalance': True,\n",
    "    'LGBM__n_jobs': 1,\n",
    "    'LGBM__feature_pre_filter': False,\n",
    "    'LGBM__lambda_l1': 0.996,\n",
    "    'LGBM__lambda_l2': 0.013,\n",
    "    'LGBM__num_leaves': 6,\n",
    "    'LGBM__feature_fraction': 0.726,\n",
    "    'LGBM__bagging_fraction': 0.701,\n",
    "    'LGBM__bagging_freq': 4,\n",
    "    'LGBM__min_child_samples': 16,\n",
    "    'IMB__sampling_strategy': 0.11\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    lgbm_params.update(\n",
    "        tune_lgbm(\n",
    "            X_train_lr,\n",
    "            y_train,\n",
    "            None,\n",
    "            timeout=Notebook.HYPERPARAMETER_TIMEOUT,\n",
    "            n_jobs=Notebook.HYPERPARAMETER_NJOBS,\n",
    "            n_trials=Notebook.HYPERPARAMETER_TRIALS,\n",
    "            score=Notebook.HYPERPARAMETER_SCORE\n",
    "        )\n",
    "    )\n",
    "\n",
    "modelkey = \"LightGBM\"\n",
    "model = (\n",
    "    CalibratedClassifierCV(\n",
    "        ImbPipeline(\n",
    "            steps=[\n",
    "                (\"IMB\", RandomUnderSampler()), \n",
    "                (\"LGBM\", LGBMClassifier())\n",
    "            ]\n",
    "        ).set_params(**lgbm_params),\n",
    "        cv=5,\n",
    "        method='isotonic',\n",
    "        n_jobs=Notebook.HYPERPARAMETER_NJOBS\n",
    "    ).fit(\n",
    "        X_train_lgbm,\n",
    "        y_train\n",
    "    )\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    model.predict(X_test_lgbm),\n",
    "    model.predict_proba(X_test_lgbm)[:, 1],\n",
    "    modelkey,\n",
    "    \"lightgbm\",\n",
    "    tuning=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers = [\n",
    "    shap.TreeExplainer(_.base_estimator['LGBM'])(X_test_lgbm)\n",
    "    for _ in model.calibrated_classifiers_\n",
    "]\n",
    "shap_values = shap.Explanation(\n",
    "    base_values = np.array([_.base_values for _ in explainers]).mean(axis=0),\n",
    "    values = np.array([_.values for _ in explainers]).mean(axis=0),\n",
    "    data = explainers[0].data,\n",
    "    feature_names = X_train_lgbm.columns\n",
    ")\n",
    "Notebook.EXPLAINERS[modelkey] = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_features_joint(\n",
    "    shap_values[:, :, 1], \n",
    "    modelkey, \n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    figsize=(16,8),\n",
    "    wspace=-0.225,\n",
    "    save = f'{Notebook.IMAGE_DIR}/shap_features_lightgbm.png' if Notebook.SAVE_IMAGES else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.beeswarm(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False, color=plt.get_cmap('coolwarm')\n",
    ")\n",
    "plt.title(\"LightGBM\")\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_lightgbm.png\", bbox_inches=\"tight\", dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"LightGBM\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_lightgbm.png\", bbox_inches=\"tight\", dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notebook.Y_PREDS = dict(reversed(Notebook.Y_PREDS.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import evaluate_multiple\n",
    "\n",
    "evaluate_multiple(\n",
    "    y_test,\n",
    "    Notebook.Y_PREDS,\n",
    "    news_modelkey=\"Baseline (NEWS)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/combined_curves.png\" if Notebook.SAVE_IMAGES else None,\n",
    "    n_resamples=Notebook.EVAL_N_RESAMPLES,\n",
    "    alert_rate_n_days = test_set_n_days,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_multiplot(y_test, dict(reversed(Notebook.Y_PREDS.items())), save=f'{Notebook.IMAGE_DIR}/combined_matrices.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(y_test, Notebook.Y_PREDS, baseline_key='Baseline (NEWS)', save=f'{Notebook.IMAGE_DIR}/combined_roc.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curves(y_test, Notebook.Y_PREDS, baseline_key='Baseline (NEWS)', save=f'{Notebook.IMAGE_DIR}/combined_pr.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curves(y_test, Notebook.Y_PREDS, save=f'{Notebook.IMAGE_DIR}/combined_calibration.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alert_rate(y_test, Notebook.Y_PREDS, test_set_n_days, baseline_key='Baseline (NEWS)', save=f'{Notebook.IMAGE_DIR}/combined_alert_rate.png' if Notebook.SAVE_IMAGES else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_force_plots(patient):\n",
    "    patient_data = X_test_lr.loc[patient].apply(\n",
    "        lambda x: f\"{x:.2f}\" if type(x) == np.float64 else x\n",
    "    )\n",
    "    patient_idx = X_test_lr.index.get_loc(patient)\n",
    "\n",
    "    explanations = {\n",
    "        modelkey: shap_values[patient_idx]\n",
    "        for modelkey, shap_values in Notebook.EXPLAINERS.items()\n",
    "        if not modelkey in [\"Baseline (NEWS)\"]\n",
    "    }\n",
    "    for _ in explanations.keys():\n",
    "        if len(explanations[_].shape) > 1:\n",
    "            explanations[_] = explanations[_][:, 1]\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.rc(\"axes\", titlesize=16)\n",
    "    for modelkey, explanation in explanations.items():\n",
    "        patient_to_use = patient_data if modelkey != \"NEWS Logistic Regression\" else patient_data[SCICols.news_data_raw]\n",
    "\n",
    "        explanation = shap.Explanation(explanation)\n",
    "        explanation.data = patient_to_use.values\n",
    "\n",
    "        fig = shap.plots.force(\n",
    "            explanation,\n",
    "            feature_names=patient_to_use.index,\n",
    "            matplotlib=True,\n",
    "            contribution_threshold=0.08,\n",
    "            show=False,\n",
    "            text_rotation=15,\n",
    "        )\n",
    "\n",
    "        plt.title(modelkey)\n",
    "        display(fig)\n",
    "\n",
    "        if Notebook.SAVE_IMAGES:\n",
    "            plt.savefig(\n",
    "                f\"{Notebook.IMAGE_DIR}/comaprison_force_plot_{modelkey.replace(' ','')}.png\",\n",
    "                bbox_inches=\"tight\", dpi=200\n",
    "            )\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "    sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame({key:val[0] for key, val in Notebook.Y_PREDS.items()}).astype(bool).set_index(y_test.index)\n",
    "candidate_mask = (\n",
    "    preds_df['LightGBM (tuned)'] & \n",
    "    ~preds_df['Baseline (NEWS)'] & \n",
    "    y_test.astype(bool) &\n",
    "    (X_test_lr.AssistedBreathing == 0)\n",
    ")\n",
    "candidates = preds_df[candidate_mask].index\n",
    "\n",
    "patient_force_plots(55599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def patient_decision_plots(patient):\n",
    "#     patient_data = X_test_lr.loc[patient].apply(\n",
    "#         lambda x: f\"{x:.2f}\" if type(x) == np.float64 else x\n",
    "#     )\n",
    "#     patient_idx = X_test_lr.index.get_loc(patient)\n",
    "\n",
    "#     explanations = {\n",
    "#         modelkey: shap_values[patient_idx]\n",
    "#         for modelkey, shap_values in Notebook.EXPLAINERS.items()\n",
    "#         if not modelkey in [\"Baseline (NEWS)\"]\n",
    "#     }\n",
    "#     for _ in explanations.keys():\n",
    "#         if len(explanations[_].shape) > 1:\n",
    "#             explanations[_] = explanations[_][:, 1]\n",
    "\n",
    "#     sns.set_style(\"white\")\n",
    "#     plt.rc(\"axes\", titlesize=16)\n",
    "#     for modelkey, explanation in explanations.items():\n",
    "#         patient_to_use = patient_data if modelkey != \"NEWS Logistic Regression\" else patient_data[SCICols.news_data_raw]\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         shap.decision_plot(explanation.base_values, explanation.values, explanation.data, explanation.feature_names, show=False)\n",
    "#         plt.title(modelkey)\n",
    "        \n",
    "#         if Notebook.SAVE_IMAGES:\n",
    "#             plt.savefig(\n",
    "#                 f\"{Notebook.IMAGE_DIR}/comaprison_force_plot_{modelkey.replace(' ','')}.png\",\n",
    "#                 bbox_inches=\"tight\", dpi=200\n",
    "#             )\n",
    "\n",
    "#         #plt.clf()\n",
    "\n",
    "# patient_decision_plots(55599)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
