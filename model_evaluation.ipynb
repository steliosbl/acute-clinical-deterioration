{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP Project - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, pickle, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import f2_score, METRICS, evaluate, evaluate_from_pred, with_sampling_strategies, spotCheckCV, spotCheckDatasets, F2TabNet, joint_plot\n",
    "from utils.isolation_forest_wrapper import IsolationForestWrapper\n",
    "%aimport utils.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparameter_tuning import tune_xgboost, tune_tabnet, tune_lgbm, tune_randomforest, tune_isolationforest, tune_logisticregression\n",
    "%aimport hyperparameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    IMAGE_DIR = \"images/critical_event_48\"\n",
    "    MODEL_DIR = \"models/critical_event_48\"\n",
    "    OUTCOME_WITHIN = 2\n",
    "\n",
    "    SAVE_MODELS = True\n",
    "    SAVE_IMAGES = True\n",
    "    RUN_HYPERPARAMETERS = True\n",
    "    HYPERPARAMETER_TIMEOUT = 60 * 60\n",
    "    SHAP_PLOTS_MAXDISPLAY = 20\n",
    "\n",
    "    MODELS = {}\n",
    "    EXPLAINERS = {}\n",
    "    EVAL_RESULTS = {}\n",
    "    TUNED_RESULTS = {}\n",
    "    MORTALITY_RESULTS = {}\n",
    "    CRITICALCARE_RESULTS = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(Notebook.IMAGE_DIR)\n",
    "    os.makedirs(Notebook.MODEL_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore():\n",
    "    with open(f\"{Notebook.MODEL_DIR}/models.bin\", \"rb\") as file:\n",
    "        Notebook.MODELS = pickle.load(file)\n",
    "\n",
    "    with open(f\"{Notebook.MODEL_DIR}/explainers.bin\", \"rb\") as file:\n",
    "        Notebook.EXPLAINERS = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "\n",
    "sci = (\n",
    "    SCIData.load('data/sci_processed.h5')\n",
    "    .fix_readmissionband()\n",
    "    .derive_critical_event(within=Notebook.OUTCOME_WITHIN, return_subcols=True)\n",
    ")\n",
    "Notebook.OUTCOME = 'CriticalEvent'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_exclusive_cols(X1, X2):\n",
    "    exclusive_cols = set(X1.columns) ^ set(X2.columns)\n",
    "    X1.drop(exclusive_cols, axis=1, errors=\"ignore\", inplace=True)\n",
    "    X2.drop(exclusive_cols, axis=1, errors=\"ignore\", inplace=True)\n",
    "\n",
    "\n",
    "def ensure_categorical_overlap(X1, X2, cols_to_check):\n",
    "    for col in cols_to_check:\n",
    "        col = X1.columns[col]\n",
    "        X1_uniq, X2_uniq = X1[col].unique(), X2[col].unique()\n",
    "        to_remove = list(set(X1_uniq) ^ set(X2_uniq))\n",
    "        repl = list(set(X1_uniq) & set(X2_uniq))[0]\n",
    "        X1.loc[X1[col].isin(to_remove), col] = repl\n",
    "        X2.loc[X2[col].isin(to_remove), col] = repl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scii = (\n",
    "    sci.omit_redundant()\n",
    "    .drop([\"ReadmissionBand\", \"AgeBand\", \"LastSpecialty\"], axis=1)\n",
    "    .omit_ae()\n",
    "    .raw_news()\n",
    "    .mandate_news()\n",
    "    .mandate_blood()\n",
    "    .augment_hsmr()\n",
    ")\n",
    "\n",
    "sci_train, sci_test = train_test_split(\n",
    "    scii, test_size=0.33, random_state=42, stratify=scii[Notebook.OUTCOME]\n",
    ")\n",
    "y_test_mortality, y_test_criticalcare = (\n",
    "    sci_test.DiedWithinThreshold.copy(),\n",
    "    sci_test.CriticalCare.copy(),\n",
    ")\n",
    "\n",
    "if Notebook.OUTCOME == \"CriticalEvent\":\n",
    "    sci_train, sci_test = (\n",
    "        sci_train.drop(\n",
    "            [\"DiedWithinThreshold\", \"CriticalCare\"], axis=1, errors=\"ignore\"\n",
    "        ),\n",
    "        sci_test.drop([\"DiedWithinThreshold\", \"CriticalCare\"], axis=1, errors=\"ignore\"),\n",
    "    )\n",
    "\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "\n",
    "# Drop HSMR_15 as there is only 1 in the entire dataset, making a split impossible\n",
    "(X_train, y_train), (X_test, y_test) = (\n",
    "    sci_train.encode_ccs_onehot().xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, dropna=False, fillna=True\n",
    "    ),\n",
    "    sci_test.encode_ccs_onehot().xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, dropna=False, fillna=True\n",
    "    ),\n",
    ")\n",
    "categorical_cols_idx, categorical_cols_dims = X_train.describe_categories()\n",
    "drop_exclusive_cols(X_train, X_test)\n",
    "ensure_categorical_overlap(X_train, X_test, categorical_cols_idx)\n",
    "\n",
    "# Mandated vitals, Categorical diagnoses (main only)\n",
    "(X_train_if, y_train_if), (X_test_if, y_test_if) = (\n",
    "    sci_train.drop(SCICols.diagnoses[1:], axis=1).xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, fillna=True\n",
    "    ),\n",
    "    sci_test.drop(SCICols.diagnoses[1:], axis=1).xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, fillna=True\n",
    "    ),\n",
    ")\n",
    "drop_exclusive_cols(X_train_if, X_test_if)\n",
    "\n",
    "(X_train_lgbm, y_train_lgbm), (X_test_lgbm, y_test_lgbm) = (\n",
    "    sci_train.encode_ccs_onehot().xy(outcome=Notebook.OUTCOME, fillna=True),\n",
    "    sci_test.encode_ccs_onehot().xy(outcome=Notebook.OUTCOME, fillna=True),\n",
    ")\n",
    "drop_exclusive_cols(X_train_lgbm, X_test_lgbm)\n",
    "ensure_categorical_overlap(X_train_lgbm, X_test_lgbm, categorical_cols_idx)\n",
    "\n",
    "(X_train_tn, X_valid_tn, y_train_tn, y_valid_tn) = train_test_split(\n",
    "    X_train.to_numpy(),\n",
    "    y_train.to_numpy(),\n",
    "    stratify=y_train,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "(X_train_news, y_train_news), (X_test_news, y_test_news) = (\n",
    "    sci_train.xy(\n",
    "        outcome=Notebook.OUTCOME, x=SCICols.news_data_raw, dtype=float, fillna=True\n",
    "    ),\n",
    "    sci_test.xy(\n",
    "        outcome=Notebook.OUTCOME, x=SCICols.news_data_raw, dtype=float, fillna=True\n",
    "    ),\n",
    ")\n",
    "drop_exclusive_cols(X_train_news, X_test_news)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "def get_threshold(y_train, y_pred_proba, target=0.85):\n",
    "    \"\"\" Given prediction probabilities, sets the prediction threshold to approach the given target recall\n",
    "    \"\"\"\n",
    "\n",
    "    # Get candidate thresholds from the model, and find the one that gives the best fbeta score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "    closest = thresholds[np.abs(recall - target).argmin()]\n",
    "\n",
    "    return closest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (NEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notebook.EVAL_RESULTS[\"Baseline (NEWS)\"] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred=(sci.loc[sci_test.index].c_NEWS_score >= 7),\n",
    "    y_pred_proba=(sci.loc[sci_test.index].c_NEWS_score),\n",
    "    plot_title=\"NEWS (Threshold = 7)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/baseline_news.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[\"Baseline (NEWS)\"] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred=(sci.loc[sci_test.index].c_NEWS_score >= 7),\n",
    "    y_pred_proba=(sci.loc[sci_test.index].c_NEWS_score),\n",
    "    plot_title=\"NEWS (Threshold = 7, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/baseline_news_mortality.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[\"Baseline (NEWS)\"] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred=(sci.loc[sci_test.index].c_NEWS_score >= 7),\n",
    "    y_pred_proba=(sci.loc[sci_test.index].c_NEWS_score),\n",
    "    plot_title=\"NEWS (Threshold = 7, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/baseline_news_criticalcare.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (NEWS only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelkey = \"Logistic Regression (NEWS only)\"\n",
    "model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42).fit(\n",
    "    X_train_news, y_train_news\n",
    ")\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_news,\n",
    "    y_test_news,\n",
    "    plot_title=\"Logistic Regression (NEWS only, non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train_news, model.predict_proba(X_train_news)[:, 1],)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test_news)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_news,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (NEWS only, tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (NEWS only, tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (NEWS only, tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(\n",
    "    model, X_train_news, feature_perturbation=\"correlation_dependent\"\n",
    ")\n",
    "shap_values = explainer(X_test_news)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Logistic Regression (NEWS only)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_logistic_regression_news.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Logistic Regression (NEWS only)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_logistic_regression_news.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    \"LR__penalty\": \"l2\",\n",
    "    \"LR__solver\": \"lbfgs\",\n",
    "    \"LR__C\": 7.87,\n",
    "    \"LR__class_weight\": \"balanced\",\n",
    "    \"IMB__sampling_strategy\": 0.2,\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    lr_params = tune_logisticregression(\n",
    "        X_train, y_train, timeout=Notebook.HYPERPARAMETER_TIMEOUT\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"Logistic Regression\"\n",
    "model = (\n",
    "    ImbPipeline(\n",
    "        steps=[\n",
    "            (\"IMB\", RandomUnderSampler()),\n",
    "            (\"LR\", LogisticRegression(max_iter=10000)),\n",
    "        ]\n",
    "    )\n",
    "    .set_params(**lr_params)\n",
    "    .fit(X_train, y_train)\n",
    ")\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    plot_title=\"Logistic Regression (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(\n",
    "    model[\"LR\"], X_train, feature_perturbation=\"correlation_dependent\"\n",
    ")\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_logistic_regression.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_logistic_regression.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"RF__n_estimators\": 250,\n",
    "    \"RF__max_features\": 0.56,\n",
    "    \"RF__min_samples_split\": 8,\n",
    "    \"RF__min_samples_leaf\": 3,\n",
    "    \"RF__max_samples\": 0.75,\n",
    "    \"RF__class_weight\": \"balanced\",\n",
    "    \"IMB__sampling_strategy\": 0.14,\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    rf_params = tune_randomforest(\n",
    "        X_train, y_train, timeout=Notebook.HYPERPARAMETER_TIMEOUT\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"Random Forest\"\n",
    "model = (\n",
    "    ImbPipeline(steps=[(\"IMB\", RandomUnderSampler()), (\"RF\", RandomForestClassifier())])\n",
    "    .set_params(**rf_params)\n",
    "    .fit(X_train.to_numpy(), y_train)\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test.to_numpy(),\n",
    "    y_test,\n",
    "    plot_title=\"Random Forest (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train.to_numpy())[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred = np.where(y_pred_proba > 1 - threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Random Forest (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Random Forest (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Random Forest (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model[\"RF\"])\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Random Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_random_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Random Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_random_forest.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params = {\n",
    "    \"XGB__tree_method\": \"hist\",\n",
    "    \"XGB__booster\": \"gbtree\",\n",
    "    \"XGB__lambda\": 7e-2,\n",
    "    \"XGB__alpha\": 7e-05,\n",
    "    \"XGB__subsample\": 0.42,\n",
    "    \"XGB__colsample_bytree\": 0.87,\n",
    "    \"XGB__scale_pos_weight\": 14,\n",
    "    \"XGB__max_depth\": 7,\n",
    "    \"XGB__min_child_weight\": 10,\n",
    "    \"XGB__eta\": 0.034,\n",
    "    \"XGB__gamma\": 4e-08,\n",
    "    \"XGB__grow_policy\": \"lossguide\",\n",
    "    \"IMB__sampling_strategy\": 0.1,\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    xgboost_params = tune_xgboost(\n",
    "        X_train, y_train, timeout=Notebook.HYPERPARAMETER_TIMEOUT\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"XGBoost\"\n",
    "model = (\n",
    "    ImbPipeline(\n",
    "        steps=[\n",
    "            (\"IMB\", RandomUnderSampler()),\n",
    "            (\"XGB\", XGBClassifier(tree_method=\"hist\")),\n",
    "        ]\n",
    "    )\n",
    "    .set_params(**xgboost_params)\n",
    "    .fit(X_train, y_train)\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"XGBoost (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_xgboost.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > 1 - threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"XGBoost (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_xgboost.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"XGBoost (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_xgboost.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"XGBoost (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_xgboost.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = model[\"XGB\"].feature_importances_.argsort()[::-1]\n",
    "fig = sns.barplot(\n",
    "    x=model[\"XGB\"].feature_importances_[sorted_idx],\n",
    "    y=X_train.columns[sorted_idx],\n",
    "    color=\"deepskyblue\",\n",
    ")\n",
    "fig.set_title(\"XGBoost - Global feature importance (gain)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/global_weights_xgboost.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model[\"XGB\"])\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"XGBoost\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_xgboost.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"XGBoost\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_xgboost.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"feature_pre_filter\": False,\n",
    "    \"lambda_l1\": 3e-3,\n",
    "    \"lambda_l2\": 5.82,\n",
    "    \"num_leaves\": 223,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 1.0,\n",
    "    \"bagging_freq\": 0,\n",
    "    \"min_child_samples\": 20,\n",
    "    'objective': \"binary\",\n",
    "    'metrics': [\"binary_logloss\", \"auc\"],\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    lgbm_params = tune_lgbm(\n",
    "        X_train_lgbm, y_train_lgbm, timeout=Notebook.HYPERPARAMETER_TIMEOUT\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"LightGBM\"\n",
    "model = LGBMClassifier(\n",
    "     **lgbm_params\n",
    ").fit(X_train_lgbm.copy(), y_train_lgbm)\n",
    "\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_lgbm.copy(),\n",
    "    y_test_lgbm,\n",
    "    plot_title=\"LightGBM (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_lightgbm.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_test_lgbm, model.predict_proba(X_test_lgbm)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test_lgbm)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_lgbm,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"LightGBM (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_lightgbm.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"LightGBM (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_lightgbm.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"LightGBM (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_lightgbm.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "fig = lgb.plot_importance(model)\n",
    "fig.set_title(\"LightGBM - Global feature importance (gain)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/global_weights_lightgbm.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"LightGBM\")\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_lightgbm.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"LightGBM\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_lightgbm.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_params = {\n",
    "    \"n_estimators\": 87,\n",
    "    \"max_samples\": 0.79,\n",
    "    \"contamination\": 4.5e-3,\n",
    "    \"max_features\": 0.61,\n",
    "    \"bootstrap\": True,\n",
    "}\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    if_params = tune_isolationforest(\n",
    "        X_train_if, y_train_if, timeout=Notebook.HYPERPARAMETER_TIMEOUT\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelkey = \"Isolation Forest\"\n",
    "\n",
    "model = IsolationForestWrapper(**if_params).fit(X_train_if[~y_train_if].to_numpy())\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_if.to_numpy(),\n",
    "    y_test_if,\n",
    "    plot_title=\"Isolation Forest (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = model.decision_function(X_train_if)\n",
    "y_pred_proba_train -= y_pred_proba_train.min()\n",
    "\n",
    "threshold = get_threshold(y_train_if, y_pred_proba_train,)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.decision_function(X_test_if)\n",
    "y_pred = np.where(y_pred_proba - y_pred_proba.min() > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_if,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Isolation Forest (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Isolation Forest (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Isolation Forest (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_test_if)\n",
    "shap_values.values = -shap_values.values  # Fix for isolation forest's unique labelling\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Isolation Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_isolation_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(\n",
    "    shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False\n",
    ")\n",
    "plt.title(\"Isolation Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_isolation_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "tabnet_params = dict(\n",
    "    cat_idxs=categorical_cols_idx,\n",
    "    cat_dims=categorical_cols_dims,\n",
    "    n_a=64,\n",
    "    n_d=64,\n",
    "    n_steps=3,\n",
    "    gamma=1.0,\n",
    "    lambda_sparse=9e-4,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=0.02, weight_decay=1e-05),\n",
    "    mask_type=\"sparsemax\",\n",
    "    n_shared=1,\n",
    "    scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-05, factor=0.5,),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    verbose=0,\n",
    ")\n",
    "tabnet_epochs, tabnet_patience = 100, 50\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    tabnet_params, tabnet_epochs, tabnet_patience = tune_tabnet(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        categorical_cols_idx,\n",
    "        categorical_cols_dims,\n",
    "        timeout=Notebook.HYPERPARAMETER_TIMEOUT,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelkey = \"TabNet\"\n",
    "model = TabNetClassifier(**tabnet_params)\n",
    "model.fit(\n",
    "    X_train=X_train_tn,\n",
    "    y_train=y_train_tn,\n",
    "    eval_set=[(X_train_tn, y_train_tn), (X_valid_tn, y_valid_tn),],\n",
    "    eval_name=[\"train\", \"valid\"],\n",
    "    eval_metric=[F2TabNet],\n",
    "    max_epochs=tabnet_epochs,\n",
    "    patience=tabnet_patience,\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test.to_numpy(),\n",
    "    y_test,\n",
    "    \"TabNet (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_tabnet.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(\n",
    "    y_test, model.predict_proba(X_test.to_numpy())[:, 1], target=0.785\n",
    ")\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"TabNet (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_tabnet.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mortality\")\n",
    "Notebook.MORTALITY_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_mortality,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"TabNet (tuned, predicting mortality only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_mortality_thresholded_tabnet.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "print(\"Critical Care\")\n",
    "Notebook.CRITICALCARE_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_criticalcare,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"TabNet (tuned, predicting critical care only)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_criticalcare_thresholded_tabnet.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = model.feature_importances_.argsort()[::-1]\n",
    "fig = sns.barplot(\n",
    "    x=model.feature_importances_[sorted_idx],\n",
    "    y=X_train.columns[sorted_idx],\n",
    "    color=\"deepskyblue\",\n",
    ")\n",
    "fig.set_title(\"TabNet - Global feature importance\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/global_weights_tabnet.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tn_shap = shap.sample(X_test.to_numpy(), 5000)\n",
    "explainer = shap.KernelExplainer(model.predict_proba, shap.sample(X_train_tn, 100))\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    shap_values = explainer.shap_values(X_test_tn_shap, nsamples=50)\n",
    "\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values[1],\n",
    "    X_test_tn_shap,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    plot_type=\"dot\",\n",
    ")\n",
    "plt.title(\"TabNet (estimated)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_tabnet.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values[1],\n",
    "    X_test_tn_shap,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    plot_type=\"bar\",\n",
    "    color=shap.plots.colors.red_rgb,\n",
    ")\n",
    "plt.title(\"TabNet (estimated)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_tabnet.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.SAVE_MODELS:\n",
    "    with open(f\"{Notebook.MODEL_DIR}/models.bin\", \"wb\") as file:\n",
    "        pickle.dump(Notebook.MODELS, file)\n",
    "\n",
    "    with open(f\"{Notebook.MODEL_DIR}/explainers.bin\", \"wb\") as file:\n",
    "        pickle.dump(Notebook.EXPLAINERS, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-tuning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [results[0].assign(Model=key) for key, results in Notebook.EVAL_RESULTS.items()]\n",
    ").set_index(\"Model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-tuning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [results[0].assign(Model=key) for key, results in Notebook.TUNED_RESULTS.items()]\n",
    ").set_index(\"Model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_dict, pr_dict = (\n",
    "    {key: val[1] for key, val in Notebook.EVAL_RESULTS.items()},\n",
    "    {key: val[2] for key, val in Notebook.EVAL_RESULTS.items()},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_plot(\n",
    "    roc_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_roc_curve\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_plot(\n",
    "    pr_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_pr_curve\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Precision-Recall\",\n",
    "    legend_location=\"upper right\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict,\n",
    "    ax=ax[1],\n",
    "    title=\"Precision-Recall\",\n",
    "    legend_location=\"upper right\",\n",
    "    plot_baseline=False,\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict,\n",
    "    ax=ax[0],\n",
    "    title=\"Receiver Operating Characteristic (ROC)\",\n",
    "    plot_baseline=False,\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/combined_curves_no_baseline.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict, ax=ax[1], title=\"Precision-Recall\", legend_location=\"upper right\",\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict, ax=ax[0], title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/combined_curves.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Explanations (Setup - skip to next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.DataFrame(\n",
    "    {\n",
    "        key: model.predict(\n",
    "            {\n",
    "                \"LightGBM\": X_test_lgbm,\n",
    "                \"Isolation Forest\": X_test_if,\n",
    "                \"TabNet\": X_test.to_numpy(),\n",
    "                \"XGBoost\": X_test,\n",
    "                \"Random Forest\": X_test,\n",
    "                \"Logistic Regression\": X_test,\n",
    "            }[key]\n",
    "        )\n",
    "        for key, model in Notebook.MODELS.items()\n",
    "        if key != \"Logistic Regression (NEWS only)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "candidates = y_preds[y_preds.all(axis=1)].index\n",
    "\n",
    "patient = candidates[0]\n",
    "patient_data = X_test_lgbm.iloc[patient].apply(\n",
    "    lambda x: f\"{x:.2f}\" if type(x) == np.float64 else x\n",
    ")\n",
    "patient_data_if = X_test_if.iloc[patient].copy()\n",
    "patient_data_if.update(X_test_lgbm.iloc[patient])\n",
    "\n",
    "explanations = {\n",
    "    modelkey: shap_values[patient]\n",
    "    for modelkey, (_, shap_values) in Notebook.EXPLAINERS.items()\n",
    "    if not modelkey in [\"TabNet\", \"Logistic Regression (NEWS only)\"]\n",
    "}\n",
    "for _ in explanations.keys():\n",
    "    if len(explanations[_].shape) > 1:\n",
    "        explanations[_] = explanations[_][:, 1]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    tabnet_explainer = Notebook.EXPLAINERS[\"TabNet\"][0]\n",
    "    explanations[\"TabNet\"] = shap.Explanation(\n",
    "        tabnet_explainer.shap_values(X_test.to_numpy()[patient])[1],\n",
    "        data=patient_data.values,\n",
    "        base_values=tabnet_explainer.expected_value[1],\n",
    "        feature_names=patient_data.index,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Force Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.rc(\"axes\", titlesize=16)\n",
    "for modelkey, explanation in explanations.items():\n",
    "    patient_to_use = patient_data if modelkey != \"Isolation Forest\" else patient_data_if\n",
    "\n",
    "    explanation = shap.Explanation(explanation)\n",
    "    explanation.data = patient_to_use.values\n",
    "\n",
    "    fig = shap.plots.force(\n",
    "        explanation,\n",
    "        feature_names=patient_to_use.index,\n",
    "        matplotlib=True,\n",
    "        contribution_threshold=0.08,\n",
    "        show=False,\n",
    "        text_rotation=15,\n",
    "    )\n",
    "\n",
    "    plt.title(modelkey)\n",
    "    display(fig)\n",
    "\n",
    "    if Notebook.SAVE_IMAGES:\n",
    "        plt.savefig(\n",
    "            f\"{Notebook.IMAGE_DIR}/comaprison_force_plot_{modelkey.replace(' ','')}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortality-only Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        results[0].assign(Model=key)\n",
    "        for key, results in Notebook.MORTALITY_RESULTS.items()\n",
    "    ]\n",
    ").set_index(\"Model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_dict, pr_dict = (\n",
    "    {key: val[1] for key, val in Notebook.MORTALITY_RESULTS.items()},\n",
    "    {key: val[2] for key, val in Notebook.MORTALITY_RESULTS.items()},\n",
    ")\n",
    "\n",
    "joint_plot(\n",
    "    roc_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_roc_curve_mortality\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Receiver Operating Characteristic (predicting mortality only)\",\n",
    ")\n",
    "\n",
    "joint_plot(\n",
    "    pr_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_pr_curve_mortality\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Precision-Recall (predicting mortality only)\",\n",
    "    legend_location=\"upper right\",\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict, ax=ax[1], title=\"Precision-Recall\", legend_location=\"upper right\",\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict, ax=ax[0], title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/combined_curves_mortality.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical care-only results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_dict, pr_dict = (\n",
    "    {key: val[1] for key, val in Notebook.CRITICALCARE_RESULTS.items()},\n",
    "    {key: val[2] for key, val in Notebook.CRITICALCARE_RESULTS.items()},\n",
    ")\n",
    "\n",
    "joint_plot(\n",
    "    roc_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_roc_curve_criticalcare\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Receiver Operating Characteristic (predicting critical care only)\",\n",
    ")\n",
    "\n",
    "joint_plot(\n",
    "    pr_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_pr_curve_criticalcare\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    "    ax=None,\n",
    "    title=\"Precision-Recall (predicting critical care only)\",\n",
    "    legend_location=\"upper right\",\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict, ax=ax[1], title=\"Precision-Recall\", legend_location=\"upper right\",\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict, ax=ax[0], title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/combined_curves_criticalcare.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
