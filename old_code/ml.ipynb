{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, math, itertools, json, logging, os\n",
    "from hashlib import md5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"colorblind\")\n",
    "sns.set(rc={\"figure.figsize\": (11.5, 8.5), \"figure.dpi\": 100})\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    RUN_TRAINING = False\n",
    "    SCRIPT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "#SCIData.load('data/sci.h5').clean_all().filter_vague_diagnoses().derive_readmission().omit_vbg().omit_ae().save()\n",
    "if Notebook.RUN_TRAINING:\n",
    "    sci = SCIData.load('data/sci_processed.h5').augment_hsmr(onehot=True).omit_news_extras().mandate_news().impute_blood().raw_news().mandate_diagnoses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RUN_TRAINING:\n",
    "    X, _ = sci.omit_redundant().xy()\n",
    "    ys = {\n",
    "        'CriticalCare48h': sci.derive_critical_care(within=2).xy(outcome=\"CriticalCare\")[1],\n",
    "        'Death48h': sci.derive_death_within(within=2).xy(outcome=\"DiedWithinThreshold\")[1],\n",
    "        'CriticalEvent48h': sci.derive_critical_event(within=2).xy(outcome=\"CriticalEvent\")[1],\n",
    "        'LOS48h': (sci.TotalLOS >= 48).to_numpy(),\n",
    "        'ReadmissionWithin30Days': sci.Readmitted.fillna(False).to_numpy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (numeric_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_pipeline, make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "full_processor = Pipeline(steps=[(\"columns\", ct)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "f2_score = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "METRICS = {\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"Precision\": \"precision\",\n",
    "    \"Recall\": \"recall\",\n",
    "    \"AUC\": \"roc_auc\",\n",
    "    \"F1 Score\": \"f1\",\n",
    "    \"F2 Score\": f2_score,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "def spotCheckCV(model, X, y, cv=3, pretty=True):\n",
    "    scores = cross_validate(model, X, y, scoring=METRICS, cv=cv)\n",
    "    if pretty:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    (name.split(\"_\")[1], sc)\n",
    "                    for name, score in scores.items()\n",
    "                    if name.startswith(\"test\")\n",
    "                    for sc in score\n",
    "                ],\n",
    "                columns=[\"Metric\", \"Score\"],\n",
    "            )\n",
    "            .groupby(\"Metric\")\n",
    "            .agg(\n",
    "                Mean=pd.NamedAgg(column=\"Score\", aggfunc=np.mean),\n",
    "                Std=pd.NamedAgg(column=\"Score\", aggfunc=np.std),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import cross_validate_parallel_file\n",
    "%aimport cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, C=1e2, max_iter=1000),\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "}\n",
    "\n",
    "IMBALANCED_MODELS = {\n",
    "    \"Balanced Decision Tree\": DecisionTreeClassifier(class_weight=\"balanced\"),\n",
    "    \"Balanced SVM\": SVC(gamma=\"scale\", class_weight=\"balanced\"),\n",
    "    \"Balanced Random Forest\": BalancedRandomForestClassifier(\n",
    "        n_estimators=10, class_weight=\"balanced_subsample\"\n",
    "    ),\n",
    "    \"Balanced XGBoost\": XGBClassifier(\n",
    "        use_label_encoder=False, scale_pos_weight=21, eval_metric=\"logloss\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "RESAMPLERS = {\n",
    "    \"SMOTE\": SMOTE(),\n",
    "    \"Undersampling\": RandomUnderSampler(sampling_strategy=\"majority\"),\n",
    "    \"SMOTE-Tomek\": SMOTETomek(tomek=TomekLinks(sampling_strategy=\"majority\")),\n",
    "}\n",
    "\n",
    "resampled_models = {\n",
    "    f\"{classifier[0]} with {sampler[0]}\": ImbPipeline(steps=[sampler, classifier])\n",
    "    for sampler in RESAMPLERS.items()\n",
    "    for classifier in MODELS.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.SCRIPT:\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Run test')\n",
    "    parser.add_argument('--outcome', type=str,\n",
    "                        help=f'Can be: {ys.keys()}')\n",
    "    parser.add_argument('--filename', type=str,\n",
    "                        help='Output filename')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(f'########## RUNNING {args.outcome} ##############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if Notebook.RUN_TRAINING:\n",
    "    X = full_processor.fit_transform(X)\n",
    "    y = ys[args.outcome]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RUN_TRAINING:    \n",
    "    m = {**MODELS, **resampled_models, **IMBALANCED_MODELS}\n",
    "    cross_validate_parallel_file(\n",
    "        filename=args.filename,\n",
    "        models=m,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        scoring=METRICS,\n",
    "        cv=2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f'results/ml_test_2/{_}').assign(test=_[:-4]) for _ in os.listdir('results\\ml_test_2')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>test_F1 Score</th>\n",
       "      <th>test_F2 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Balanced Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.768819</td>\n",
       "      <td>0.301163</td>\n",
       "      <td>0.971962</td>\n",
       "      <td>0.175507</td>\n",
       "      <td>0.185966</td>\n",
       "      <td>0.585609</td>\n",
       "      <td>0.180474</td>\n",
       "      <td>0.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.207345</td>\n",
       "      <td>0.890289</td>\n",
       "      <td>0.845823</td>\n",
       "      <td>0.077179</td>\n",
       "      <td>0.754490</td>\n",
       "      <td>0.870676</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.273746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced SVM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>888.570860</td>\n",
       "      <td>321.909117</td>\n",
       "      <td>0.908810</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>0.650558</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>0.191912</td>\n",
       "      <td>0.332539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced XGBoost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.993473</td>\n",
       "      <td>0.350846</td>\n",
       "      <td>0.963852</td>\n",
       "      <td>0.215077</td>\n",
       "      <td>0.444791</td>\n",
       "      <td>0.874887</td>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.366228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.052651</td>\n",
       "      <td>0.365960</td>\n",
       "      <td>0.970157</td>\n",
       "      <td>0.176159</td>\n",
       "      <td>0.217761</td>\n",
       "      <td>0.600320</td>\n",
       "      <td>0.194636</td>\n",
       "      <td>0.207841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73.041921</td>\n",
       "      <td>0.320252</td>\n",
       "      <td>0.964699</td>\n",
       "      <td>0.143646</td>\n",
       "      <td>0.225681</td>\n",
       "      <td>0.601438</td>\n",
       "      <td>0.175499</td>\n",
       "      <td>0.202495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>538.906366</td>\n",
       "      <td>0.087339</td>\n",
       "      <td>0.964699</td>\n",
       "      <td>0.143646</td>\n",
       "      <td>0.225681</td>\n",
       "      <td>0.601438</td>\n",
       "      <td>0.175499</td>\n",
       "      <td>0.202495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.793403</td>\n",
       "      <td>0.328586</td>\n",
       "      <td>0.740922</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>0.739221</td>\n",
       "      <td>0.740086</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>0.184350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027507</td>\n",
       "      <td>0.438440</td>\n",
       "      <td>0.101116</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.979481</td>\n",
       "      <td>0.534011</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.082999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.420742</td>\n",
       "      <td>0.881531</td>\n",
       "      <td>0.219882</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.953666</td>\n",
       "      <td>0.586284</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>524.926106</td>\n",
       "      <td>0.257892</td>\n",
       "      <td>0.219882</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.953666</td>\n",
       "      <td>0.586284</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506372</td>\n",
       "      <td>0.760412</td>\n",
       "      <td>0.290198</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.949693</td>\n",
       "      <td>0.628038</td>\n",
       "      <td>0.042621</td>\n",
       "      <td>0.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50.040788</td>\n",
       "      <td>0.338183</td>\n",
       "      <td>0.983560</td>\n",
       "      <td>0.526058</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>0.889386</td>\n",
       "      <td>0.216197</td>\n",
       "      <td>0.159949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>103.914456</td>\n",
       "      <td>0.221660</td>\n",
       "      <td>0.852645</td>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.764402</td>\n",
       "      <td>0.882721</td>\n",
       "      <td>0.147167</td>\n",
       "      <td>0.285454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>558.057005</td>\n",
       "      <td>0.086789</td>\n",
       "      <td>0.852645</td>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.764402</td>\n",
       "      <td>0.882721</td>\n",
       "      <td>0.147167</td>\n",
       "      <td>0.285454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.519353</td>\n",
       "      <td>0.378342</td>\n",
       "      <td>0.837141</td>\n",
       "      <td>0.075669</td>\n",
       "      <td>0.783592</td>\n",
       "      <td>0.885442</td>\n",
       "      <td>0.138005</td>\n",
       "      <td>0.272895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>118.888872</td>\n",
       "      <td>3.574528</td>\n",
       "      <td>0.983681</td>\n",
       "      <td>0.683741</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.061860</td>\n",
       "      <td>0.040048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>150.504183</td>\n",
       "      <td>2.434275</td>\n",
       "      <td>0.981821</td>\n",
       "      <td>0.391114</td>\n",
       "      <td>0.165449</td>\n",
       "      <td>0.886424</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>0.186962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>575.026491</td>\n",
       "      <td>1.447260</td>\n",
       "      <td>0.981821</td>\n",
       "      <td>0.391114</td>\n",
       "      <td>0.165449</td>\n",
       "      <td>0.886424</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>0.186962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.628270</td>\n",
       "      <td>5.893065</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>0.808089</td>\n",
       "      <td>0.898654</td>\n",
       "      <td>0.146040</td>\n",
       "      <td>0.287170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>578.921019</td>\n",
       "      <td>71.142791</td>\n",
       "      <td>0.983373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1221.593238</td>\n",
       "      <td>267.216458</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>0.845509</td>\n",
       "      <td>0.279062</td>\n",
       "      <td>0.330303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1467.850778</td>\n",
       "      <td>207.501730</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>0.845507</td>\n",
       "      <td>0.279062</td>\n",
       "      <td>0.330303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.954411</td>\n",
       "      <td>79.648966</td>\n",
       "      <td>0.873003</td>\n",
       "      <td>0.089375</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.879234</td>\n",
       "      <td>0.158944</td>\n",
       "      <td>0.298299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56.937828</td>\n",
       "      <td>0.392832</td>\n",
       "      <td>0.983571</td>\n",
       "      <td>0.520243</td>\n",
       "      <td>0.153542</td>\n",
       "      <td>0.893092</td>\n",
       "      <td>0.236972</td>\n",
       "      <td>0.178702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost with SMOTE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.165682</td>\n",
       "      <td>0.378066</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.172087</td>\n",
       "      <td>0.890822</td>\n",
       "      <td>0.251843</td>\n",
       "      <td>0.197015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost with SMOTE-Tomek</th>\n",
       "      <td>0.0</td>\n",
       "      <td>544.735049</td>\n",
       "      <td>0.152836</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.172087</td>\n",
       "      <td>0.890822</td>\n",
       "      <td>0.251843</td>\n",
       "      <td>0.197015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost with Undersampling</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.070772</td>\n",
       "      <td>0.566772</td>\n",
       "      <td>0.829922</td>\n",
       "      <td>0.073058</td>\n",
       "      <td>0.788895</td>\n",
       "      <td>0.889564</td>\n",
       "      <td>0.133720</td>\n",
       "      <td>0.266496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        err     fit_time  score_time  \\\n",
       "model                                                                  \n",
       "Balanced Decision Tree                  0.0    38.768819    0.301163   \n",
       "Balanced Random Forest                  0.0     3.207345    0.890289   \n",
       "Balanced SVM                            0.0   888.570860  321.909117   \n",
       "Balanced XGBoost                        0.0    60.993473    0.350846   \n",
       "Decision Tree                           0.0    60.052651    0.365960   \n",
       "Decision Tree with SMOTE                0.0    73.041921    0.320252   \n",
       "Decision Tree with SMOTE-Tomek          0.0   538.906366    0.087339   \n",
       "Decision Tree with Undersampling        0.0     0.793403    0.328586   \n",
       "Gaussian NB                             0.0     1.027507    0.438440   \n",
       "Gaussian NB with SMOTE                  0.0     6.420742    0.881531   \n",
       "Gaussian NB with SMOTE-Tomek            0.0   524.926106    0.257892   \n",
       "Gaussian NB with Undersampling          0.0     0.506372    0.760412   \n",
       "Logistic Regression                     0.0    50.040788    0.338183   \n",
       "Logistic Regression with SMOTE          0.0   103.914456    0.221660   \n",
       "Logistic Regression with SMOTE-Tomek    0.0   558.057005    0.086789   \n",
       "Logistic Regression with Undersampling  0.0    11.519353    0.378342   \n",
       "Random Forest                           0.0   118.888872    3.574528   \n",
       "Random Forest with SMOTE                0.0   150.504183    2.434275   \n",
       "Random Forest with SMOTE-Tomek          0.0   575.026491    1.447260   \n",
       "Random Forest with Undersampling        0.0     4.628270    5.893065   \n",
       "SVM                                     0.0   578.921019   71.142791   \n",
       "SVM with SMOTE                          0.0  1221.593238  267.216458   \n",
       "SVM with SMOTE-Tomek                    0.0  1467.850778  207.501730   \n",
       "SVM with Undersampling                  0.0     2.954411   79.648966   \n",
       "XGBoost                                 0.0    56.937828    0.392832   \n",
       "XGBoost with SMOTE                      0.0    80.165682    0.378066   \n",
       "XGBoost with SMOTE-Tomek                0.0   544.735049    0.152836   \n",
       "XGBoost with Undersampling              0.0    15.070772    0.566772   \n",
       "\n",
       "                                        test_Accuracy  test_Precision  \\\n",
       "model                                                                   \n",
       "Balanced Decision Tree                       0.971962        0.175507   \n",
       "Balanced Random Forest                       0.845823        0.077179   \n",
       "Balanced SVM                                 0.908810        0.112580   \n",
       "Balanced XGBoost                             0.963852        0.215077   \n",
       "Decision Tree                                0.970157        0.176159   \n",
       "Decision Tree with SMOTE                     0.964699        0.143646   \n",
       "Decision Tree with SMOTE-Tomek               0.964699        0.143646   \n",
       "Decision Tree with Undersampling             0.740922        0.046075   \n",
       "Gaussian NB                                  0.101116        0.017807   \n",
       "Gaussian NB with SMOTE                       0.219882        0.019964   \n",
       "Gaussian NB with SMOTE-Tomek                 0.219882        0.019964   \n",
       "Gaussian NB with Undersampling               0.290198        0.021800   \n",
       "Logistic Regression                          0.983560        0.526058   \n",
       "Logistic Regression with SMOTE               0.852645        0.081426   \n",
       "Logistic Regression with SMOTE-Tomek         0.852645        0.081426   \n",
       "Logistic Regression with Undersampling       0.837141        0.075669   \n",
       "Random Forest                                0.983681        0.683741   \n",
       "Random Forest with SMOTE                     0.981821        0.391114   \n",
       "Random Forest with SMOTE-Tomek               0.981821        0.391114   \n",
       "Random Forest with Undersampling             0.842610        0.080285   \n",
       "SVM                                          0.983373        0.000000   \n",
       "SVM with SMOTE                               0.967593        0.221898   \n",
       "SVM with SMOTE-Tomek                         0.967593        0.221898   \n",
       "SVM with Undersampling                       0.873003        0.089375   \n",
       "XGBoost                                      0.983571        0.520243   \n",
       "XGBoost with SMOTE                           0.983087        0.473250   \n",
       "XGBoost with SMOTE-Tomek                     0.983087        0.473250   \n",
       "XGBoost with Undersampling                   0.829922        0.073058   \n",
       "\n",
       "                                        test_Recall  test_AUC  test_F1 Score  \\\n",
       "model                                                                          \n",
       "Balanced Decision Tree                     0.185966  0.585609       0.180474   \n",
       "Balanced Random Forest                     0.754490  0.870676       0.140013   \n",
       "Balanced SVM                               0.650558  0.873553       0.191912   \n",
       "Balanced XGBoost                           0.444791  0.874887       0.289735   \n",
       "Decision Tree                              0.217761  0.600320       0.194636   \n",
       "Decision Tree with SMOTE                   0.225681  0.601438       0.175499   \n",
       "Decision Tree with SMOTE-Tomek             0.225681  0.601438       0.175499   \n",
       "Decision Tree with Undersampling           0.739221  0.740086       0.086735   \n",
       "Gaussian NB                                0.979481  0.534011       0.034978   \n",
       "Gaussian NB with SMOTE                     0.953666  0.586284       0.039109   \n",
       "Gaussian NB with SMOTE-Tomek               0.953666  0.586284       0.039109   \n",
       "Gaussian NB with Undersampling             0.949693  0.628038       0.042621   \n",
       "Logistic Regression                        0.136323  0.889386       0.216197   \n",
       "Logistic Regression with SMOTE             0.764402  0.882721       0.147167   \n",
       "Logistic Regression with SMOTE-Tomek       0.764402  0.882721       0.147167   \n",
       "Logistic Regression with Undersampling     0.783592  0.885442       0.138005   \n",
       "Random Forest                              0.032426  0.878359       0.061860   \n",
       "Random Forest with SMOTE                   0.165449  0.886424       0.232324   \n",
       "Random Forest with SMOTE-Tomek             0.165449  0.886424       0.232324   \n",
       "Random Forest with Undersampling           0.808089  0.898654       0.146040   \n",
       "SVM                                        0.000000  0.810247       0.000000   \n",
       "SVM with SMOTE                             0.376581  0.845509       0.279062   \n",
       "SVM with SMOTE-Tomek                       0.376581  0.845507       0.279062   \n",
       "SVM with Undersampling                     0.719380  0.879234       0.158944   \n",
       "XGBoost                                    0.153542  0.893092       0.236972   \n",
       "XGBoost with SMOTE                         0.172087  0.890822       0.251843   \n",
       "XGBoost with SMOTE-Tomek                   0.172087  0.890822       0.251843   \n",
       "XGBoost with Undersampling                 0.788895  0.889564       0.133720   \n",
       "\n",
       "                                        test_F2 Score  \n",
       "model                                                  \n",
       "Balanced Decision Tree                       0.183700  \n",
       "Balanced Random Forest                       0.273746  \n",
       "Balanced SVM                                 0.332539  \n",
       "Balanced XGBoost                             0.366228  \n",
       "Decision Tree                                0.207841  \n",
       "Decision Tree with SMOTE                     0.202495  \n",
       "Decision Tree with SMOTE-Tomek               0.202495  \n",
       "Decision Tree with Undersampling             0.184350  \n",
       "Gaussian NB                                  0.082999  \n",
       "Gaussian NB with SMOTE                       0.092100  \n",
       "Gaussian NB with SMOTE-Tomek                 0.092100  \n",
       "Gaussian NB with Undersampling               0.099828  \n",
       "Logistic Regression                          0.159949  \n",
       "Logistic Regression with SMOTE               0.285454  \n",
       "Logistic Regression with SMOTE-Tomek         0.285454  \n",
       "Logistic Regression with Undersampling       0.272895  \n",
       "Random Forest                                0.040048  \n",
       "Random Forest with SMOTE                     0.186962  \n",
       "Random Forest with SMOTE-Tomek               0.186962  \n",
       "Random Forest with Undersampling             0.287170  \n",
       "SVM                                          0.000000  \n",
       "SVM with SMOTE                               0.330303  \n",
       "SVM with SMOTE-Tomek                         0.330303  \n",
       "SVM with Undersampling                       0.298299  \n",
       "XGBoost                                      0.178702  \n",
       "XGBoost with SMOTE                           0.197015  \n",
       "XGBoost with SMOTE-Tomek                     0.197015  \n",
       "XGBoost with Undersampling                   0.266496  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['test', 'model']).mean().loc['CriticalEvent']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
