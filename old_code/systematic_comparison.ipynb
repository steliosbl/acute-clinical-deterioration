{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP Project - Systematic Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, pickle, os, itertools\n",
    "from dataclasses import dataclass\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "try:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "import shap\n",
    "import optuna, sqlalchemy\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import get_metrics, get_threshold_fpr\n",
    "%aimport utils.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systematic_comparison import  *\n",
    "from models import * \n",
    "%aimport systematic_comparison, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "\n",
    "sci = SCIData.load('data/sci.h5')\n",
    "\n",
    "scii = (\n",
    "    SCIData(SCIData.quickload(\"data/sci_processed.h5\").sort_values(\"AdmissionDateTime\"))\n",
    "    .mandate(SCICols.news_data_raw)\n",
    "    .derive_critical_event(within=1, return_subcols=True)\n",
    "    .augment_shmi(onehot=True)\n",
    "    .derive_ae_diagnosis_stems(onehot=False)\n",
    ")\n",
    "\n",
    "sci_train, sci_test, _, y_test_mortality, _, y_test_criticalcare = train_test_split(\n",
    "    scii,\n",
    "    scii.DiedWithinThreshold,\n",
    "    scii.CriticalCare,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "# (X_train, y_train), (X_test, y_test) = (\n",
    "#     sci_train.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "#     sci_test.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-14 15:24:38,499]\u001b[0m A new study created in memory with name: IsolationForest_None_Within-1_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 15:24:53,069]\u001b[0m Trial 0 finished with value: 0.1906763821299505 and parameters: {'IsolationForest__n_estimators': 153, 'IsolationForest__max_samples': 0.8801704338759069, 'IsolationForest__max_features': 0.5676133891506027, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.1906763821299505.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 15:24:54,033]\u001b[0m Trial 1 finished with value: 0.1879363013243021 and parameters: {'IsolationForest__n_estimators': 102, 'IsolationForest__max_samples': 0.635656589718247, 'IsolationForest__max_features': 0.22933077808514724, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.1906763821299505.\u001b[0m\n",
      " 99%|===================| 3274/3300 [00:41<00:00]        \u001b[32m[I 2022-11-14 15:25:39,151]\u001b[0m A new study created in memory with name: IsolationForest_None_Within-1_news_scores\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 15:25:40,133]\u001b[0m Trial 0 finished with value: 0.19583857476302302 and parameters: {'IsolationForest__n_estimators': 151, 'IsolationForest__max_samples': 0.47801235969139877, 'IsolationForest__max_features': 0.17306535532655698, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.19583857476302302.\u001b[0m\n",
      "\u001b[32m[I 2022-11-14 15:25:40,458]\u001b[0m Trial 1 finished with value: 0.19525803715007134 and parameters: {'IsolationForest__n_estimators': 33, 'IsolationForest__max_samples': 0.9093070100033264, 'IsolationForest__max_features': 0.6532345235258136, 'IsolationForest__bootstrap': True}. Best is trial 0 with value: 0.19583857476302302.\u001b[0m\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stybl\\src\\acute-care-pathways\\systematic_comparison.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstybl-acp/c%3A/Users/stybl/src/acute-care-pathways/systematic_comparison.ipynb#ch0000009vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m studies[\u001b[39m0\u001b[39m:]:\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstybl-acp/c%3A/Users/stybl/src/acute-care-pathways/systematic_comparison.ipynb#ch0000009vscode-remote?line=10'>11</a>\u001b[0m     s \u001b[39m=\u001b[39m construct_study(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_, scii\u001b[39m=\u001b[39mSCIData(scii\u001b[39m.\u001b[39msample(\u001b[39m10000\u001b[39m)), cv_jobs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bstybl-acp/c%3A/Users/stybl/src/acute-care-pathways/systematic_comparison.ipynb#ch0000009vscode-remote?line=12'>13</a>\u001b[0m     r \u001b[39m=\u001b[39m s(n_trials\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, model_persistence_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodels/test/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\stybl\\src\\acute-care-pathways\\systematic_comparison.py:342\u001b[0m, in \u001b[0;36mconstruct_study.<locals>.call\u001b[1;34m(model_persistence_path, n_resamples, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m     study\u001b[39m.\u001b[39moptimize(objective, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 342\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_study_result(model_persistence_path, n_resamples)\n\u001b[0;32m    343\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[0;32m    344\u001b[0m     optuna\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mStorageInternalError,\n\u001b[0;32m    345\u001b[0m     sqlalchemy\u001b[39m.\u001b[39mexc\u001b[39m.\u001b[39mOperationalError,\n\u001b[0;32m    346\u001b[0m     \u001b[39mAssertionError\u001b[39;00m,\n\u001b[0;32m    347\u001b[0m ):\n\u001b[0;32m    348\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m################# CAUGHT DB ERROR #################\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stybl\\src\\acute-care-pathways\\systematic_comparison.py:315\u001b[0m, in \u001b[0;36mconstruct_study.<locals>.handle_study_result\u001b[1;34m(model_persistence_path, n_resamples, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     model \u001b[39m=\u001b[39m pipeline_factory(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m explain:\n\u001b[1;32m--> 315\u001b[0m         explanations \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mexplain(model[estimator\u001b[39m.\u001b[39;49m_name], X, X_test)\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m model_persistence_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_persistence_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.bin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\stybl\\src\\acute-care-pathways\\models.py:142\u001b[0m, in \u001b[0;36mEstimator.explain\u001b[1;34m(cls, model, X_train, X_test)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplain\u001b[39m(\u001b[39mcls\u001b[39m, model, X_train, X_test):\n\u001b[0;32m    138\u001b[0m     ordinal_encode \u001b[39m=\u001b[39m (\u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_requirements[\u001b[39m\"\u001b[39m\u001b[39monehot\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    139\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_requirements[\u001b[39m\"\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 142\u001b[0m     shap_values \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_explainer(model, X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_explainer_args)(\n\u001b[0;32m    143\u001b[0m         X_test\u001b[39m.\u001b[39mordinal_encode_categories() \u001b[39mif\u001b[39;00m ordinal_encode \u001b[39melse\u001b[39;00m X_test\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_requirements[\u001b[39m\"\u001b[39m\u001b[39monehot\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    147\u001b[0m         cols \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mget_onehot_categorical_columns()\n",
      "File \u001b[1;32mc:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\shap\\explainers\\_tree.py:149\u001b[0m, in \u001b[0;36mTree.__init__\u001b[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_perturbation \u001b[39m=\u001b[39m feature_perturbation\n\u001b[0;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m TreeEnsemble(model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_missing, model_output)\n\u001b[0;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output \u001b[39m=\u001b[39m model_output\n\u001b[0;32m    151\u001b[0m \u001b[39m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\shap\\explainers\\_tree.py:642\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[1;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m    641\u001b[0m     scaling \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mestimators_) \u001b[39m# output is average of trees\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees \u001b[39m=\u001b[39m [IsoTree(e\u001b[39m.\u001b[39mtree_, f, scaling\u001b[39m=\u001b[39mscaling, data\u001b[39m=\u001b[39mdata, data_missing\u001b[39m=\u001b[39mdata_missing) \u001b[39mfor\u001b[39;00m e, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(model\u001b[39m.\u001b[39mestimators_, model\u001b[39m.\u001b[39mestimators_features_)]\n\u001b[0;32m    643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_value\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m \u001b[39melif\u001b[39;00m safe_isinstance(model, [\u001b[39m\"\u001b[39m\u001b[39mpyod.models.iforest.IForest\u001b[39m\u001b[39m\"\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\shap\\explainers\\_tree.py:642\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m    641\u001b[0m     scaling \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mestimators_) \u001b[39m# output is average of trees\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees \u001b[39m=\u001b[39m [IsoTree(e\u001b[39m.\u001b[39;49mtree_, f, scaling\u001b[39m=\u001b[39;49mscaling, data\u001b[39m=\u001b[39;49mdata, data_missing\u001b[39m=\u001b[39;49mdata_missing) \u001b[39mfor\u001b[39;00m e, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(model\u001b[39m.\u001b[39mestimators_, model\u001b[39m.\u001b[39mestimators_features_)]\n\u001b[0;32m    643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_value\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m \u001b[39melif\u001b[39;00m safe_isinstance(model, [\u001b[39m\"\u001b[39m\u001b[39mpyod.models.iforest.IForest\u001b[39m\u001b[39m\"\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\shap\\explainers\\_tree.py:1405\u001b[0m, in \u001b[0;36mIsoTree.__init__\u001b[1;34m(self, tree, tree_features, normalize, scaling, data, data_missing)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues \u001b[39m*\u001b[39m scaling\n\u001b[0;32m   1404\u001b[0m \u001b[39m# re-number the features if each tree gets a different set of features\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, tree_features[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "studies = study_grid(\n",
    "    estimators=[Estimator_IsolationForest],\n",
    "    resamplers=[None],\n",
    "    scii=scii,\n",
    "    outcome_thresholds=[1],\n",
    "    features=scii.feature_group_combinations\n",
    ")\n",
    "\n",
    "for _ in studies[0:]:\n",
    "    s = construct_study(**_, scii=SCIData(scii.sample(10000)), cv_jobs=5)\n",
    "\n",
    "    r = s(n_trials=2, model_persistence_path='models/test/')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_xy(scii, Estimator_OneClassSVM, scii.feature_group_combinations['news'])\n",
    "X_train = X_train[~y_train]\n",
    "y_train = y_train[X_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 12.74, NNZs: 7, Bias: 193.600000, T: 79074, Avg. loss: 0.052632\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.12, NNZs: 7, Bias: 86.200000, T: 158148, Avg. loss: 0.093937\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 7, Bias: 278.800000, T: 237222, Avg. loss: 0.124226\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: 171.400000, T: 316296, Avg. loss: 0.083996\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: 164.000000, T: 395370, Avg. loss: 0.105799\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 6, Bias: 56.600000, T: 474444, Avg. loss: 0.127316\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.00, NNZs: 7, Bias: 35.120000, T: 553518, Avg. loss: 0.020235\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.30, NNZs: 7, Bias: 33.640000, T: 632592, Avg. loss: 0.019725\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.00, NNZs: 7, Bias: 32.160000, T: 711666, Avg. loss: 0.022718\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.00, NNZs: 7, Bias: 10.680000, T: 790740, Avg. loss: 0.021286\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 7, Bias: 49.200000, T: 869814, Avg. loss: 0.018612\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.17, NNZs: 7, Bias: 67.720000, T: 948888, Avg. loss: 0.026494\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.00, NNZs: 7, Bias: 6.240000, T: 1027962, Avg. loss: 0.016285\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.00, NNZs: 7, Bias: 24.760000, T: 1107036, Avg. loss: 0.032319\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.00, NNZs: 7, Bias: 3.280000, T: 1186110, Avg. loss: 0.019390\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.00, NNZs: 7, Bias: 1.800000, T: 1265184, Avg. loss: 0.026072\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.00, NNZs: 7, Bias: 40.320000, T: 1344258, Avg. loss: 0.034981\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.00, NNZs: 7, Bias: 18.840000, T: 1423332, Avg. loss: 0.019093\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.79, NNZs: 7, Bias: 10.544000, T: 1502406, Avg. loss: 0.007175\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.08, NNZs: 7, Bias: 14.248000, T: 1581480, Avg. loss: 0.005562\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.00, NNZs: 7, Bias: 1.952000, T: 1660554, Avg. loss: 0.005165\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.00, NNZs: 7, Bias: 9.656000, T: 1739628, Avg. loss: 0.007436\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.01, NNZs: 7, Bias: 1.360000, T: 1818702, Avg. loss: 0.008575\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.60, NNZs: 7, Bias: 17.064000, T: 1897776, Avg. loss: 0.008235\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.06, NNZs: 7, Bias: 4.768000, T: 1976850, Avg. loss: 0.005468\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.00, NNZs: 7, Bias: 24.472000, T: 2055924, Avg. loss: 0.006021\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.67, NNZs: 7, Bias: 2.812800, T: 2134998, Avg. loss: 0.001183\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 7, Bias: 1.153600, T: 2214072, Avg. loss: 0.001563\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.57, NNZs: 7, Bias: 5.894400, T: 2293146, Avg. loss: 0.002034\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2.12, NNZs: 7, Bias: 3.435200, T: 2372220, Avg. loss: 0.001972\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.23, NNZs: 7, Bias: 4.176000, T: 2451294, Avg. loss: 0.001894\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2.99, NNZs: 7, Bias: 3.316800, T: 2530368, Avg. loss: 0.001437\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.90, NNZs: 7, Bias: 1.864960, T: 2609442, Avg. loss: 0.000385\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.83, NNZs: 7, Bias: 1.533120, T: 2688516, Avg. loss: 0.000637\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.79, NNZs: 7, Bias: 2.481280, T: 2767590, Avg. loss: 0.000383\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.95, NNZs: 7, Bias: 1.509440, T: 2846664, Avg. loss: 0.000320\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.26, NNZs: 7, Bias: 1.977600, T: 2925738, Avg. loss: 0.000351\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.44, NNZs: 7, Bias: 2.445760, T: 3004812, Avg. loss: 0.000483\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1.16, NNZs: 7, Bias: 1.633920, T: 3083886, Avg. loss: 0.000339\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1.35, NNZs: 7, Bias: 2.102080, T: 3162960, Avg. loss: 0.000509\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1.70, NNZs: 7, Bias: 2.090240, T: 3242034, Avg. loss: 0.000500\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.55, NNZs: 7, Bias: 1.127872, T: 3321108, Avg. loss: 0.000053\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.42, NNZs: 7, Bias: 1.061504, T: 3400182, Avg. loss: 0.000137\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.42, NNZs: 7, Bias: 1.155136, T: 3479256, Avg. loss: 0.000105\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.45, NNZs: 7, Bias: 1.216768, T: 3558330, Avg. loss: 0.000070\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.43, NNZs: 7, Bias: 1.214400, T: 3637404, Avg. loss: 0.000089\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.49, NNZs: 7, Bias: 1.084032, T: 3716478, Avg. loss: 0.000078\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.38, NNZs: 7, Bias: 1.013158, T: 3795552, Avg. loss: 0.000016\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.30, NNZs: 7, Bias: 1.012685, T: 3874626, Avg. loss: 0.000011\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.23, NNZs: 7, Bias: 1.012211, T: 3953700, Avg. loss: 0.000017\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.19, NNZs: 7, Bias: 1.043738, T: 4032774, Avg. loss: 0.000018\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.16, NNZs: 7, Bias: 1.030464, T: 4111848, Avg. loss: 0.000013\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.14, NNZs: 7, Bias: 1.023590, T: 4190922, Avg. loss: 0.000016\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.15, NNZs: 7, Bias: 1.016717, T: 4269996, Avg. loss: 0.000018\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.15, NNZs: 7, Bias: 1.002542, T: 4349070, Avg. loss: 0.000003\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.14, NNZs: 7, Bias: 1.001167, T: 4428144, Avg. loss: 0.000003\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.13, NNZs: 7, Bias: 1.006193, T: 4507218, Avg. loss: 0.000003\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.13, NNZs: 7, Bias: 1.003538, T: 4586292, Avg. loss: 0.000003\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.12, NNZs: 7, Bias: 1.006003, T: 4665366, Avg. loss: 0.000003\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.11, NNZs: 7, Bias: 1.009748, T: 4744440, Avg. loss: 0.000003\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.11, NNZs: 7, Bias: 1.007094, T: 4823514, Avg. loss: 0.000002\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.10, NNZs: 7, Bias: 1.008279, T: 4902588, Avg. loss: 0.000003\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.10, NNZs: 7, Bias: 1.001784, T: 4981662, Avg. loss: 0.000003\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.09, NNZs: 7, Bias: 1.005530, T: 5060736, Avg. loss: 0.000003\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.09, NNZs: 7, Bias: 1.004155, T: 5139810, Avg. loss: 0.000003\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.001500, T: 5218884, Avg. loss: 0.000003\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000457, T: 5297958, Avg. loss: 0.000001\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000950, T: 5377032, Avg. loss: 0.000001\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000675, T: 5456106, Avg. loss: 0.000001\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.001168, T: 5535180, Avg. loss: 0.000001\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000637, T: 5614254, Avg. loss: 0.000000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000618, T: 5693328, Avg. loss: 0.000001\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.001368, T: 5772402, Avg. loss: 0.000001\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000837, T: 5851476, Avg. loss: 0.000001\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000562, T: 5930550, Avg. loss: 0.000001\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000799, T: 6009624, Avg. loss: 0.000001\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000181, T: 6088698, Avg. loss: 0.000000\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000126, T: 6167772, Avg. loss: 0.000000\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000173, T: 6246846, Avg. loss: 0.000000\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000169, T: 6325920, Avg. loss: 0.000000\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000063, T: 6404994, Avg. loss: 0.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000264, T: 6484068, Avg. loss: 0.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000209, T: 6563142, Avg. loss: 0.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000044, T: 6642216, Avg. loss: 0.000000\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000033, T: 6721290, Avg. loss: 0.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000033, T: 6800364, Avg. loss: 0.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000073, T: 6879438, Avg. loss: 0.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000021, T: 6958512, Avg. loss: 0.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000041, T: 7037586, Avg. loss: 0.000000\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000006, T: 7116660, Avg. loss: 0.000000\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000005, T: 7195734, Avg. loss: 0.000000\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000007, T: 7274808, Avg. loss: 0.000000\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000009, T: 7353882, Avg. loss: 0.000000\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000007, T: 7432956, Avg. loss: 0.000000\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000009, T: 7512030, Avg. loss: 0.000000\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000007, T: 7591104, Avg. loss: 0.000000\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000007, T: 7670178, Avg. loss: 0.000000\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000013, T: 7749252, Avg. loss: 0.000000\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000008, T: 7828326, Avg. loss: 0.000000\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 7907400, Avg. loss: 0.000000\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 7986474, Avg. loss: 0.000000\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 8065548, Avg. loss: 0.000000\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8144622, Avg. loss: 0.000000\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000000, T: 8223696, Avg. loss: 0.000000\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8302770, Avg. loss: 0.000000\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000000, T: 8381844, Avg. loss: 0.000000\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8460918, Avg. loss: 0.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8539992, Avg. loss: 0.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8619066, Avg. loss: 0.000000\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 8698140, Avg. loss: 0.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 8777214, Avg. loss: 0.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000001, T: 8856288, Avg. loss: 0.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 8935362, Avg. loss: 0.000000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.08, NNZs: 7, Bias: 1.000002, T: 9014436, Avg. loss: 0.000000\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.07, NNZs: 7, Bias: 1.000001, T: 9093510, Avg. loss: 0.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.07, NNZs: 7, Bias: 1.000002, T: 9172584, Avg. loss: 0.000000\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 116 epochs took 1.18 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Scaling&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;Scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Respiration_rate&#x27;,\n",
       "                                                   &#x27;O2_saturation&#x27;,\n",
       "                                                   &#x27;Temperature&#x27;, &#x27;SystolicBP&#x27;,\n",
       "                                                   &#x27;HeartRate&#x27;])])),\n",
       "                (&#x27;OneClassSVM&#x27;,\n",
       "                 OneClassSVMWrapper(average=100000.0, eta0=100,\n",
       "                                    learning_rate=&#x27;adaptive&#x27;, max_iter=20000,\n",
       "                                    nu=0.001, random_state=42, tol=1e-12,\n",
       "                                    verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Scaling&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;Scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Respiration_rate&#x27;,\n",
       "                                                   &#x27;O2_saturation&#x27;,\n",
       "                                                   &#x27;Temperature&#x27;, &#x27;SystolicBP&#x27;,\n",
       "                                                   &#x27;HeartRate&#x27;])])),\n",
       "                (&#x27;OneClassSVM&#x27;,\n",
       "                 OneClassSVMWrapper(average=100000.0, eta0=100,\n",
       "                                    learning_rate=&#x27;adaptive&#x27;, max_iter=20000,\n",
       "                                    nu=0.001, random_state=42, tol=1e-12,\n",
       "                                    verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaling: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;Scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Respiration_rate&#x27;, &#x27;O2_saturation&#x27;,\n",
       "                                  &#x27;Temperature&#x27;, &#x27;SystolicBP&#x27;, &#x27;HeartRate&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Respiration_rate&#x27;, &#x27;O2_saturation&#x27;, &#x27;Temperature&#x27;, &#x27;SystolicBP&#x27;, &#x27;HeartRate&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;AVCPU_Alert&#x27;, &#x27;AssistedBreathing&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneClassSVMWrapper</label><div class=\"sk-toggleable__content\"><pre>OneClassSVMWrapper(average=100000.0, eta0=100, learning_rate=&#x27;adaptive&#x27;,\n",
       "                   max_iter=20000, nu=0.001, random_state=42, tol=1e-12,\n",
       "                   verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Scaling',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('Scaler', StandardScaler(),\n",
       "                                                  ['Respiration_rate',\n",
       "                                                   'O2_saturation',\n",
       "                                                   'Temperature', 'SystolicBP',\n",
       "                                                   'HeartRate'])])),\n",
       "                ('OneClassSVM',\n",
       "                 OneClassSVMWrapper(average=100000.0, eta0=100,\n",
       "                                    learning_rate='adaptive', max_iter=20000,\n",
       "                                    nu=0.001, random_state=42, tol=1e-12,\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PipelineFactory(Estimator_OneClassSVM, None, SCIData(X_train), y_train)()\n",
    "model.set_params(**dict(\n",
    "    OneClassSVM__verbose=1,\n",
    "    OneClassSVM__tol=1e-12, \n",
    "    OneClassSVM__nu=1e-3, \n",
    "    OneClassSVM__learning_rate='adaptive', \n",
    "    OneClassSVM__eta0=100, \n",
    "    OneClassSVM__average=1e5\n",
    "))\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27208706810772665"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, -model.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0536743464871563"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-OneClassSVMWrapper().fit(X).decision_function(X)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35620"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(SGDOneClassSVM().fit(X).predict(X)==-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942450985107733"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, -OneClassSVMWrapper().fit(X).decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function models.OneClassSVMWrapper.decision_function(self, X)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estimator_OneClassSVM._estimator.decision_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "# studies = [construct_study(**_, storage='sqlite:///models/studies.db', n_trials=2, sci_train=SCIData(sci_train.head(1000)), sci_test=SCIData(sci_test.head(1000))) for _ in get_studies(sci_train, study_grid)[:5]]\n",
    "# with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "#             results = Parallel(n_jobs=1)(\n",
    "#                 delayed(_)(n_trials=2) for _ in studies[:2]\n",
    "#             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
