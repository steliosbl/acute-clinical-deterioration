{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, math, itertools, json, logging\n",
    "from hashlib import md5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"colorblind\")\n",
    "sns.set(rc={\"figure.figsize\": (11.5, 8.5), \"figure.dpi\": 100})\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "#SCIData.load('data/sci.h5').clean_all().filter_vague_diagnoses().derive_readmission().omit_vbg().omit_ae().save()\n",
    "sci = SCIData.load('data/sci_processed.h5').augment_hsmr(onehot=True).omit_news_extras().mandate_news().impute_blood().raw_news().mandate_diagnoses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = sci.omit_redundant().xy()\n",
    "ys = {\n",
    "    'CriticalCare48h': sci.derive_critical_care(within=2).xy(outcome=\"CriticalCare\")[1],\n",
    "    'Death48h': sci.derive_death_within(within=2).xy(outcome=\"DiedWithinThreshold\")[1],\n",
    "    'CriticalEvent48h': sci.derive_critical_event(within=2).xy(outcome=\"CriticalEvent\")[1],\n",
    "    'LOS48h': (sci.TotalLOS >= 48).to_numpy(),\n",
    "    'ReadmissionWithin30Days': sci.Readmitted.fillna(False).to_numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (numeric_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_pipeline, make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "full_processor = Pipeline(steps=[(\"columns\", ct)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "f2_score = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "METRICS = {\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"Precision\": \"precision\",\n",
    "    \"Recall\": \"recall\",\n",
    "    \"AUC\": \"roc_auc\",\n",
    "    \"F1 Score\": \"f1\",\n",
    "    \"F2 Score\": f2_score,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "def spotCheckCV(model, X, y, cv=3, pretty=True):\n",
    "    scores = cross_validate(model, X, y, scoring=METRICS, cv=cv)\n",
    "    if pretty:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    (name.split(\"_\")[1], sc)\n",
    "                    for name, score in scores.items()\n",
    "                    if name.startswith(\"test\")\n",
    "                    for sc in score\n",
    "                ],\n",
    "                columns=[\"Metric\", \"Score\"],\n",
    "            )\n",
    "            .groupby(\"Metric\")\n",
    "            .agg(\n",
    "                Mean=pd.NamedAgg(column=\"Score\", aggfunc=np.mean),\n",
    "                Std=pd.NamedAgg(column=\"Score\", aggfunc=np.std),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import cross_validate_parallel_file\n",
    "%aimport cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, C=1e2, max_iter=1000),\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "}\n",
    "\n",
    "IMBALANCED_MODELS = {\n",
    "    \"Balanced Decision Tree\": DecisionTreeClassifier(class_weight=\"balanced\"),\n",
    "    \"Balanced SVM\": SVC(gamma=\"scale\", class_weight=\"balanced\"),\n",
    "    \"Balanced Random Forest\": BalancedRandomForestClassifier(\n",
    "        n_estimators=10, class_weight=\"balanced_subsample\"\n",
    "    ),\n",
    "    \"Balanced XGBoost\": XGBClassifier(\n",
    "        use_label_encoder=False, scale_pos_weight=21, eval_metric=\"logloss\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "RESAMPLERS = {\n",
    "    \"SMOTE\": SMOTE(),\n",
    "    \"Undersampling\": RandomUnderSampler(sampling_strategy=\"majority\"),\n",
    "    \"SMOTE-Tomek\": SMOTETomek(tomek=TomekLinks(sampling_strategy=\"majority\")),\n",
    "}\n",
    "\n",
    "resampled_models = {\n",
    "    f\"{classifier[0]} with {sampler[0]}\": ImbPipeline(steps=[sampler, classifier])\n",
    "    for sampler in RESAMPLERS.items()\n",
    "    for classifier in MODELS.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run test')\n",
    "parser.add_argument('--outcome', type=str,\n",
    "                    help=f'Can be: {ys.keys()}')\n",
    "parser.add_argument('--filename', type=str,\n",
    "                    help='Output filename')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f'########## RUNNING {args.outcome} ##############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._logistic.LogisticRegression"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = full_processor.fit_transform(X)\n",
    "y = ys[args.outcome]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = {**MODELS, **resampled_models, **IMBALANCED_MODELS}\n",
    "m = {'Dummy': DummyClassifier(strategy='constant', constant=1)}\n",
    "cross_validate_parallel_file(\n",
    "    filename=args.filename,\n",
    "    models=m,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    scoring=METRICS,\n",
    "    cv=2,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
