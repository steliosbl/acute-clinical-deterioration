{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, math, itertools, json, logging\n",
    "from hashlib import md5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"colorblind\")\n",
    "sns.set(rc={\"figure.figsize\": (11.5, 8.5), \"figure.dpi\": 100})\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "X, y = SCIData.load(\"data/sci_processed.h5\").omit_redundant().omit_vbg().omit_ae().derive_critical_event().augment_hsmr(onehot=True).impute_blood().raw_news().mandate_news().mandate_diagnoses().xy(outcome='DiedDuringStay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[(\"scale\", MinMaxScaler()),])\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[(\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),]\n",
    ")\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (numeric_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (categorical_pipeline, make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "full_processor = Pipeline(steps=[(\"columns\", ct)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    full_processor.fit_transform(X), y, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "f2_score = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "METRICS = {\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"Precision\": \"precision\",\n",
    "    \"Recall\": \"recall\",\n",
    "    \"AUC\": \"roc_auc\",\n",
    "    \"F1 Score\": \"f1\",\n",
    "    \"F2 Score\": f2_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "def spotCheckCV(model, X, y, cv=3, pretty=True):\n",
    "    scores = cross_validate(model, X, y, scoring=METRICS, cv=cv)\n",
    "    if pretty:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    (name.split(\"_\")[1], sc)\n",
    "                    for name, score in scores.items()\n",
    "                    if name.startswith(\"test\")\n",
    "                    for sc in score\n",
    "                ],\n",
    "                columns=[\"Metric\", \"Score\"],\n",
    "            )\n",
    "            .groupby(\"Metric\")\n",
    "            .agg(\n",
    "                Mean=pd.NamedAgg(column=\"Score\", aggfunc=np.mean),\n",
    "                Std=pd.NamedAgg(column=\"Score\", aggfunc=np.std),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def cross_validate_parallel(models, X, y, cv=3, threads=None):\n",
    "    if not threads:\n",
    "        threads = len(models)\n",
    "    \n",
    "    with Pool(threads) as p:\n",
    "        keys, values = zip(*models.items())\n",
    "        result = zip(keys, p.map(partial(cross_validate, X=X, y=y, cv=cv, scoring=METRICS), values))\n",
    "\n",
    "    return dict(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dummy1': {'fit_time': array([0.0781076 , 0.07810926, 0.06248593]),\n",
       "  'score_time': array([0.06248665, 0.03123999, 0.04686213]),\n",
       "  'test_Accuracy': array([0.04694439, 0.04694439, 0.04690408]),\n",
       "  'test_Precision': array([0.04694439, 0.04694439, 0.04690408]),\n",
       "  'test_Recall': array([1., 1., 1.]),\n",
       "  'test_AUC': array([0.5, 0.5, 0.5]),\n",
       "  'test_F1 Score': array([0.08967885, 0.08967885, 0.0896053 ]),\n",
       "  'test_F2 Score': array([0.19761438, 0.19761438, 0.19747151])},\n",
       " 'Dummy0': {'fit_time': array([0.07810569, 0.07810497, 0.06248856]),\n",
       "  'score_time': array([0.04686809, 0.04686475, 0.03124166]),\n",
       "  'test_Accuracy': array([0.95305561, 0.95305561, 0.95309592]),\n",
       "  'test_Precision': array([0., 0., 0.]),\n",
       "  'test_Recall': array([0., 0., 0.]),\n",
       "  'test_AUC': array([0.5, 0.5, 0.5]),\n",
       "  'test_F1 Score': array([0., 0., 0.]),\n",
       "  'test_F2 Score': array([0., 0., 0.])},\n",
       " 'Dummyhalf': {'fit_time': array([0.06249285, 0.05452728, 0.03124475]),\n",
       "  'score_time': array([0., 0., 0.]),\n",
       "  'test_Accuracy': array([nan, nan, nan]),\n",
       "  'test_Precision': array([nan, nan, nan]),\n",
       "  'test_Recall': array([nan, nan, nan]),\n",
       "  'test_AUC': array([nan, nan, nan]),\n",
       "  'test_F1 Score': array([nan, nan, nan]),\n",
       "  'test_F2 Score': array([nan, nan, nan])}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "models = {\n",
    "    'Dummy1': DummyClassifier(strategy=\"constant\", constant=1),\n",
    "    'Dummy0': DummyClassifier(strategy=\"constant\", constant=0),\n",
    "    'Dummyhalf': DummyClassifier(strategy=\"constant\", constant=0.5)\n",
    "}\n",
    "\n",
    "cross_validate_parallel(models, X_train, y_train, cv=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
