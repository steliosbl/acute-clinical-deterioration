{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP Project - Systematic Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, pickle, os, itertools\n",
    "from dataclasses import dataclass\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "try:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import get_metrics, get_threshold_fpr\n",
    "%aimport utils.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "\n",
    "sci = SCIData.load('data/sci.h5')\n",
    "\n",
    "scii = (\n",
    "    SCIData(SCIData.quickload(\"data/sci_processed.h5\").sort_values(\"AdmissionDateTime\"))\n",
    "    .mandate(SCICols.news_data_raw)\n",
    "    .derive_critical_event(within=1, return_subcols=True)\n",
    "    .augment_shmi(onehot=True)\n",
    "    .omit_redundant()\n",
    "    .raw_news()\n",
    "    .derive_ae_diagnosis_stems(onehot=False)\n",
    "    .categorize()\n",
    "   # .onehot_encode_categories()\n",
    ")\n",
    "\n",
    "sci_train, sci_test, _, y_test_mortality, _, y_test_criticalcare = train_test_split(\n",
    "    scii,\n",
    "    scii.DiedWithinThreshold,\n",
    "    scii.CriticalCare,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "# (X_train, y_train), (X_test, y_test) = (\n",
    "#     sci_train.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "#     sci_test.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = (\n",
    "    sci_train.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "    sci_test.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    ")\n",
    "categorical_cols, categories = X_train.describe_categories()\n",
    "#X_train = X_train.ordinal_encode_categories()\n",
    "X_train = X_train.ordinal_encode_categories().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from typing import Dict, Any, Iterable\n",
    "\n",
    "\n",
    "class Estimator:\n",
    "    _name: str\n",
    "    _estimator: BaseEstimator\n",
    "    _requirements: Dict[str, bool]\n",
    "    _static_params: Dict[str, Any] = {}\n",
    "    _tuning_params_default: Dict[str, Any] = {}\n",
    "    _fit_params: Dict[str, Any] = {}\n",
    "\n",
    "    def __init__(self, sci_train):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        return dict()\n",
    "\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        return {\n",
    "            f\"{cls._name}__{key}\": value\n",
    "            for key, value in {\n",
    "                **cls._static_params,\n",
    "                **cls._tuning_params_default,\n",
    "                **params,\n",
    "            }.items()\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return cls._estimator(**cls._static_params)\n",
    "\n",
    "    @classmethod\n",
    "    def fit_params(cls, X_train, y_train):\n",
    "        return {f\"{cls._name}__{key}\": value for key, value in cls._fit_params.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn import FunctionSampler\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class Resampler(Estimator):\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        return {\n",
    "            f\"{cls._name}__kw_args\": {\n",
    "                **cls._static_params,\n",
    "                **cls._tuning_params_default,\n",
    "                **params,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(\n",
    "            func=partial(SCIData.resample, cls._estimator),\n",
    "            validate=False,\n",
    "            kw_args=cls._static_params,\n",
    "        )\n",
    "\n",
    "\n",
    "class Resampler_SMOTE(Resampler):\n",
    "    _name = \"SMOTE\"\n",
    "    _estimator = SMOTENC\n",
    "\n",
    "    _static_params = dict(random_state=42, n_jobs=None,)\n",
    "\n",
    "    _tuning_params_default = dict(sampling_strategy=0.1, k_neighbors=5)\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            sampling_strategy=trial.suggest_float(\n",
    "                f\"{cls._name}__sampling_strategy\", 0.1, 0.5\n",
    "            ),\n",
    "            k_neighbors=trial.suggest_int(f\"{cls._name}__k_neighbors\", 2, 10),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(\n",
    "            func=SCIData.SMOTE, validate=False, kw_args=cls._static_params\n",
    "        )\n",
    "\n",
    "\n",
    "class Resampler_RandomUnderSampler(Resampler):\n",
    "    _name = \"RandomUnderSampler\"\n",
    "    _estimator = RandomUnderSampler\n",
    "\n",
    "    _static_params = dict(random_state=42, replacement=False)\n",
    "\n",
    "    _tuning_params_default = dict(sampling_strategy=0.1)\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            sampling_strategy=trial.suggest_float(\n",
    "                f\"{cls._name}__sampling_strategy\", 0.05, 0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "\n",
    "class No_Resampling(Resampler):\n",
    "    _name = \"No_Resampling\"\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        return dict()\n",
    "\n",
    "    @staticmethod\n",
    "    def _(X, y):\n",
    "        return X, y\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(func=cls._, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "class Estimator_LightGBM(Estimator):\n",
    "    _name = \"LightGBM\"\n",
    "    _estimator = LGBMClassifier\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=False, imputation=False, fillna=False, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        objective=\"binary\",\n",
    "        metric=[\"l2\", \"auc\"],\n",
    "        boosting_type=\"gbdt\",\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        is_unbalance=True,\n",
    "        reg_alpha=1.8e-3,\n",
    "        reg_lambda=6e-4,\n",
    "        num_leaves=14,\n",
    "        colsample_bytree=0.4,\n",
    "        subsample=0.97,\n",
    "        subsample_freq=1,\n",
    "        min_child_samples=6,\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            reg_alpha=trial.suggest_float(\n",
    "                f\"{cls._name}__reg_alpha\", 1e-4, 10.0, log=True\n",
    "            ),\n",
    "            reg_lambda=trial.suggest_float(\n",
    "                f\"{cls._name}__reg_lambda\", 1e-4, 10.0, log=True\n",
    "            ),\n",
    "            num_leaves=trial.suggest_int(f\"{cls._name}__num_leaves\", 2, 256),\n",
    "            colsample_bytree=trial.suggest_float(\n",
    "                f\"{cls._name}__colsample_bytree\", 0.4, 1.0\n",
    "            ),\n",
    "            subsample=trial.suggest_float(f\"{cls._name}__subsample\", 0.4, 1.0),\n",
    "            subsample_freq=trial.suggest_int(f\"{cls._name}__subsample_freq\", 1, 7),\n",
    "            min_child_samples=trial.suggest_int(\n",
    "                f\"{cls._name}__min_child_samples\", 5, 150\n",
    "            ),\n",
    "            is_unbalance=trial.suggest_categorical(\n",
    "                f\"{cls._name}__is_unbalance\", [True, False]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if not suggestions[\"is_unbalance\"]:\n",
    "            suggestions[\"scale_pos_weight\"] = trial.suggest_int(\n",
    "                f\"{cls._name}__scale_pos_weight\", 1, 100\n",
    "            )\n",
    "\n",
    "        r = cls.compile_parameters(suggestions)\n",
    "        if not suggestions[\"is_unbalance\"]:\n",
    "            del r[f\"{cls._name}__is_unbalance\"]\n",
    "\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "class Estimator_XGBoost(Estimator):\n",
    "    _name = \"XGBoost\"\n",
    "    _estimator = XGBClassifier\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=False, imputation=False, fillna=False, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        verbosity=0,\n",
    "        n_jobs=1,\n",
    "        objective=\"binary:logistic\",\n",
    "        booster=\"gbtree\",\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = {\n",
    "        **dict(\n",
    "            tree_method=\"hist\",\n",
    "            alpha=7e-05,\n",
    "            subsample=0.42,\n",
    "            colsample_bytree=0.87,\n",
    "            scale_pos_weight=14,\n",
    "            max_depth=7,\n",
    "            min_child_weight=10,\n",
    "            eta=0.035,\n",
    "            gamma=4e-08,\n",
    "            grow_policy=\"lossguide\",\n",
    "        ),\n",
    "        \"lambda\": 7e-2,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            tree_method=trial.suggest_categorical(\n",
    "                f\"{cls._name}__tree_method\", [\"approx\", \"hist\"]\n",
    "            ),\n",
    "            alpha=trial.suggest_float(f\"{cls._name}__alpha\", 1e-8, 1.0, log=True),\n",
    "            subsample=trial.suggest_float(f\"{cls._name}__subsample\", 0.2, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\n",
    "                f\"{cls._name}__colsample_bytree\", 0.2, 1.0\n",
    "            ),\n",
    "            scale_pos_weight=trial.suggest_int(\n",
    "                f\"{cls._name}__scale_pos_weight\", 1, 100\n",
    "            ),\n",
    "            max_depth=trial.suggest_int(f\"{cls._name}__max_depth\", 3, 9, step=2),\n",
    "            min_child_weight=trial.suggest_int(f\"{cls._name}__min_child_weight\", 2, 10),\n",
    "            eta=trial.suggest_float(f\"{cls._name}__eta\", 1e-8, 1.0, log=True),\n",
    "            gamma=trial.suggest_float(f\"{cls._name}__gamma\", 1e-8, 1.0, log=True),\n",
    "            grow_policy=trial.suggest_categorical(\n",
    "                f\"{cls._name}__grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "            ),\n",
    "        )\n",
    "        suggestions[\"lambda\"] = trial.suggest_float(\n",
    "            f\"{cls._name}__lambda\", 1e-8, 1.0, log=True\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class Estimator_LogisticRegression(Estimator):\n",
    "    _name = \"LogisticRegression\"\n",
    "    _estimator = LogisticRegression\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=True, ordinal=False, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(max_iter=100, solver=\"lbfgs\", random_state=42, penalty=\"l2\")\n",
    "\n",
    "    _tuning_params_default = dict(penalty=\"l2\", C=5.9, class_weight=\"balanced\")\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            penalty=trial.suggest_categorical(f\"{cls._name}__penalty\", [\"l2\", \"none\"]),\n",
    "            C=trial.suggest_float(f\"{cls._name}__C\", 0.01, 10),\n",
    "            class_weight=trial.suggest_categorical(\n",
    "                f\"{cls._name}__class_weight\", [None, \"balanced\"]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # if suggestions[\"penalty\"] == \"elasticnet\":\n",
    "        #     suggestions[\"l1_ratio\"] = trial.suggest_float(\n",
    "        #         f\"{cls._name}__l1_ratio\", 0.05, 0.95\n",
    "        #     )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class Estimator_RandomForest(Estimator):\n",
    "    _estimator = RandomForestClassifier\n",
    "    _name = \"RandomForest\"\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=True, imputation=False, fillna=True, resampling=False\n",
    "    )\n",
    "    _tuning_params_default = dict(\n",
    "        n_estimators=250,\n",
    "        max_features=0.56,\n",
    "        min_samples_split=8,\n",
    "        min_samples_leaf=3,\n",
    "        max_samples=0.75,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_estimators=trial.suggest_int(f\"{cls._name}__n_estimators\", 25, 250),\n",
    "            max_features=trial.suggest_float(f\"{cls._name}__max_features\", 0.15, 1.0),\n",
    "            min_samples_split=trial.suggest_int(\n",
    "                f\"{cls._name}__min_samples_split\", 2, 15\n",
    "            ),\n",
    "            min_samples_leaf=trial.suggest_int(f\"{cls._name}__min_samples_leaf\", 1, 15),\n",
    "            max_samples=trial.suggest_float(f\"{cls._name}__max_samples\", 0.5, 0.99),\n",
    "            class_weight=trial.suggest_categorical(\n",
    "                f\"{cls._name}__class_weight\", [None, \"balanced\", \"balanced_subsample\"]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.isolation_forest_wrapper import IsolationForestWrapper\n",
    "\n",
    "\n",
    "class Estimator_IsolationForest(Estimator):\n",
    "    _name = \"IsolationForest\"\n",
    "    _estimator = IsolationForestWrapper\n",
    "    _requirements = dict(\n",
    "        onehot=True, ordinal=False, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        n_estimators=140,\n",
    "        max_samples=0.45,\n",
    "        contamination=0.02,\n",
    "        max_features=0.69,\n",
    "        bootstrap=False,\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_estimators=trial.suggest_int(f\"{cls._name}__n_estimators\", 1, 200),\n",
    "            max_samples=trial.suggest_float(f\"{cls._name}__max_samples\", 0.0, 1.0),\n",
    "            contamination=trial.suggest_float(\n",
    "                f\"{cls._name}__contamination\", 1e-6, 1e-1\n",
    "            ),\n",
    "            max_features=trial.suggest_float(f\"{cls._name}__max_features\", 0.0, 1.0),\n",
    "            bootstrap=trial.suggest_categorical(\n",
    "                f\"{cls._name}__bootstrap\", [True, False]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TabNetWrapper(TabNetClassifier):\n",
    "    weights: int = 0\n",
    "    max_epochs: int = 100\n",
    "    patience: int = 10\n",
    "    batch_size: int = 1024\n",
    "    virtual_batch_size: int = 128\n",
    "    drop_last: bool = True\n",
    "    eval_metric: str = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return super().fit(\n",
    "            X_train=X.to_numpy(),\n",
    "            y_train=y.to_numpy(),\n",
    "            eval_metric=self.eval_metric,\n",
    "            weights=self.weights,\n",
    "            max_epochs=self.max_epochs,\n",
    "            patience=self.patience,\n",
    "            batch_size=self.batch_size,\n",
    "            virtual_batch_size=self.virtual_batch_size,\n",
    "            drop_last=self.drop_last,\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        return super().predict(X.to_numpy())\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(X.to_numpy())\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return self.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator_TabNet(Estimator):\n",
    "    _estimator = TabNetWrapper\n",
    "    _name = \"TabNet\"\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=True, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        verbose=0,\n",
    "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        scheduler_params=dict(mode=\"min\", min_lr=1e-5, factor=0.5),\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "        cat_emb_dim=1,\n",
    "        max_epochs=50,\n",
    "        eval_metric=\"average_precision\",\n",
    "        weights=1,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.2,\n",
    "        lambda_sparse=8e-4,\n",
    "        mask_type=\"sparsemax\",\n",
    "        n_shared=3,\n",
    "        scheduler_params=dict(patience=5),\n",
    "    )\n",
    "\n",
    "    def __init__(self, sci_train):\n",
    "        self._categorical_idxs, self._categorical_dims = sci_train.describe_categories(\n",
    "            dimensions=True\n",
    "        )\n",
    "\n",
    "    def factory(self):\n",
    "        return self._estimator(\n",
    "            cat_idxs=self._categorical_idxs,\n",
    "            cat_dims=[\n",
    "                _ + 1 for _ in self._categorical_dims\n",
    "            ],  # Because we may add 1 category when we fill_na\n",
    "            **self._static_params,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_steps=trial.suggest_int(f\"{cls._name}__n_steps\", 1, 10),\n",
    "            n_shared=trial.suggest_int(f\"{cls._name}__n_shared\", 1, 10),\n",
    "            gamma=trial.suggest_float(f\"{cls._name}__gamma\", 1, 1.5),\n",
    "            lambda_sparse=trial.suggest_float(\n",
    "                f\"{cls._name}__lambda_sparse\", 1e-6, 1e-3, log=True\n",
    "            ),\n",
    "            mask_type=trial.suggest_categorical(\n",
    "                f\"{cls._name}__mask_type\", [\"entmax\", \"sparsemax\"]\n",
    "            ),\n",
    "            scheduler_params=dict(\n",
    "                patience=trial.suggest_int(f\"{cls._name}__scheduler__patience\", 3, 10)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        n_da = trial.suggest_int(f\"{cls._name}__n_da\", 4, 32,)\n",
    "        suggestions[\"n_d\"], suggestions[\"n_a\"] = n_da, n_da\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        r = {\n",
    "            **cls._static_params,\n",
    "            **cls._tuning_params_default,\n",
    "            **params,\n",
    "            \"scheduler_params\": {\n",
    "                **cls._static_params[\"scheduler_params\"],\n",
    "                **params[\"scheduler_params\"],\n",
    "            },\n",
    "        }\n",
    "        return {f\"{cls._name}__{key}\": value for key, value in r.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_studies(sci_train):\n",
    "    news = SCICols.news_data_raw\n",
    "    news_extended = SCICols.news_data_raw + SCICols.news_data_extras\n",
    "    labs = SCICols.blood\n",
    "    hospital = [\n",
    "        \"AdmissionMethodDescription\",\n",
    "        \"AdmissionSpecialty\",\n",
    "        \"SentToSDEC\",\n",
    "        \"Readmission\",\n",
    "    ]\n",
    "    ae = [\"AandEPresentingComplaint\", \"AandEMainDiagnosis\"]\n",
    "    diagnoses = [_ for _ in sci_train.columns if _.startswith(\"SHMI__\")]\n",
    "    phenotype = [\"Female\", \"Age\"]\n",
    "\n",
    "    return list(\n",
    "        dict(\n",
    "            news=news,\n",
    "            news_extended=news_extended,\n",
    "            news_with_phenotype=news_extended + phenotype,\n",
    "            with_ae_notes=news_extended + phenotype + ae,\n",
    "            with_labs=news_extended + phenotype + labs,\n",
    "            with_notes_and_labs=news_extended + phenotype + ae + labs,\n",
    "            with_hospital=news_extended + phenotype + hospital,\n",
    "            with_notes_and_hospital=news_extended + phenotype + ae + hospital,\n",
    "            with_labs_and_hospital=news_extended + phenotype + labs + hospital,\n",
    "            with_labs_and_diagnoses=news_extended + phenotype + labs + diagnoses,\n",
    "            all=news_extended + phenotype + ae + labs + hospital + diagnoses,\n",
    "        ).items()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_studies(sci_train, study_grid=None, cli_model_arg=None):\n",
    "    estimators = dict(\n",
    "        cpu=[\n",
    "            Estimator_IsolationForest,\n",
    "            Estimator_LightGBM,\n",
    "            Estimator_LogisticRegression,\n",
    "            Estimator_RandomForest,\n",
    "            Estimator_XGBoost,\n",
    "        ],\n",
    "        gpu=[Estimator_TabNet],\n",
    "    )\n",
    "    estimators[\"all\"] = estimators[None] = estimators[\"cpu\"] + estimators[\"gpu\"]\n",
    "    estimators.update({\n",
    "        _._name: [_] for _ in estimators['all']\n",
    "    })\n",
    "\n",
    "    if study_grid is None:\n",
    "        study_grid = dict(\n",
    "            estimator=estimators[cli_model_arg],\n",
    "            resampler=[No_Resampling, Resampler_RandomUnderSampler, Resampler_SMOTE],\n",
    "            features=get_feature_studies(sci_train),\n",
    "        )\n",
    "\n",
    "    k, v = zip(*study_grid.items())\n",
    "    return [dict(zip(k, _)) for _ in itertools.product(*v)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Pipeline(ImbPipeline):\n",
    "    def persist(self, filename):\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "\n",
    "\n",
    "class PipelineFactory:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator: Estimator,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        resampler: Optional[Estimator] = None,\n",
    "    ):\n",
    "        (self._estimator, self._resampler, self._X_train, self._y_train,) = (\n",
    "            estimator,\n",
    "            resampler,\n",
    "            X_train,\n",
    "            y_train,\n",
    "        )\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        steps = [\n",
    "            (self._estimator._name, self._estimator.factory(),),\n",
    "        ]\n",
    "        if self._resampler is not None:\n",
    "            steps = [(self._resampler._name, self._resampler.factory(),),] + steps\n",
    "\n",
    "        return Pipeline(steps=steps).set_params(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "class Objective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator: Estimator,\n",
    "        resampler: Estimator,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"average_precision\",\n",
    "        cv_jobs=1,\n",
    "    ):\n",
    "        (\n",
    "            self._estimator,\n",
    "            self._resampler,\n",
    "            self._X_train,\n",
    "            self._y_train,\n",
    "            self._cv,\n",
    "            self._scoring,\n",
    "            self._cv_jobs,\n",
    "        ) = (\n",
    "            estimator,\n",
    "            resampler,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv,\n",
    "            scoring,\n",
    "            cv_jobs,\n",
    "        )\n",
    "\n",
    "        self._best_score = 0\n",
    "        self._best_model = None\n",
    "\n",
    "        self._pipeline_factory = PipelineFactory(\n",
    "            estimator=self._estimator,\n",
    "            resampler=self._resampler,\n",
    "            X_train=self._X_train,\n",
    "            y_train=self._y_train,\n",
    "        )\n",
    "\n",
    "        self._fit_params = self._estimator.fit_params(self._X_train, self._y_train)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        trial_params = {\n",
    "            **(self._resampler.suggest_parameters(trial) if self._resampler else {}),\n",
    "            **self._estimator.suggest_parameters(trial),\n",
    "        }\n",
    "        model = self._pipeline_factory(**trial_params)\n",
    "\n",
    "        score = cross_validate(\n",
    "            model,\n",
    "            self._X_train,\n",
    "            self._y_train,\n",
    "            cv=self._cv,\n",
    "            scoring=self._scoring,\n",
    "            n_jobs=self._cv_jobs,\n",
    "            fit_params=self._fit_params,\n",
    "        )[\"test_score\"].mean()\n",
    "\n",
    "        if score > self._best_score:\n",
    "            self._best_score = score\n",
    "            self._best_model = self._pipeline_factory(**trial_params).fit(\n",
    "                self._X_train, self._y_train\n",
    "            )\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Iterable, Optional, Tuple\n",
    "\n",
    "\n",
    "def construct_study(\n",
    "    estimator: Estimator,\n",
    "    sci_train: SCIData,\n",
    "    sci_test: SCIData,\n",
    "    features: Tuple[str, Iterable[str]] = (\"All\", []),\n",
    "    resampler: Estimator = None,\n",
    "    cv=5,\n",
    "    scoring=\"average_precision\",\n",
    "    storage=None,\n",
    "    model_persistence_path=None,\n",
    "    cv_jobs=1,\n",
    "    **kwargs,\n",
    "):\n",
    "    sci_args = dict(\n",
    "        x=features[1],\n",
    "        imputation=estimator._requirements[\"imputation\"],\n",
    "        onehot_encoding=estimator._requirements[\"onehot\"],\n",
    "        ordinal_encoding=estimator._requirements[\"ordinal\"],\n",
    "        fillna=estimator._requirements[\"fillna\"],\n",
    "    )\n",
    "    (X_train, y_train), (X_test, y_test) = sci_train.xy(**sci_args), sci_test.xy(**sci_args)\n",
    "\n",
    "    name = f\"{estimator._name}_{resampler._name if resampler else 'None'}_{features[0]}\"\n",
    "    objective = Objective(\n",
    "        estimator=estimator(SCIData(sci_train[features[1]])),\n",
    "        resampler=resampler(SCIData(sci_train[features[1]])),\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        cv_jobs=cv_jobs,\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=name, storage=storage)\n",
    "\n",
    "    def handle_study_result(model_persistence_path=None, n_resamples=99, **kwargs):\n",
    "        model = objective._best_model\n",
    "        if model_persistence_path is not None:\n",
    "            model.persist(f\"{model_persistence_path}/{name}\")\n",
    "\n",
    "        try:\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        except AttributeError:\n",
    "            y_pred_proba = model.decision_function(X_test)\n",
    "            \n",
    "        y_pred = np.where(y_pred_proba > get_threshold_fpr(y_test, y_pred_proba, target=0.05), 1, 0)\n",
    "\n",
    "        metrics = {\n",
    "            **dict(\n",
    "                name=name,\n",
    "                estimator=estimator._name,\n",
    "                resampler=resampler._name,\n",
    "                features=features[0]\n",
    "            ),\n",
    "            **get_metrics(y_test, y_pred, y_pred_proba, n_resamples)\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "        \n",
    "\n",
    "    def call(model_persistence_path=None, n_resamples=99, **kwargs):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            study.optimize(objective, **kwargs)\n",
    "\n",
    "        return handle_study_result(model_persistence_path, n_resamples)\n",
    "\n",
    "    return call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = SCIData(sci_train.head(1000)).xy(imputation=False, fillna=True, onehot_encoding=False, ordinal_encoding=True)\n",
    "# #XX, yy = Resampler_RandomUnderSampler(sci_train).factory().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "# study_grid = dict(\n",
    "#     # estimator=[Estimator_LightGBM, Estimator_IsolationForest, Estimator_LogisticRegression, Estimator_RandomForest, Estimator_TabNet, Estimator_XGBoost],\n",
    "#     estimator=[Estimator_IsolationForest],\n",
    "#     resampler=[No_Resampling, Resampler_SMOTE, Resampler_RandomUnderSampler],\n",
    "#     features=get_feature_studies(sci_train),\n",
    "# )\n",
    "\n",
    "# for _ in get_studies(sci_train, study_grid):\n",
    "#     s = construct_study(**_, sci_train=SCIData(sci_train.head(1000)), sci_test=SCIData(sci_test.head(1000)))\n",
    "\n",
    "#     r = s(n_trials=2)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# studies = [construct_study(**_, sci_train=SCIData(sci_train.head(1000)), sci_test=SCIData(sci_test.head(1000))) for _ in get_studies(sci_train, study_grid)]\n",
    "# with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "#             results = Parallel(n_jobs=1)(\n",
    "#                 delayed(_)(n_trials=2) for _ in studies[:2]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "if SCRIPT:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-m\", \"--models\", help=\"Can be 'all', 'cpu', or 'gpu'\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-j\", \"--njobs\", help=\"Number of CPUs to use. Default=1\", type=int, default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-c\", \"--cv_jobs\", help=\"Number of CV jobs. Default=5\", type=int, default=5\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--persist\",\n",
    "        help=\"Filepath to save the models. If unset, wont save them\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--debug\",\n",
    "        help=\"Whether to only use a small subset of data for debugging\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\", \"--trials\", help=\"Number of trials. Default=1000\", type=int, default=1000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-hr\", \"--hours\", help=\"Trial timeout in hours\", type=int, default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\",\n",
    "        \"--storage\",\n",
    "        help=\"Trial storage for optuna\",\n",
    "        default=\"sqlite:///models/studies.db\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        help='Output path for final results',\n",
    "        default='results.csv'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--n_resamples',\n",
    "        help='Number of resamples for bootstrapping metrics',\n",
    "        default=9999\n",
    "    )\n",
    "    parser.add_argument(\"-v\", \"--verbose\", help=\"Optuna verbosity\", action=\"store_true\")\n",
    "\n",
    "    args = vars(parser.parse_args())\n",
    "else:\n",
    "    args = dict(\n",
    "        models=\"LightGBM\",\n",
    "        njobs=1,\n",
    "        cvjobs=1,\n",
    "        persist=None,\n",
    "        debug=True,\n",
    "        trials=2,\n",
    "        hours=2,\n",
    "        storage=None,\n",
    "        verbose=True,\n",
    "        output='results.csv',\n",
    "        n_resamples=99,\n",
    "    )\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    if args[\"verbose\"]:\n",
    "        optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    if args[\"persist\"] is not None:\n",
    "        try:\n",
    "            os.makedirs(args[\"persist\"])\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "    sci_train_ = sci_train\n",
    "    if args[\"debug\"]:\n",
    "        sci_train_ = SCIData(sci_train.sample(1000))\n",
    "\n",
    "    studies = [\n",
    "        construct_study(**_, **args, sci_train=sci_train_, sci_test=sci_test)\n",
    "        for _ in get_studies(sci_train, cli_model_arg=args[\"models\"])\n",
    "    ]\n",
    "\n",
    "    study_args = dict(\n",
    "        model_persistence_path=args[\"persist\"],\n",
    "        n_resamples=args['n_resamples'],\n",
    "        n_trials=args[\"trials\"] if not args[\"debug\"] else 2,\n",
    "        timeout=args[\"hours\"] * 60 * 60,\n",
    "    )\n",
    "\n",
    "    if args[\"njobs\"] > 1:\n",
    "        print(\"Starting execution (parallel)\")\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=args[\"cv_jobs\"]):\n",
    "            results = Parallel(n_jobs=args[\"njobs\"])(\n",
    "                delayed(_)(**study_args) for _ in studies\n",
    "            )\n",
    "    else:\n",
    "        print(\"Starting execution (linear)\")\n",
    "        results = [_(**study_args) for _ in studies]\n",
    "    \n",
    "    pd.DataFrame(results).to_csv(args['output'])\n",
    "\n",
    "\n",
    "run(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
