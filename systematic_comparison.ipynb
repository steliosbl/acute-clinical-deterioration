{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP Project - Systematic Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings, pickle, os, itertools\n",
    "from dataclasses import dataclass\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "try:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "\n",
    "sci = SCIData.load('data/sci.h5')\n",
    "\n",
    "scii = (\n",
    "    SCIData(SCIData.quickload(\"data/sci_processed.h5\").sort_values(\"AdmissionDateTime\"))\n",
    "    .mandate(SCICols.news_data_raw)\n",
    "    .derive_critical_event(within=1, return_subcols=True)\n",
    "    .augment_shmi(onehot=True)\n",
    "    .omit_redundant()\n",
    "    .raw_news()\n",
    "    .derive_ae_diagnosis_stems(onehot=False)\n",
    "    .categorize()\n",
    "   # .onehot_encode_categories()\n",
    ")\n",
    "\n",
    "sci_train, sci_test, _, y_test_mortality, _, y_test_criticalcare = train_test_split(\n",
    "    scii,\n",
    "    scii.DiedWithinThreshold,\n",
    "    scii.CriticalCare,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "# (X_train, y_train), (X_test, y_test) = (\n",
    "#     sci_train.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "#     sci_test.xy(outcome=\"CriticalEvent\", dropna=False, fillna=False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from typing import Dict, Any, Iterable\n",
    "\n",
    "\n",
    "class Estimator:\n",
    "    _name: str\n",
    "    _estimator: BaseEstimator\n",
    "    _requirements: Dict[str, bool]\n",
    "    _static_params: Dict[str, Any] = {}\n",
    "    _tuning_params_default: Dict[str, Any] = {}\n",
    "    _fit_params: Dict[str, Any] = {}\n",
    "\n",
    "    def __init__(self, sci_train):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        return dict()\n",
    "\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        return {\n",
    "            f\"{cls._name}__{key}\": value\n",
    "            for key, value in {\n",
    "                **cls._static_params,\n",
    "                **cls._tuning_params_default,\n",
    "                **params,\n",
    "            }.items()\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return cls._estimator(**cls._static_params)\n",
    "\n",
    "    @classmethod\n",
    "    def fit_params(cls, X_train, y_train):\n",
    "        return {f\"{cls._name}__{key}\": value for key, value in cls._fit_params.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn import FunctionSampler\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class Resampler(Estimator):\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        return {\n",
    "            f\"{cls._name}__kw_args\": {\n",
    "                **cls._static_params,\n",
    "                **cls._tuning_params_default,\n",
    "                **params,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(\n",
    "            func=partial(SCIData.resample, cls._estimator),\n",
    "            validate=False,\n",
    "            kw_args=cls._static_params,\n",
    "        )\n",
    "\n",
    "\n",
    "class Resampler_SMOTE(Resampler):\n",
    "    _name = \"SMOTE\"\n",
    "    _estimator = SMOTENC\n",
    "\n",
    "    _static_params = dict(random_state=42, n_jobs=None,)\n",
    "\n",
    "    _tuning_params_default = dict(sampling_strategy=0.1, k_neighbors=5)\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            sampling_strategy=trial.suggest_float(\n",
    "                f\"{cls._name}__sampling_strategy\", 0.1, 0.5\n",
    "            ),\n",
    "            k_neighbors=trial.suggest_int(f\"{cls._name}__k_neighbors\", 2, 10),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(\n",
    "            func=SCIData.SMOTE, validate=False, kw_args=cls._static_params\n",
    "        )\n",
    "\n",
    "\n",
    "class Resampler_RandomUnderSampler(Resampler):\n",
    "    _name = \"RandomUnderSampler\"\n",
    "    _estimator = RandomUnderSampler\n",
    "\n",
    "    _static_params = dict(random_state=42, replacement=False)\n",
    "\n",
    "    _tuning_params_default = dict(sampling_strategy=0.1)\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            sampling_strategy=trial.suggest_float(\n",
    "                f\"{cls._name}__sampling_strategy\", 0.05, 0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "\n",
    "class No_Resampling(Resampler):\n",
    "    _name = \"No_Resampling\"\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        return dict()\n",
    "\n",
    "    @staticmethod\n",
    "    def _(X, y):\n",
    "        return X, y\n",
    "\n",
    "    @classmethod\n",
    "    def factory(cls):\n",
    "        return FunctionSampler(func=cls._, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "class Estimator_LightGBM(Estimator):\n",
    "    _name = \"LightGBM\"\n",
    "    _estimator = LGBMClassifier\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=False, imputation=False, fillna=False, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        objective=\"binary\",\n",
    "        metric=[\"l2\", \"auc\"],\n",
    "        boosting_type=\"gbdt\",\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        is_unbalance=True,\n",
    "        reg_alpha=1.8e-3,\n",
    "        reg_lambda=6e-4,\n",
    "        num_leaves=14,\n",
    "        colsample_bytree=0.4,\n",
    "        subsample=0.97,\n",
    "        subsample_freq=1,\n",
    "        min_child_samples=6,\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            reg_alpha=trial.suggest_float(\n",
    "                f\"{cls._name}__reg_alpha\", 1e-4, 10.0, log=True\n",
    "            ),\n",
    "            reg_lambda=trial.suggest_float(\n",
    "                f\"{cls._name}__reg_lambda\", 1e-4, 10.0, log=True\n",
    "            ),\n",
    "            num_leaves=trial.suggest_int(f\"{cls._name}__num_leaves\", 2, 256),\n",
    "            colsample_bytree=trial.suggest_float(\n",
    "                f\"{cls._name}__colsample_bytree\", 0.4, 1.0\n",
    "            ),\n",
    "            subsample=trial.suggest_float(f\"{cls._name}__subsample\", 0.4, 1.0),\n",
    "            subsample_freq=trial.suggest_int(f\"{cls._name}__subsample_freq\", 1, 7),\n",
    "            min_child_samples=trial.suggest_int(\n",
    "                f\"{cls._name}__min_child_samples\", 5, 150\n",
    "            ),\n",
    "            is_unbalance=trial.suggest_categorical(\n",
    "                f\"{cls._name}__is_unbalance\", [True, False]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if not suggestions[\"is_unbalance\"]:\n",
    "            suggestions[\"scale_pos_weight\"] = trial.suggest_int(\n",
    "                f\"{cls._name}__scale_pos_weight\", 1, 100\n",
    "            )\n",
    "\n",
    "        r = cls.compile_parameters(suggestions)\n",
    "        if not suggestions[\"is_unbalance\"]:\n",
    "            del r[f\"{cls._name}__is_unbalance\"]\n",
    "\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "class Estimator_XGBoost(Estimator):\n",
    "    _name = \"XGBoost\"\n",
    "    _estimator = XGBClassifier\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=False, imputation=False, fillna=False, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        verbosity=0,\n",
    "        n_jobs=1,\n",
    "        objective=\"binary:logistic\",\n",
    "        booster=\"gbtree\",\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = {\n",
    "        **dict(\n",
    "            tree_method=\"hist\",\n",
    "            alpha=7e-05,\n",
    "            subsample=0.42,\n",
    "            colsample_bytree=0.87,\n",
    "            scale_pos_weight=14,\n",
    "            max_depth=7,\n",
    "            min_child_weight=10,\n",
    "            eta=0.035,\n",
    "            gamma=4e-08,\n",
    "            grow_policy=\"lossguide\",\n",
    "        ),\n",
    "        \"lambda\": 7e-2,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            tree_method=trial.suggest_categorical(\n",
    "                f\"{cls._name}__tree_method\", [\"approx\", \"hist\"]\n",
    "            ),\n",
    "            alpha=trial.suggest_float(f\"{cls._name}__alpha\", 1e-8, 1.0, log=True),\n",
    "            subsample=trial.suggest_float(f\"{cls._name}__subsample\", 0.2, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\n",
    "                f\"{cls._name}__colsample_bytree\", 0.2, 1.0\n",
    "            ),\n",
    "            scale_pos_weight=trial.suggest_int(\n",
    "                f\"{cls._name}__scale_pos_weight\", 1, 100\n",
    "            ),\n",
    "            max_depth=trial.suggest_int(f\"{cls._name}__max_depth\", 3, 9, step=2),\n",
    "            min_child_weight=trial.suggest_int(f\"{cls._name}__min_child_weight\", 2, 10),\n",
    "            eta=trial.suggest_float(f\"{cls._name}__eta\", 1e-8, 1.0, log=True),\n",
    "            gamma=trial.suggest_float(f\"{cls._name}__gamma\", 1e-8, 1.0, log=True),\n",
    "            grow_policy=trial.suggest_categorical(\n",
    "                f\"{cls._name}__grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "            ),\n",
    "        )\n",
    "        suggestions[\"lambda\"] = trial.suggest_float(\n",
    "            f\"{cls._name}__lambda\", 1e-8, 1.0, log=True\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class Estimator_LogisticRegression(Estimator):\n",
    "    _name = \"LogisticRegression\"\n",
    "    _estimator = LogisticRegression\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=True, ordinal=False, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(max_iter=100, solver=\"lbfgs\", random_state=42, penalty=\"l2\")\n",
    "\n",
    "    _tuning_params_default = dict(penalty=\"l2\", C=5.9, class_weight=\"balanced\")\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            penalty=trial.suggest_categorical(f\"{cls._name}__penalty\", [\"l2\", \"none\"]),\n",
    "            C=trial.suggest_float(f\"{cls._name}__C\", 0.01, 10),\n",
    "            class_weight=trial.suggest_categorical(\n",
    "                f\"{cls._name}__class_weight\", [None, \"balanced\"]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # if suggestions[\"penalty\"] == \"elasticnet\":\n",
    "        #     suggestions[\"l1_ratio\"] = trial.suggest_float(\n",
    "        #         f\"{cls._name}__l1_ratio\", 0.05, 0.95\n",
    "        #     )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class Estimator_RandomForest(Estimator):\n",
    "    _estimator = RandomForestClassifier\n",
    "    _name = \"RandomForest\"\n",
    "\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=True, imputation=False, fillna=True, resampling=False\n",
    "    )\n",
    "    _tuning_params_default = dict(\n",
    "        n_estimators=250,\n",
    "        max_features=0.56,\n",
    "        min_samples_split=8,\n",
    "        min_samples_leaf=3,\n",
    "        max_samples=0.75,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_estimators=trial.suggest_int(f\"{cls._name}__n_estimators\", 25, 250),\n",
    "            max_features=trial.suggest_float(f\"{cls._name}__max_features\", 0.15, 1.0),\n",
    "            min_samples_split=trial.suggest_int(\n",
    "                f\"{cls._name}__min_samples_split\", 2, 15\n",
    "            ),\n",
    "            min_samples_leaf=trial.suggest_int(f\"{cls._name}__min_samples_leaf\", 1, 15),\n",
    "            max_samples=trial.suggest_float(f\"{cls._name}__max_samples\", 0.5, 0.99),\n",
    "            class_weight=trial.suggest_categorical(\n",
    "                f\"{cls._name}__class_weight\", [None, \"balanced\", \"balanced_subsample\"]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.isolation_forest_wrapper import IsolationForestWrapper\n",
    "\n",
    "\n",
    "class Estimator_IsolationForest(Estimator):\n",
    "    _name = \"IsolationForest\"\n",
    "    _estimator = IsolationForestWrapper\n",
    "    _requirements = dict(\n",
    "        onehot=True, ordinal=False, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        n_estimators=140,\n",
    "        max_samples=0.45,\n",
    "        contamination=0.02,\n",
    "        max_features=0.69,\n",
    "        bootstrap=False,\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_estimators=trial.suggest_int(f\"{cls._name}__n_estimators\", 1, 200),\n",
    "            max_samples=trial.suggest_float(f\"{cls._name}__max_samples\", 0.0, 1.0),\n",
    "            contamination=trial.suggest_float(\n",
    "                f\"{cls._name}__contamination\", 1e-6, 1e-1\n",
    "            ),\n",
    "            max_features=trial.suggest_float(f\"{cls._name}__max_features\", 0.0, 1.0),\n",
    "            bootstrap=trial.suggest_categorical(\n",
    "                f\"{cls._name}__bootstrap\", [True, False]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TabNetWrapper(TabNetClassifier):\n",
    "    weights: int = 0\n",
    "    max_epochs: int = 100\n",
    "    patience: int = 10\n",
    "    batch_size: int = 1024\n",
    "    virtual_batch_size: int = 128\n",
    "    drop_last: bool = True\n",
    "    eval_metric: str = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return super().fit(\n",
    "            X_train=X.to_numpy(),\n",
    "            y_train=y.to_numpy(),\n",
    "            eval_metric=self.eval_metric,\n",
    "            weights=self.weights,\n",
    "            max_epochs=self.max_epochs,\n",
    "            patience=self.patience,\n",
    "            batch_size=self.batch_size,\n",
    "            virtual_batch_size=self.virtual_batch_size,\n",
    "            drop_last=self.drop_last,\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        return super().predict(X.to_numpy())\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(X.to_numpy())\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return self.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator_TabNet(Estimator):\n",
    "    _estimator = TabNetWrapper\n",
    "    _name = \"TabNet\"\n",
    "    _requirements = dict(\n",
    "        onehot=False, ordinal=True, imputation=True, fillna=True, resampling=False\n",
    "    )\n",
    "\n",
    "    _static_params = dict(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        verbose=0,\n",
    "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        scheduler_params=dict(mode=\"min\", min_lr=1e-5, factor=0.5),\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "        cat_emb_dim=1,\n",
    "        max_epochs=50,\n",
    "        eval_metric=\"average_precision\",\n",
    "        weights=1,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    _tuning_params_default = dict(\n",
    "        n_d=8,\n",
    "        n_a=8,\n",
    "        n_steps=3,\n",
    "        gamma=1.2,\n",
    "        lambda_sparse=8e-4,\n",
    "        mask_type=\"sparsemax\",\n",
    "        n_shared=3,\n",
    "        scheduler_params=dict(patience=5),\n",
    "    )\n",
    "\n",
    "    def __init__(self, sci_train):\n",
    "        self._categorical_idxs, self._categorical_dims = sci_train.describe_categories(\n",
    "            dimensions=True\n",
    "        )\n",
    "\n",
    "    def factory(self):\n",
    "        return self._estimator(\n",
    "            cat_idxs=self._categorical_idxs,\n",
    "            cat_dims=[\n",
    "                _ + 1 for _ in self._categorical_dims\n",
    "            ],  # Because we may add 1 category when we fill_na\n",
    "            **self._static_params,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def suggest_parameters(cls, trial):\n",
    "        suggestions = dict(\n",
    "            n_steps=trial.suggest_int(f\"{cls._name}__n_steps\", 1, 10),\n",
    "            n_shared=trial.suggest_int(f\"{cls._name}__n_shared\", 1, 10),\n",
    "            gamma=trial.suggest_float(f\"{cls._name}__gamma\", 1, 1.5),\n",
    "            lambda_sparse=trial.suggest_float(\n",
    "                f\"{cls._name}__lambda_sparse\", 1e-6, 1e-3, log=True\n",
    "            ),\n",
    "            mask_type=trial.suggest_categorical(\n",
    "                f\"{cls._name}__mask_type\", [\"entmax\", \"sparsemax\"]\n",
    "            ),\n",
    "            scheduler_params=dict(\n",
    "                patience=trial.suggest_int(f\"{cls._name}__scheduler__patience\", 3, 10)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        n_da = trial.suggest_int(f\"{cls._name}__n_da\", 4, 32,)\n",
    "        suggestions[\"n_d\"], suggestions[\"n_a\"] = n_da, n_da\n",
    "\n",
    "        return cls.compile_parameters(suggestions)\n",
    "\n",
    "    @classmethod\n",
    "    def compile_parameters(cls, params):\n",
    "        r = {\n",
    "            **cls._static_params,\n",
    "            **cls._tuning_params_default,\n",
    "            **params,\n",
    "            \"scheduler_params\": {\n",
    "                **cls._static_params[\"scheduler_params\"],\n",
    "                **params[\"scheduler_params\"],\n",
    "            },\n",
    "        }\n",
    "        return {f\"{cls._name}__{key}\": value for key, value in r.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_studies(sci_train):\n",
    "    news = SCICols.news_data_raw\n",
    "    news_extended = SCICols.news_data_raw + SCICols.news_data_extras\n",
    "    labs = SCICols.blood\n",
    "    hospital = [\n",
    "        \"AdmissionMethodDescription\",\n",
    "        \"AdmissionSpecialty\",\n",
    "        \"SentToSDEC\",\n",
    "        \"Readmission\",\n",
    "    ]\n",
    "    ae = [\"AandEPresentingComplaint\", \"AandEMainDiagnosis\"]\n",
    "    diagnoses = [_ for _ in sci_train.columns if _.startswith(\"SHMI__\")]\n",
    "    phenotype = [\"Female\", \"Age\"]\n",
    "\n",
    "    return list(\n",
    "        dict(\n",
    "            news=news,\n",
    "            news_extended=news_extended,\n",
    "            news_with_phenotype=news_extended + phenotype,\n",
    "            with_ae_notes=news_extended + phenotype + ae,\n",
    "            with_labs=news_extended + phenotype + labs,\n",
    "            with_notes_and_labs=news_extended + phenotype + ae + labs,\n",
    "            with_hospital=news_extended + phenotype + hospital,\n",
    "            with_notes_and_hospital=news_extended + phenotype + ae + hospital,\n",
    "            with_labs_and_hospital=news_extended + phenotype + labs + hospital,\n",
    "            with_labs_and_diagnoses=news_extended + phenotype + labs + diagnoses,\n",
    "            all=news_extended + phenotype + ae + labs + hospital + diagnoses,\n",
    "        ).items()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_studies(sci_train, study_grid=None, cli_model_arg=None):\n",
    "    estimators = dict(\n",
    "        cpu=[\n",
    "            Estimator_IsolationForest,\n",
    "            Estimator_LightGBM,\n",
    "            Estimator_LogisticRegression,\n",
    "            Estimator_RandomForest,\n",
    "            Estimator_XGBoost,\n",
    "        ],\n",
    "        gpu=[Estimator_TabNet],\n",
    "    )\n",
    "    estimators[\"all\"] = estimators[None] = estimators[\"cpu\"] + estimators[\"gpu\"]\n",
    "\n",
    "    if study_grid is None:\n",
    "        study_grid = dict(\n",
    "            estimator=estimators[cli_model_arg],\n",
    "            resampler=[No_Resampling, Resampler_RandomUnderSampler, Resampler_SMOTE],\n",
    "            features=get_feature_studies(sci_train),\n",
    "        )\n",
    "\n",
    "    k, v = zip(*study_grid.items())\n",
    "    return [dict(zip(k, _)) for _ in itertools.product(*v)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Pipeline(ImbPipeline):\n",
    "    def persist(self, filename):\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "\n",
    "\n",
    "class PipelineFactory:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator: Estimator,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        resampler: Optional[Estimator] = None,\n",
    "    ):\n",
    "        (self._estimator, self._resampler, self._X_train, self._y_train,) = (\n",
    "            estimator,\n",
    "            resampler,\n",
    "            X_train,\n",
    "            y_train,\n",
    "        )\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        steps = [\n",
    "            (self._estimator._name, self._estimator.factory(),),\n",
    "        ]\n",
    "        if self._resampler is not None:\n",
    "            steps = [(self._resampler._name, self._resampler.factory(),),] + steps\n",
    "\n",
    "        return Pipeline(steps=steps).set_params(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "class Objective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator: Estimator,\n",
    "        resampler: Estimator,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"average_precision\",\n",
    "        persist_model=True,\n",
    "        cv_jobs=1,\n",
    "    ):\n",
    "        (\n",
    "            self._estimator,\n",
    "            self._resampler,\n",
    "            self._X_train,\n",
    "            self._y_train,\n",
    "            self._cv,\n",
    "            self._scoring,\n",
    "            self._persist_model,\n",
    "            self._cv_jobs,\n",
    "        ) = (\n",
    "            estimator,\n",
    "            resampler,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv,\n",
    "            scoring,\n",
    "            persist_model,\n",
    "            cv_jobs,\n",
    "        )\n",
    "\n",
    "        self._best_score = 0\n",
    "        self._best_model = None\n",
    "\n",
    "        self._pipeline_factory = PipelineFactory(\n",
    "            estimator=self._estimator,\n",
    "            resampler=self._resampler,\n",
    "            X_train=self._X_train,\n",
    "            y_train=self._y_train,\n",
    "        )\n",
    "\n",
    "        self._fit_params = self._estimator.fit_params(self._X_train, self._y_train)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        trial_params = {\n",
    "            **(self._resampler.suggest_parameters(trial) if self._resampler else {}),\n",
    "            **self._estimator.suggest_parameters(trial),\n",
    "        }\n",
    "        model = self._pipeline_factory(**trial_params)\n",
    "\n",
    "        score = cross_validate(\n",
    "            model,\n",
    "            self._X_train,\n",
    "            self._y_train,\n",
    "            cv=self._cv,\n",
    "            scoring=self._scoring,\n",
    "            n_jobs=self._cv_jobs,\n",
    "            fit_params=self._fit_params,\n",
    "        )[\"test_score\"].mean()\n",
    "\n",
    "        if self._persist_model and (score > self._best_score):\n",
    "            self._best_score = score\n",
    "            self._best_model = self._pipeline_factory(**trial_params).fit(\n",
    "                self._X_train, self._y_train\n",
    "            )\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Iterable, Optional, Tuple\n",
    "\n",
    "\n",
    "def construct_study(\n",
    "    estimator: Estimator,\n",
    "    sci_train: SCIData,\n",
    "    sci_test: SCIData,\n",
    "    features: Tuple[str, Iterable[str]] = (\"All\", []),\n",
    "    resampler: Estimator = None,\n",
    "    cv=5,\n",
    "    scoring=\"average_precision\",\n",
    "    storage=None,\n",
    "    persist=None,\n",
    "    cv_jobs=1,\n",
    "    **kwargs,\n",
    "):\n",
    "    X_train, y_train = sci_train.xy(\n",
    "        x=features[1],\n",
    "        imputation=estimator._requirements[\"imputation\"],\n",
    "        onehot_encoding=estimator._requirements[\"onehot\"],\n",
    "        ordinal_encoding=estimator._requirements[\"ordinal\"],\n",
    "        fillna=estimator._requirements[\"fillna\"],\n",
    "    )\n",
    "\n",
    "    name = f\"{estimator._name}_{resampler._name if resampler else 'None'}_{features[0]}\"\n",
    "    objective = Objective(\n",
    "        estimator=estimator(SCIData(sci_train[features[1]])),\n",
    "        resampler=resampler(SCIData(sci_train[features[1]])),\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        persist_model=persist is not None,\n",
    "        cv_jobs=cv_jobs,\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=name, storage=storage)\n",
    "\n",
    "    def call(persist=None, **kwargs):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            study.optimize(objective, **kwargs)\n",
    "\n",
    "        if persist is not None:\n",
    "            objective._best_model.persist(f\"{persist}/{name}\")\n",
    "\n",
    "        return objective._best_model\n",
    "\n",
    "    return call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = SCIData(sci_train.head(1000)).xy(imputation=False, fillna=False, onehot_encoding=False, ordinal_encoding=False)\n",
    "# XX, yy = Resampler_RandomUnderSampler(sci_train).factory().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_grid = dict(\n",
    "    # estimator=[Estimator_LightGBM, Estimator_IsolationForest, Estimator_LogisticRegression, Estimator_RandomForest, Estimator_TabNet, Estimator_XGBoost],\n",
    "    estimator=[Estimator_LightGBM],\n",
    "    resampler=[No_Resampling, Resampler_SMOTE, Resampler_RandomUnderSampler],\n",
    "    features=get_feature_studies(sci_train),\n",
    ")\n",
    "\n",
    "for _ in get_studies(sci_train, study_grid):\n",
    "    s = construct_study(**_, sci_train=SCIData(sci_train.head(1000)), sci_test=sci_test)\n",
    "\n",
    "    r = s(n_trials=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-02 11:08:17,341]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,358]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,378]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,407]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,424]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,453]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,480]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,518]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,546]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,584]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,646]\u001b[0m A new study created in memory with name: IsolationForest_No_Resampling_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,660]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,676]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,694]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,722]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,742]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,771]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,807]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,845]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,873]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:17,918]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,006]\u001b[0m A new study created in memory with name: IsolationForest_RandomUnderSampler_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,020]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,041]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,063]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,102]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,119]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,149]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,175]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,214]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,242]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,278]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,339]\u001b[0m A new study created in memory with name: IsolationForest_SMOTE_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,342]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,347]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,354]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,360]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,367]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,375]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,381]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,389]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,396]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,421]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,446]\u001b[0m A new study created in memory with name: LightGBM_No_Resampling_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,450]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,455]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,461]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,468]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,475]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,483]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,490]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,498]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,506]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,530]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,554]\u001b[0m A new study created in memory with name: LightGBM_RandomUnderSampler_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,559]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,566]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,573]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,580]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,587]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,595]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,603]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,613]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,620]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,643]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,668]\u001b[0m A new study created in memory with name: LightGBM_SMOTE_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,683]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,709]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,726]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,752]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,773]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,809]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,836]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,876]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,904]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:18,944]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,010]\u001b[0m A new study created in memory with name: LogisticRegression_No_Resampling_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,028]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,045]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,063]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,093]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,111]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,141]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,170]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,209]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,246]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,295]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,375]\u001b[0m A new study created in memory with name: LogisticRegression_RandomUnderSampler_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,394]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,413]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,435]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,461]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,480]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,509]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,539]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,573]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,599]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,635]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,698]\u001b[0m A new study created in memory with name: LogisticRegression_SMOTE_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,703]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,710]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,718]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,727]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,735]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,747]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,758]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,770]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,781]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,809]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,838]\u001b[0m A new study created in memory with name: RandomForest_No_Resampling_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,844]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,851]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,859]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,872]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,883]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,894]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,904]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,917]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,930]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:19,969]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,003]\u001b[0m A new study created in memory with name: RandomForest_RandomUnderSampler_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,008]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,017]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,024]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,033]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,042]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,055]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,066]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,078]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,090]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,115]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,142]\u001b[0m A new study created in memory with name: RandomForest_SMOTE_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,147]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,152]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,159]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,166]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,175]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,183]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,191]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,198]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,206]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,242]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,269]\u001b[0m A new study created in memory with name: XGBoost_No_Resampling_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,274]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,279]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,285]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,294]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,304]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,312]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,319]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,329]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,338]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,359]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,389]\u001b[0m A new study created in memory with name: XGBoost_RandomUnderSampler_all\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,394]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_news\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,400]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_news_extended\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,406]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_news_with_phenotype\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,414]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_ae_notes\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,424]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,434]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_notes_and_labs\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,443]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,455]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_notes_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,465]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_labs_and_hospital\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,499]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_with_labs_and_diagnoses\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:20,533]\u001b[0m A new study created in memory with name: XGBoost_SMOTE_all\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution (linear)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-02 11:08:20,949]\u001b[0m Trial 0 finished with value: 0.20446343415829218 and parameters: {'IsolationForest__n_estimators': 40, 'IsolationForest__max_samples': 0.08822531200379968, 'IsolationForest__contamination': 0.08103596320467027, 'IsolationForest__max_features': 0.392320924409435, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.20446343415829218.\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:22,317]\u001b[0m Trial 1 finished with value: 0.1917243487408843 and parameters: {'IsolationForest__n_estimators': 164, 'IsolationForest__max_samples': 0.015555377198114395, 'IsolationForest__contamination': 0.06637270738034899, 'IsolationForest__max_features': 0.5880126057173825, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.20446343415829218.\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:23,439]\u001b[0m Trial 0 finished with value: 0.1688969060234958 and parameters: {'IsolationForest__n_estimators': 130, 'IsolationForest__max_samples': 0.0643517066961713, 'IsolationForest__contamination': 0.04216302079362879, 'IsolationForest__max_features': 0.2722697801988049, 'IsolationForest__bootstrap': True}. Best is trial 0 with value: 0.1688969060234958.\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:23,848]\u001b[0m Trial 1 finished with value: 0.1827227553517771 and parameters: {'IsolationForest__n_estimators': 42, 'IsolationForest__max_samples': 0.9857344799919224, 'IsolationForest__contamination': 0.03382803273980313, 'IsolationForest__max_features': 0.1930012189614777, 'IsolationForest__bootstrap': False}. Best is trial 1 with value: 0.1827227553517771.\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:24,808]\u001b[0m Trial 0 finished with value: 0.291013398035984 and parameters: {'IsolationForest__n_estimators': 98, 'IsolationForest__max_samples': 0.6722912842463269, 'IsolationForest__contamination': 0.07909576046620274, 'IsolationForest__max_features': 0.3537457296816001, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.291013398035984.\u001b[0m\n",
      "\u001b[32m[I 2022-11-02 11:08:25,517]\u001b[0m Trial 1 finished with value: 0.21308118173952845 and parameters: {'IsolationForest__n_estimators': 71, 'IsolationForest__max_samples': 0.34033725719871755, 'IsolationForest__contamination': 0.004151212546131689, 'IsolationForest__max_features': 0.6689265124771121, 'IsolationForest__bootstrap': False}. Best is trial 0 with value: 0.291013398035984.\u001b[0m\n",
      "\u001b[33m[W 2022-11-02 11:08:26,167]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\stybl\\AppData\\Local\\Temp\\ipykernel_10880\\1511633633.py\", line 45, in __call__\n",
      "    score = cross_validate(\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\imblearn\\pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py\", line 306, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 434, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 138, in _parallel_build_estimators\n",
      "    estimator_fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 458, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  Input In [60] in <cell line: 92>\n    run(args)\n",
      "  Input In [60] in run\n    _(**study_args)\n",
      "  Input In [49] in call\n    study.optimize(objective, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\study.py:419 in optimize\n    _optimize(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\_optimize.py:66 in _optimize\n    _optimize_sequential(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\_optimize.py:160 in _optimize_sequential\n    frozen_trial = _run_trial(study, func, catch)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\_optimize.py:234 in _run_trial\n    raise func_err\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\optuna\\study\\_optimize.py:196 in _run_trial\n    value_or_values = func(trial)\n",
      "  Input In [44] in __call__\n    score = cross_validate(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266 in cross_validate\n    results = parallel(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:1046 in __call__\n    while self.dispatch_one_batch(iterator):\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:861 in dispatch_one_batch\n    self._dispatch(tasks)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:779 in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py:208 in apply_async\n    result = ImmediateResult(func)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py:572 in __init__\n    self.results = batch()\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:262 in __call__\n    return [func(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:262 in <listcomp>\n    return [func(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\fixes.py:117 in __call__\n    return self.function(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686 in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\imblearn\\pipeline.py:281 in fit\n    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:306 in fit\n    super()._fit(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:434 in _fit\n    all_results = Parallel(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:1043 in __call__\n    if self.dispatch_one_batch(iterator):\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:861 in dispatch_one_batch\n    self._dispatch(tasks)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:779 in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py:208 in apply_async\n    result = ImmediateResult(func)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\_parallel_backends.py:572 in __init__\n    self.results = batch()\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:262 in __call__\n    return [func(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\joblib\\parallel.py:262 in <listcomp>\n    return [func(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\fixes.py:117 in __call__\n    return self.function(*args, **kwargs)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:138 in _parallel_build_estimators\n    estimator_fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342 in fit\n    super().fit(\n",
      "  File c:\\Users\\stybl\\miniconda3\\envs\\py39\\lib\\site-packages\\sklearn\\tree\\_classes.py:458 in fit\n    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "if SCRIPT:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-m\", \"--models\", help=\"Can be 'all', 'cpu', or 'gpu'\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-j\", \"--njobs\", help=\"Number of CPUs to use. Default=1\", type=int, default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-c\", \"--cv_jobs\", help=\"Number of CV jobs. Default=5\", type=int, default=5\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--persist\",\n",
    "        help=\"Filepath to save the models. If unset, wont save them\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--debug\",\n",
    "        help=\"Whether to only use a small subset of data for debugging\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\", \"--trials\", help=\"Number of trials. Default=1000\", type=int, default=100\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-hr\", \"--hours\", help=\"Trial timeout in hours\", type=int, default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\",\n",
    "        \"--storage\",\n",
    "        help=\"Trial storage for optuna\",\n",
    "        default=None #\"sqlite:///models/studies.db\",\n",
    "    )\n",
    "    parser.add_argument(\"-v\", \"--verbose\", help=\"Optuna verbosity\", action=\"store_true\")\n",
    "\n",
    "    args = vars(parser.parse_args())\n",
    "else:\n",
    "    args = dict(\n",
    "        models=\"cpu\",\n",
    "        njobs=1,\n",
    "        cvjobs=5,\n",
    "        persist=None,\n",
    "        debug=True,\n",
    "        trials=100,\n",
    "        hours=2,\n",
    "        storage=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    if args[\"verbose\"]:\n",
    "        optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    if args[\"persist\"] is not None:\n",
    "        try:\n",
    "            os.makedirs(persist)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "    sci_train_ = sci_train\n",
    "    if args[\"debug\"]:\n",
    "        sci_train_ = SCIData(sci_train.sample(1000))\n",
    "\n",
    "    studies = [\n",
    "        construct_study(**_, **args, sci_train=sci_train_, sci_test=sci_test)\n",
    "        for _ in get_studies(sci_train, cli_model_arg=args[\"models\"])\n",
    "    ]\n",
    "\n",
    "    study_args = dict(\n",
    "        persist=args[\"persist\"],\n",
    "        n_trials=args[\"trials\"] if not args[\"debug\"] else 2,\n",
    "        timeout=args[\"hours\"] * 60 * 60,\n",
    "    )\n",
    "\n",
    "    if args[\"njobs\"] > 1:\n",
    "        print(\"Starting execution (parallel)\")\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=args[\"cv_jobs\"]):\n",
    "            results = Parallel(n_jobs=args[\"njobs\"])(\n",
    "                delayed(_)(**study_args) for _ in studies\n",
    "            )\n",
    "    else:\n",
    "        print(\"Starting execution (linear)\")\n",
    "        for _ in studies:\n",
    "            _(**study_args)\n",
    "\n",
    "\n",
    "run(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
