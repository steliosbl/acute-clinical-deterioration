{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Preprocessing\n",
    "\n",
    "Cleans up and exports the original ACP dataset files into HDF5-compressed Pandas DataFrames.\n",
    "\n",
    "AEData:\n",
    " - Raw data must be unzipped into a directory.\n",
    " - Default path for the raw data is `data/AEdata`. This can be modified from the `Notebook` class.\n",
    "\n",
    "ICD10: \n",
    " - Original spreadsheet for ICD-10 (March 2021) can be found [here](https://www.health.gov.za/icd-10-master-industry-table/).\n",
    " - This should be placed in the `data/ICD10` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    RAW_DIR = Path(\"data/AEdata\")\n",
    "\n",
    "    RUN_ALL = False\n",
    "\n",
    "    # Enable ONLY if running as a script\n",
    "    MULTITHREADING = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_per_dtype(df):\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in df.dtypes.iteritems():\n",
    "        new_dict[v].append(k)\n",
    "    for k in new_dict.keys():\n",
    "        print(f\"{k}: {new_dict[k]}\")\n",
    "\n",
    "\n",
    "def col_counts_topn(df, n=10):\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in col_counts.items():\n",
    "        new_dict[v.size].append(k)\n",
    "    for k in sorted(new_dict.keys())[:n]:\n",
    "        print(f\"{k}: {new_dict[k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Dates File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_correct_strings(df: pd.DataFrame):\n",
    "    string_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[string_cols] = df[string_cols].applymap(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eddates(df: pd.DataFrame):\n",
    "    # Manual Correction: The first ArrivalDtm column has values in\n",
    "    # excel-style integer format (see https://stackoverflow.com/a/65460255/7662085)\n",
    "    if df.ArrivalDtm.dtype != np.dtype(\"datetime64[ns]\"):\n",
    "        df[\"ArrivalDtm\"] = pd.to_datetime(df.ArrivalDtm, unit=\"D\", origin=\"1899-12-30\")\n",
    "\n",
    "    # Iterate columns pairwise, and stack them vertically into a single DF\n",
    "    return pd.DataFrame(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                df[list(_)].dropna().values\n",
    "                for _ in zip(df.columns[::3], df.columns[1::3])\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"AESerial\", \"ArrivalDtm\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_mainfiledates(df: pd.DataFrame):\n",
    "    return hdf5_correct_strings(df)\n",
    "\n",
    "\n",
    "def convert_event_dates(infile=\"Each event dateDONE.xlsx\", outfile=\"event_dates.h5\"):\n",
    "    result = {}\n",
    "\n",
    "    xlsx = pd.ExcelFile(Notebook.RAW_DIR / infile)\n",
    "    convert_sheets = {\n",
    "        \"EDDATES\": convert_eddates,\n",
    "        \"MainFileDates\": convert_mainfiledates,\n",
    "    }\n",
    "\n",
    "    for sheet, converter in convert_sheets.items():\n",
    "        result[sheet] = converter(pd.read_excel(xlsx, sheet, index_col=None))\n",
    "\n",
    "    with pd.HDFStore(Notebook.DATA_DIR / outfile) as store:\n",
    "        for name, df in result.items():\n",
    "            store[name] = df\n",
    "\n",
    "    return result.values()\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    convert_event_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCI File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SCI(xlsx):\n",
    "    df = xlsx.copy()\n",
    "\n",
    "    # Drop redundant columns\n",
    "    redundant = (\n",
    "        [\n",
    "            \"Admission FY Month\",\n",
    "            \"Year Admit\",\n",
    "            \"Month Admit\",\n",
    "            \"Admit Hour\",\n",
    "            \"Admit Week\",\n",
    "            \"Year Disch\",\n",
    "            \"Month Disch\",\n",
    "            \"Disch Hour\",\n",
    "            \"Disch Week\",\n",
    "            \"Admission Fy Year\",\n",
    "            \"Admit Day\",\n",
    "            \"Discharge Fy Year\",\n",
    "            \"Disch Day\",\n",
    "        ]\n",
    "        + [\"Admission Consultant\", \"Last Consultant\", \"Area\", \"GP Practice\", \"PCT\"]\n",
    "        + [\"Admissions Date\", \"Admission Date\", \"aLT Client GUID\", \"Client GUID\"]\n",
    "    )\n",
    "    df = df.drop(redundant, axis=1)\n",
    "\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "\n",
    "    # Drop c_ prefixed columns with no values in them\n",
    "    df = df.drop(\n",
    "        [\n",
    "            col\n",
    "            for col, count in col_counts.items()\n",
    "            if count.size <= 2 and col.startswith(\"c_\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Replace NoNSw2d with np.NAN in all applicable columns\n",
    "    df = df.replace({\"NoNSw2d\": np.NAN, \"NoObW2D\": np.NAN, \"Noobw2d\": np.NAN})\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"Admission Type\": \"Elective\",\n",
    "        \"Admission Area\": \"Medical Assessment Area\",\n",
    "        \"Discharge Area\": \"Assessment Area Discharge\",\n",
    "        \"c_Nausea\": \"1 - Nausea present\",\n",
    "        \"c_Vomiting\": \"1 - Vomiting since last round\",\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over 7 Days\",\n",
    "                \"Over 14 Days\",\n",
    "                \"Care Home\",\n",
    "                \"Died During Stay\",\n",
    "                \"Died Within 30 Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__).apply(lambda x: np.nan if x == NotImplemented else x)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"Admission Type\": \"ElectiveAdmission\",\n",
    "            \"Admission Area\": \"AssessmentAreaAdmission\",\n",
    "            \"Discharge Area\": \"AssessmentAreaDischarge\",\n",
    "            \"c_Vomiting\": \"c_Vomiting_since_last_round\",\n",
    "            \"Spell Discharge Date\": \"DischargeDateTime\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert NEWS dates\n",
    "    datetimes = [\"News CreatedWhen\", \"News TouchedWhen\", \"News AuthoredDtm\"]\n",
    "    df[datetimes] = df[datetimes].apply(pd.to_datetime, errors=\"coerce\")\n",
    "\n",
    "    # Convert blood results\n",
    "    # Ignore certain non-numeric entries as they make up less than 0.001%\n",
    "    numeric = [\n",
    "        \"Urea (serum)\",\n",
    "        \"Sodium (serum)\",\n",
    "        \"Potassium (serum)\",\n",
    "        \"Creatinine\",\n",
    "        \"pO2 (POC) Venous\",\n",
    "    ]\n",
    "    df[numeric] = df[numeric].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Remove spaces from column names\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "\n",
    "    # Drop duplicates based on serial code\n",
    "    df = df.sort_values('SEQ', ascending=False).drop_duplicates(\"SpellSerial\")\n",
    "\n",
    "    df = df.replace('nan', np.nan)\n",
    "\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 13:00:58,159 [INFO] Reading file: data\\AEdata\\Copy of SCI11868 Delivered 7 Ian Browne.xlsx\n",
      "2022-07-22 13:06:09,583 [INFO] Processing file: data\\AEdata\\Copy of SCI11868 Delivered 7 Ian Browne.xlsx\n",
      "2022-07-22 13:06:18,308 [INFO] Writing to: data\\sci.h5/table\n",
      "C:\\Users\\stybl\\AppData\\Local\\Temp\\ipykernel_7584\\3731441436.py:12: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block4_values] [items->Index(['SpellSerial', 'PatientType', 'IntendedManagement',\n",
      "       'AdmissionMethodDescription', 'AdmissionSpecialty', 'LastSpecialty',\n",
      "       'AdmitWard', 'NextWard2', 'NextWard3', 'NextWard4', 'NextWard5',\n",
      "       'NextWard6', 'NextWard7', 'NextWard8', 'NextWard9', 'DischargeWard',\n",
      "       'LOSBand', 'Gender', 'AgeBand', 'AESerial', 'AandEPresentingComplaint',\n",
      "       'AandEMainDiagnosis', 'AandELocation', 'AandEPatientGroupDescription',\n",
      "       'MainICD10', 'MainDiagnosis', 'SecDiag1', 'SecDiag2', 'SecDiag3',\n",
      "       'SecDiag4', 'SecDiag5', 'SecDiag6', 'MainOPCS4', 'MainProcedure',\n",
      "       'SecOper1', 'SecOper2', 'SecOper3', 'SecOper4', 'SecOper5', 'SecOper6',\n",
      "       'PrimarySpecialtyLocalCode', 'SpellHRG', 'HRGDesc',\n",
      "       'DischargeDestinationDescription', 'AllCFS', 'PatientNoSeq', 'AllCFS.1',\n",
      "       'AllDatesofCFSReadings', 'NoofminsbetweenAllCFS&Admission',\n",
      "       'CFSReadingsBefore(B)After(A)Addmission', 'WordingBeforeAdmission',\n",
      "       'WordingAfterAdmission', 'c_O2_device_or_air', 'c_Patient_Position',\n",
      "       'c_Level_of_consciousness', 'c_Pain', 'c_Nausea',\n",
      "       'c_Vomiting_since_last_round'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(outfile, key=\"table\")\n"
     ]
    }
   ],
   "source": [
    "if Notebook.RUN_ALL or True:\n",
    "    infile = Notebook.RAW_DIR / \"Copy of SCI11868 Delivered 7 Ian Browne.xlsx\"\n",
    "    outfile = Notebook.DATA_DIR / \"sci.h5\"\n",
    "\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile)\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    df = process_SCI(xlsx)\n",
    "\n",
    "    logging.info(f\"Writing to: {outfile}/table\")\n",
    "    df.to_hdf(outfile, key=\"table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_datetime(df, old, new):\n",
    "    df[new] = pd.to_datetime(\n",
    "        df[old]\n",
    "        .dropna(how=\"any\")\n",
    "        .astype(str)\n",
    "        .replace(\"\\.0\", \"\", regex=True)\n",
    "        .apply(\" \".join, 1),\n",
    "        format=\"%Y %m %W %A %H\",\n",
    "    )\n",
    "\n",
    "\n",
    "def process_AD(xlsx):\n",
    "    df = xlsx.copy()\n",
    "\n",
    "    # Construct DateTime from the individual columns describing admission/discharge date\n",
    "    adm_dt, disch_dt = (\n",
    "        [\"YearAdmit\", \"MonthAdmit\", \"AdmitWeek\", \"AdmitDay\", \"AdmitHour\"],\n",
    "        [\"YearDisch\", \"MonthDisch\", \"DischWeek\", \"DischDay\", \"DischHour\"],\n",
    "    )\n",
    "    reconstruct_datetime(df, adm_dt, \"AdmissionDateTime\")\n",
    "    if \"SpellDischargeDate\" in df.columns:\n",
    "        df = df.rename(columns={\"SpellDischargeDate\": \"DischargeDateTime\"})\n",
    "    else:\n",
    "        reconstruct_datetime(df, disch_dt, \"DischargeDateTime\")\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"AdmissionType\": \"Elective\",\n",
    "        \"AdmissionArea\": \"Medical Assessment Area\",\n",
    "        \"DischargeArea\": \"Assessment Area Discharge\",\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over7Days\",\n",
    "                \"Over14Days\",\n",
    "                \"CareHome\",\n",
    "                \"DiedDuringStay\",\n",
    "                \"DiedWithin30Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__).apply(lambda x: np.nan if x == NotImplemented else x)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"AdmissionType\": \"ElectiveAdmission\",\n",
    "            \"AdmissionArea\": \"AssessmentAreaAdmission\",\n",
    "            \"DischargeArea\": \"AssessmentAreaDischarge\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Drop individual date component columns and some extraneous ones\n",
    "    df = df.drop(\n",
    "        adm_dt\n",
    "        + disch_dt\n",
    "        + [\n",
    "            \"DischargeFYear\",\n",
    "            \"AdmissionFYear\",\n",
    "            \"AdmissionFYMonth\",\n",
    "            \"AdmissionConsultant\",\n",
    "            \"LastConsultant\",\n",
    "            \"Area\",\n",
    "            \"PCT\",\n",
    "            \"GPPractice\",\n",
    "            \"AdmissionWardEndDate\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    # Drop duplicates based on serial code\n",
    "    df = df.drop_duplicates(\"SpellSerial\")\n",
    "\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 09:13:38,608 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2014-15DONE.xlsx\n",
      "2022-07-20 09:16:25,233 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2014-15DONE.xlsx\n",
      "2022-07-20 09:16:32,573 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2015-16DONE.xlsx\n",
      "2022-07-20 09:19:27,155 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2015-16DONE.xlsx\n",
      "2022-07-20 09:19:31,283 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2016-17DONE.xlsx\n",
      "2022-07-20 09:23:30,736 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2016-17DONE.xlsx\n",
      "2022-07-20 09:23:38,861 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2017-18DONE.xlsx\n",
      "2022-07-20 09:26:36,617 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2017-18DONE.xlsx\n",
      "2022-07-20 09:26:42,001 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2018-19DONE.xlsx\n",
      "2022-07-20 09:30:03,442 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2018-19DONE.xlsx\n",
      "2022-07-20 09:30:07,654 [INFO] Reading file: data\\AEdata\\AD\\Admission Data FY2019-21DONE.xlsx\n",
      "2022-07-20 09:34:19,413 [INFO] Processing file: data\\AEdata\\AD\\Admission Data FY2019-21DONE.xlsx\n",
      "2022-07-20 09:34:30,029 [INFO] Reading file: data\\AEdata\\AD\\Admissions FY2013-14DONE.xlsx\n",
      "2022-07-20 09:36:21,498 [INFO] Processing file: data\\AEdata\\AD\\Admissions FY2013-14DONE.xlsx\n",
      "2022-07-20 09:36:26,376 [INFO] Reading file: data\\AEdata\\AD\\~$Admission Data FY2014-15DONE.xlsx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\AEdata\\\\AD\\\\~$Admission Data FY2014-15DONE.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m infile \u001b[39min\u001b[39;00m (Notebook\u001b[39m.\u001b[39mRAW_DIR \u001b[39m/\u001b[39m indir)\u001b[39m.\u001b[39miterdir():\n\u001b[1;32m---> 21\u001b[0m         results\u001b[39m.\u001b[39mappend(process_AD_single(infile))\n\u001b[0;32m     23\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWriting all to \u001b[39m\u001b[39m{\u001b[39;00moutfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m r \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(results)\n",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36mprocess_AD_single\u001b[1;34m(infile)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_AD_single\u001b[39m(infile):\n\u001b[0;32m      2\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReading file: \u001b[39m\u001b[39m{\u001b[39;00minfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     xlsx \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(infile)\n\u001b[0;32m      5\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing file: \u001b[39m\u001b[39m{\u001b[39;00minfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m process_AD(xlsx)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=454'>455</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=455'>456</a>\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=456'>457</a>\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=457'>458</a>\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=458'>459</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=459'>460</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=460'>461</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=461'>462</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1373'>1374</a>\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1374'>1375</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1375'>1376</a>\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1376'>1377</a>\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1377'>1378</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1378'>1379</a>\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1379'>1380</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1380'>1381</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1381'>1382</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1382'>1383</a>\u001b[0m         )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1246'>1247</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1247'>1248</a>\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1249'>1250</a>\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1250'>1251</a>\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1251'>1252</a>\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1252'>1253</a>\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/excel/_base.py?line=1253'>1254</a>\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=798'>799</a>\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    <a href='file:///c%3A/Users/stybl/miniconda3/envs/py39/lib/site-packages/pandas/io/common.py?line=800'>801</a>\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\AEdata\\\\AD\\\\~$Admission Data FY2014-15DONE.xlsx'"
     ]
    }
   ],
   "source": [
    "def process_AD_single(infile):\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile)\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    return process_AD(xlsx)\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL or True:\n",
    "    indir = \"AD\"\n",
    "    outfile = Notebook.DATA_DIR / \"AD.h5\"\n",
    "    results = []\n",
    "\n",
    "    if Notebook.MULTITHREADING:\n",
    "        with Pool(3) as p:\n",
    "            results = p.map(\n",
    "                process_AD_single, list((Notebook.RAW_DIR / indir).iterdir())\n",
    "            )\n",
    "    else:\n",
    "        for infile in (Notebook.RAW_DIR / indir).iterdir():\n",
    "            results.append(process_AD_single(infile))\n",
    "\n",
    "    logging.info(f\"Writing all to {outfile}\")\n",
    "    r = pd.concat(results)\n",
    "    r.to_hdf(outfile, key=\"table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICD-10 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_icd10(xlsx):\n",
    "    ICD10_3_Codes = (\n",
    "        xlsx[\n",
    "            [\n",
    "                \"Chapter_No\",\n",
    "                \"Chapter_Desc\",\n",
    "                \"Group_Code\",\n",
    "                \"Group_Desc\",\n",
    "                \"ICD10_3_Code\",\n",
    "                \"ICD10_3_Code_Desc\",\n",
    "            ]\n",
    "        ]\n",
    "        .drop_duplicates(\"ICD10_3_Code\")\n",
    "        .set_index(\"ICD10_3_Code\")\n",
    "    )\n",
    "    ICD10_Codes = xlsx[[\"ICD10_Code\", \"ICD10_3_Code\", \"WHO_Full_Desc\"]].set_index(\n",
    "        \"ICD10_Code\"\n",
    "    )\n",
    "\n",
    "    return ICD10_3_Codes, ICD10_Codes\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    infile = Notebook.DATA_DIR / \"ICD10/ICD-10_MIT_2021_Excel_16-March_2021.xlsx\"\n",
    "    outfile = Notebook.DATA_DIR / \"icd10.h5\"\n",
    "\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile, sheet_name=\"SA ICD-10 MIT 2021\")\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    tc, c = process_icd10(xlsx)\n",
    "\n",
    "    logging.info(f\"Writing to: {outfile}\")\n",
    "    with pd.HDFStore(outfile) as store:\n",
    "        store[\"ICD10_3_Codes\"], store[\"ICD10_Codes\"] = tc, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 08:44:53,357 [INFO] Reading file: data\\ICD10\\Birkmeyer.csv\n",
      "2022-07-19 08:44:53,367 [INFO] Processing file: data\\ICD10\\Birkmeyer.csv\n",
      "2022-07-19 08:44:53,367 [INFO] Writing to: data\\birkmeyer_icd10.h5\n"
     ]
    }
   ],
   "source": [
    "if Notebook.RUN_ALL:\n",
    "    infile = Notebook.DATA_DIR / \"ICD10/Birkmeyer.csv\"\n",
    "    outfile = Notebook.DATA_DIR / \"birkmeyer_icd10.h5\"\n",
    "    logging.info(f'Reading file: {infile}')\n",
    "    df = pd.read_csv(infile)\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    #df = process_birkmeyer(df)\n",
    "\n",
    "    logging.info(f\"Writing to: {outfile}\")\n",
    "    df.to_hdf(outfile, 'table')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5731e6c604298f2045ab2a13cfc59f8afa6fcab4ec4a3faad8b85db05f43f72d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
