{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    DATA_DIR = Path('data')\n",
    "    RAW_DIR = Path('data/AEdata')\n",
    "\n",
    "    RUN_ALL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_per_dtype(df):\n",
    "    col_counts = {col:df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in df.dtypes.iteritems():\n",
    "        new_dict[v].append(k)\n",
    "    for k in new_dict.keys():\n",
    "        print(f'{k}: {new_dict[k]}')\n",
    "\n",
    "def col_counts_topn(df, n=10):\n",
    "    col_counts = {col:df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in col_counts.items():\n",
    "        new_dict[v.size].append(k)\n",
    "    for k in sorted(new_dict.keys())[:n]:\n",
    "        print(f'{k}: {new_dict[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Dates File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_correct_strings(df: pd.DataFrame):\n",
    "    string_cols = df.select_dtypes(include='object').columns\n",
    "    df[string_cols] = df[string_cols].applymap(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eddates(df: pd.DataFrame):\n",
    "    # Manual Correction: The first ArrivalDtm column has values in\n",
    "    # excel-style integer format (see https://stackoverflow.com/a/65460255/7662085)\n",
    "    if df.ArrivalDtm.dtype != np.dtype('datetime64[ns]'):\n",
    "        df['ArrivalDtm'] = pd.to_datetime(df.ArrivalDtm, unit='D', origin='1899-12-30')\n",
    "\n",
    "    # Iterate columns pairwise, and stack them vertically into a single DF\n",
    "    return pd.DataFrame(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                df[list(_)].dropna().values \n",
    "                for _ in zip(df.columns[::3], df.columns[1::3])]\n",
    "        ), columns=['AESerial', 'ArrivalDtm']\n",
    "    )\n",
    "\n",
    "def convert_mainfiledates(df: pd.DataFrame):\n",
    "    return hdf5_correct_strings(df)\n",
    "\n",
    "def convert_event_dates(infile = 'Each event dateDONE.xlsx', outfile = 'event_dates.h5'):\n",
    "    result = {}\n",
    "\n",
    "    xlsx = pd.ExcelFile(Notebook.RAW_DIR / infile)\n",
    "    convert_sheets = {\n",
    "        'EDDATES': convert_eddates,\n",
    "        'MainFileDates': convert_mainfiledates\n",
    "    }\n",
    "\n",
    "    for sheet, converter in convert_sheets.items():\n",
    "        result[sheet] = converter(\n",
    "            pd.read_excel(xlsx, sheet, index_col=None)\n",
    "        )\n",
    "\n",
    "    with pd.HDFStore(Notebook.DATA_DIR / outfile) as store:\n",
    "        for name, df in result.items():\n",
    "            store[name] = df\n",
    "\n",
    "    return result.values()\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    convert_event_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCI File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SCI(xlsx):\n",
    "    df = xlsx.copy()\n",
    "\n",
    "    # Drop redundant columns\n",
    "    redundant = ['Admission FY Month', 'Year Admit', 'Month Admit', 'Admit Hour', 'Admit Week', 'Year Disch', 'Month Disch', 'Disch Hour', 'Disch Week', 'Admission Fy Year', 'Admit Day', 'Discharge Fy Year', 'Disch Day'] + \\\n",
    "    ['Admission Consultant', 'Last Consultant', 'Area', 'GP Practice', 'PCT'] + \\\n",
    "    ['Admissions Date', 'Admission Date', 'aLT Client GUID', 'Client GUID']\n",
    "    df = df.drop(redundant, axis=1)\n",
    "\n",
    "    col_counts = {col:df[col].value_counts() for col in df.columns}\n",
    "\n",
    "    # Drop c_ prefixed columns with no values in them\n",
    "    df = df.drop([col for col, count in col_counts.items() if count.size <= 2 and col.startswith('c_')], axis=1)\n",
    "\n",
    "    # Replace NoNSw2d with np.NAN in all applicable columns\n",
    "    df = df.replace({'NoNSw2d': np.NAN, 'NoObW2D': np.NAN, 'Noobw2d': np.NAN})\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"Admission Type\": \"Elective\",\n",
    "        \"Admission Area\": \"Medical Assessment Area\",\n",
    "        \"Discharge Area\": \"Assessment Area Discharge\",\n",
    "        \"c_Nausea\": '1 - Nausea present',\n",
    "        'c_Vomiting': '1 - Vomiting since last round',\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over 7 Days\",\n",
    "                \"Over 14 Days\",\n",
    "                \"Care Home\",\n",
    "                \"Died During Stay\",\n",
    "                \"Died Within 30 Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"Admission Type\": \"ElectiveAdmission\",\n",
    "            \"Admission Area\": \"AssessmentAreaAdmission\",\n",
    "            \"Discharge Area\": \"AssessmentAreaDischarge\",\n",
    "            \"c_Vomiting\": \"c_Vomiting_since_last_round\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert NEWS dates\n",
    "    datetimes = ['News CreatedWhen', 'News TouchedWhen', 'News AuthoredDtm']\n",
    "    df[datetimes] = df[datetimes].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "    # Convert blood results\n",
    "    # Ignore certain non-numeric entries as they make up less than 0.001%\n",
    "    numeric = ['Urea (serum)', 'Sodium (serum)', 'Potassium (serum)', 'Creatinine', 'pO2 (POC) Venous']\n",
    "    df[numeric] = df[numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remove spaces from column names\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "    return hdf5_correct_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RUN_ALL:\n",
    "    infile = Notebook.RAW_DIR / 'Copy of SCI11868 Delivered 7 Ian Browne.xlsx'\n",
    "    outfile = Notebook.DATA_DIR / 'sci.h5'\n",
    "    \n",
    "    logging.info(f'Reading file: {infile}')\n",
    "    xlsx = pd.read_excel(infile)\n",
    "\n",
    "    logging.info(f'Processing file: {infile}')\n",
    "    df = process_SCI(xlsx)\n",
    "\n",
    "    logging.info(f'Writing to: {outfile}/table')\n",
    "    df.to_hdf(outfile, key='table')\n",
    "\n",
    "    columns_per_dtype(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_datetime(df, old, new):\n",
    "    df[new] = pd.to_datetime(\n",
    "        df[old]\n",
    "        .dropna(how=\"any\")\n",
    "        .astype(str)\n",
    "        .replace(\"\\.0\", \"\", regex=True)\n",
    "        .apply(\" \".join, 1),\n",
    "        format=\"%Y %m %A %H\",\n",
    "    )\n",
    "\n",
    "def process_AD(xlsx):\n",
    "    df = xlsx.copy()\n",
    "    \n",
    "    # Construct DateTime from the individual columns describing admission/discharge date\n",
    "    adm_dt, disch_dt = (\n",
    "        [\"YearAdmit\", \"MonthAdmit\", \"AdmitDay\", \"AdmitHour\"],\n",
    "        [\"YearDisch\", \"MonthDisch\", \"DischDay\", \"DischHour\"],\n",
    "    )\n",
    "    reconstruct_datetime(df, adm_dt, \"AdmissionDateTime\")\n",
    "    if 'SpellDischargeDate' in df.columns:\n",
    "        df = df.rename(columns={'SpellDischargeDate': 'DischargeDateTime'})\n",
    "    else:\n",
    "        reconstruct_datetime(df, disch_dt, \"DischargeDateTime\")\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"AdmissionType\": \"Elective\",\n",
    "        \"AdmissionArea\": \"Medical Assessment Area\",\n",
    "        \"DischargeArea\": \"Assessment Area Discharge\",\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over7Days\",\n",
    "                \"Over14Days\",\n",
    "                \"CareHome\",\n",
    "                \"DiedDuringStay\",\n",
    "                \"DiedWithin30Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"AdmissionType\": \"ElectiveAdmission\",\n",
    "            \"AdmissionArea\": \"AssessmentAreaAdmission\",\n",
    "            \"DischargeArea\": \"AssessmentAreaDischarge\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Drop individual date component columns and some extraneous ones\n",
    "    df = df.drop(\n",
    "        adm_dt\n",
    "        + disch_dt\n",
    "        + [\n",
    "            \"DischWeek\",\n",
    "            \"DischargeFYear\",\n",
    "            \"AdmitWeek\",\n",
    "            \"AdmissionFYear\",\n",
    "            \"AdmissionFYMonth\",\n",
    "            \"AdmissionConsultant\",\n",
    "            \"LastConsultant\",\n",
    "            \"Area\",\n",
    "            \"PCT\",\n",
    "            \"GPPractice\",\n",
    "            \"AdmissionWardEndDate\"\n",
    "        ],\n",
    "        axis=1,\n",
    "        errors='ignore'\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RUN_ALL:\n",
    "    outfile = Notebook.DATA_DIR / 'AD.h5'\n",
    "    results = []\n",
    "\n",
    "    for infile in (Notebook.RAW_DIR / indir).iterdir():\n",
    "        logging.info(f'Reading file: {infile}')\n",
    "        xlsx = pd.read_excel(infile)\n",
    "\n",
    "        logging.info(f'Processing file: {infile}')\n",
    "        results.append(process_AD(xlsx))\n",
    "    \n",
    "    logging.info(f'Writing all to {outfile}')\n",
    "    r = hdf5_correct_strings(pd.concat(results))\n",
    "    r.to_hdf(outfile, key='table')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5731e6c604298f2045ab2a13cfc59f8afa6fcab4ec4a3faad8b85db05f43f72d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
