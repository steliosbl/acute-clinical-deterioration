{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Preprocessing\n",
    "\n",
    "Cleans up and exports the original ACP dataset files into HDF5-compressed Pandas DataFrames.\n",
    "\n",
    "AEData:\n",
    " - Raw data must be unzipped into a directory.\n",
    " - Default path for the raw data is `data/AEdata`. This can be modified from the `Notebook` class.\n",
    "\n",
    "ICD10: \n",
    " - Original spreadsheet for ICD-10 (March 2021) can be found [here](https://www.health.gov.za/icd-10-master-industry-table/).\n",
    " - This should be placed in the `data/ICD10` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    RAW_DIR = Path(\"data/AEdata\")\n",
    "\n",
    "    RUN_ALL = False\n",
    "\n",
    "    # Enable ONLY if running as a script\n",
    "    MULTITHREADING = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_per_dtype(df):\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in df.dtypes.iteritems():\n",
    "        new_dict[v].append(k)\n",
    "    for k in new_dict.keys():\n",
    "        print(f\"{k}: {new_dict[k]}\")\n",
    "\n",
    "\n",
    "def col_counts_topn(df, n=10):\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in col_counts.items():\n",
    "        new_dict[v.size].append(k)\n",
    "    for k in sorted(new_dict.keys())[:n]:\n",
    "        print(f\"{k}: {new_dict[k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Dates File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_correct_strings(df: pd.DataFrame):\n",
    "    string_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[string_cols] = df[string_cols].applymap(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eddates(df: pd.DataFrame):\n",
    "    # Manual Correction: The first ArrivalDtm column has values in\n",
    "    # excel-style integer format (see https://stackoverflow.com/a/65460255/7662085)\n",
    "    if df.ArrivalDtm.dtype != np.dtype(\"datetime64[ns]\"):\n",
    "        df[\"ArrivalDtm\"] = pd.to_datetime(df.ArrivalDtm, unit=\"D\", origin=\"1899-12-30\")\n",
    "\n",
    "    # Iterate columns pairwise, and stack them vertically into a single DF\n",
    "    return pd.DataFrame(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                df[list(_)].dropna().values\n",
    "                for _ in zip(df.columns[::3], df.columns[1::3])\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"AESerial\", \"ArrivalDtm\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_mainfiledates(df: pd.DataFrame):\n",
    "    return hdf5_correct_strings(df)\n",
    "\n",
    "\n",
    "def convert_event_dates(infile=\"Each event dateDONE.xlsx\", outfile=\"event_dates.h5\"):\n",
    "    result = {}\n",
    "\n",
    "    xlsx = pd.ExcelFile(Notebook.RAW_DIR / infile)\n",
    "    convert_sheets = {\n",
    "        \"EDDATES\": convert_eddates,\n",
    "        \"MainFileDates\": convert_mainfiledates,\n",
    "    }\n",
    "\n",
    "    for sheet, converter in convert_sheets.items():\n",
    "        result[sheet] = converter(pd.read_excel(xlsx, sheet, index_col=None))\n",
    "\n",
    "    with pd.HDFStore(Notebook.DATA_DIR / outfile) as store:\n",
    "        for name, df in result.items():\n",
    "            store[name] = df\n",
    "\n",
    "    return result.values()\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    convert_event_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCI File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SCI(xlsx):\n",
    "    df = xlsx.copy()\n",
    "\n",
    "    # Drop redundant columns\n",
    "    redundant = (\n",
    "        [\n",
    "            \"Admission FY Month\",\n",
    "            \"Year Admit\",\n",
    "            \"Month Admit\",\n",
    "            \"Admit Hour\",\n",
    "            \"Admit Week\",\n",
    "            \"Year Disch\",\n",
    "            \"Month Disch\",\n",
    "            \"Disch Hour\",\n",
    "            \"Disch Week\",\n",
    "            \"Admission Fy Year\",\n",
    "            \"Admit Day\",\n",
    "            \"Discharge Fy Year\",\n",
    "            \"Disch Day\",\n",
    "        ]\n",
    "        + [\"Admission Consultant\", \"Last Consultant\", \"Area\", \"GP Practice\", \"PCT\"]\n",
    "        + [\"Admissions Date\", \"Admission Date\", \"aLT Client GUID\", \"Client GUID\"]\n",
    "    )\n",
    "    df = df.drop(redundant, axis=1)\n",
    "\n",
    "    col_counts = {col: df[col].value_counts() for col in df.columns}\n",
    "\n",
    "    # Drop c_ prefixed columns with no values in them\n",
    "    df = df.drop(\n",
    "        [\n",
    "            col\n",
    "            for col, count in col_counts.items()\n",
    "            if count.size <= 2 and col.startswith(\"c_\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Replace NoNSw2d with np.NAN in all applicable columns\n",
    "    df = df.replace({\"NoNSw2d\": np.NAN, \"NoObW2D\": np.NAN, \"Noobw2d\": np.NAN})\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"Admission Type\": \"Elective\",\n",
    "        \"Admission Area\": \"Medical Assessment Area\",\n",
    "        \"Discharge Area\": \"Assessment Area Discharge\",\n",
    "        \"c_Nausea\": \"1 - Nausea present\",\n",
    "        \"c_Vomiting\": \"1 - Vomiting since last round\",\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over 7 Days\",\n",
    "                \"Over 14 Days\",\n",
    "                \"Care Home\",\n",
    "                \"Died During Stay\",\n",
    "                \"Died Within 30 Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__).replace(\"NotImplemented\", np.nan)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"Admission Type\": \"ElectiveAdmission\",\n",
    "            \"Admission Area\": \"AssessmentAreaAdmission\",\n",
    "            \"Discharge Area\": \"AssessmentAreaDischarge\",\n",
    "            \"c_Vomiting\": \"c_Vomiting_since_last_round\",\n",
    "            \"Spell Discharge Date\": \"DischargeDateTime\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert NEWS dates\n",
    "    datetimes = [\"News CreatedWhen\", \"News TouchedWhen\", \"News AuthoredDtm\"]\n",
    "    df[datetimes] = df[datetimes].apply(pd.to_datetime, errors=\"coerce\")\n",
    "\n",
    "    # Convert blood results\n",
    "    # Ignore certain non-numeric entries as they make up less than 0.001%\n",
    "    numeric = [\n",
    "        \"Urea (serum)\",\n",
    "        \"Sodium (serum)\",\n",
    "        \"Potassium (serum)\",\n",
    "        \"Creatinine\",\n",
    "        \"pO2 (POC) Venous\",\n",
    "    ]\n",
    "    df[numeric] = df[numeric].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Remove spaces from column names\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "\n",
    "    # Drop duplicates based on serial code\n",
    "    df = df.drop_duplicates(\"SpellSerial\")\n",
    "\n",
    "    df = df.replace('nan', np.nan)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.RUN_ALL:\n",
    "    infile = Notebook.RAW_DIR / \"Copy of SCI11868 Delivered 7 Ian Browne.xlsx\"\n",
    "    outfile = Notebook.DATA_DIR / \"sci.h5\"\n",
    "\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile)\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    df = process_SCI(xlsx)\n",
    "\n",
    "    logging.info(f\"Writing to: {outfile}/table\")\n",
    "    df.to_hdf(outfile, key=\"table\")\n",
    "\n",
    "    columns_per_dtype(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_datetime(df, old, new):\n",
    "    df[new] = pd.to_datetime(\n",
    "        df[old]\n",
    "        .dropna(how=\"any\")\n",
    "        .astype(str)\n",
    "        .replace(\"\\.0\", \"\", regex=True)\n",
    "        .apply(\" \".join, 1),\n",
    "        format=\"%Y %m %A %H\",\n",
    "    )\n",
    "\n",
    "\n",
    "def process_AD(xlsx):\n",
    "    df = xlsx.copy()\n",
    "\n",
    "    # Construct DateTime from the individual columns describing admission/discharge date\n",
    "    adm_dt, disch_dt = (\n",
    "        [\"YearAdmit\", \"MonthAdmit\", \"AdmitDay\", \"AdmitHour\"],\n",
    "        [\"YearDisch\", \"MonthDisch\", \"DischDay\", \"DischHour\"],\n",
    "    )\n",
    "    reconstruct_datetime(df, adm_dt, \"AdmissionDateTime\")\n",
    "    if \"SpellDischargeDate\" in df.columns:\n",
    "        df = df.rename(columns={\"SpellDischargeDate\": \"DischargeDateTime\"})\n",
    "    else:\n",
    "        reconstruct_datetime(df, disch_dt, \"DischargeDateTime\")\n",
    "\n",
    "    # Turn these 2-value string columns into binary\n",
    "    binarise = {\n",
    "        \"AdmissionType\": \"Elective\",\n",
    "        \"AdmissionArea\": \"Medical Assessment Area\",\n",
    "        \"DischargeArea\": \"Assessment Area Discharge\",\n",
    "        **{\n",
    "            _: \"Yes\"\n",
    "            for _ in [\n",
    "                \"Over7Days\",\n",
    "                \"Over14Days\",\n",
    "                \"CareHome\",\n",
    "                \"DiedDuringStay\",\n",
    "                \"DiedWithin30Days\",\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for col, true in binarise.items():\n",
    "        df[col] = df[col].apply(true.__eq__)\n",
    "\n",
    "    # Rename some of the binarised columns for better clarity\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"AdmissionType\": \"ElectiveAdmission\",\n",
    "            \"AdmissionArea\": \"AssessmentAreaAdmission\",\n",
    "            \"DischargeArea\": \"AssessmentAreaDischarge\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Drop individual date component columns and some extraneous ones\n",
    "    df = df.drop(\n",
    "        adm_dt\n",
    "        + disch_dt\n",
    "        + [\n",
    "            \"DischWeek\",\n",
    "            \"DischargeFYear\",\n",
    "            \"AdmitWeek\",\n",
    "            \"AdmissionFYear\",\n",
    "            \"AdmissionFYMonth\",\n",
    "            \"AdmissionConsultant\",\n",
    "            \"LastConsultant\",\n",
    "            \"Area\",\n",
    "            \"PCT\",\n",
    "            \"GPPractice\",\n",
    "            \"AdmissionWardEndDate\",\n",
    "        ],\n",
    "        axis=1,\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    # Drop duplicates based on serial code\n",
    "    df = df.drop_duplicates(\"SpellSerial\")\n",
    "\n",
    "    df = df.replace('nan', np.nan)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_AD_single(infile):\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile)\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    return process_AD(xlsx)\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    indir = \"AD\"\n",
    "    outfile = Notebook.DATA_DIR / \"AD.h5\"\n",
    "    results = []\n",
    "\n",
    "    if Notebook.MULTITHREADING:\n",
    "        with Pool(3) as p:\n",
    "            results = p.map(\n",
    "                process_AD_single, list((Notebook.RAW_DIR / indir).iterdir())\n",
    "            )\n",
    "    else:\n",
    "        for infile in (Notebook.RAW_DIR / indir).iterdir():\n",
    "            results.append(process_AD_single(infile))\n",
    "\n",
    "    logging.info(f\"Writing all to {outfile}\")\n",
    "    r = pd.concat(results)\n",
    "    r.to_hdf(outfile, key=\"table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICD-10 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_icd10(xlsx):\n",
    "    ICD10_3_Codes = (\n",
    "        xlsx[\n",
    "            [\n",
    "                \"Chapter_No\",\n",
    "                \"Chapter_Desc\",\n",
    "                \"Group_Code\",\n",
    "                \"Group_Desc\",\n",
    "                \"ICD10_3_Code\",\n",
    "                \"ICD10_3_Code_Desc\",\n",
    "            ]\n",
    "        ]\n",
    "        .drop_duplicates(\"ICD10_3_Code\")\n",
    "        .set_index(\"ICD10_3_Code\")\n",
    "    )\n",
    "    ICD10_Codes = xlsx[[\"ICD10_Code\", \"ICD10_3_Code\", \"WHO_Full_Desc\"]].set_index(\n",
    "        \"ICD10_Code\"\n",
    "    )\n",
    "\n",
    "    return ICD10_3_Codes, ICD10_Codes\n",
    "\n",
    "\n",
    "if Notebook.RUN_ALL:\n",
    "    infile = Notebook.DATA_DIR / \"ICD10/ICD-10_MIT_2021_Excel_16-March_2021.xlsx\"\n",
    "    outfile = Notebook.DATA_DIR / \"icd10.h5\"\n",
    "\n",
    "    logging.info(f\"Reading file: {infile}\")\n",
    "    xlsx = pd.read_excel(infile, sheet_name=\"SA ICD-10 MIT 2021\")\n",
    "\n",
    "    logging.info(f\"Processing file: {infile}\")\n",
    "    tc, c = process_icd10(xlsx)\n",
    "\n",
    "    logging.info(f\"Writing to: {outfile}\")\n",
    "    with pd.HDFStore(outfile) as store:\n",
    "        store[\"ICD10_3_Codes\"], store[\"ICD10_Codes\"] = tc, c\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5731e6c604298f2045ab2a13cfc59f8afa6fcab4ec4a3faad8b85db05f43f72d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
