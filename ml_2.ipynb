{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP Project - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, pickle, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "import shap\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import f2_score, METRICS, evaluate, evaluate_from_pred, with_sampling_strategies, spotCheckCV, spotCheckDatasets, F2TabNet, joint_plot\n",
    "from utils.isolation_forest_wrapper import IsolationForestWrapper\n",
    "%aimport utils.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notebook:\n",
    "    # Remember to create these directories!\n",
    "    IMAGE_DIR = \"images/critical_event_48\"\n",
    "    MODEL_DIR = \"models/critical_event_48\"\n",
    "    OUTCOME_PRESET = \"CriticalEvent48\"\n",
    "\n",
    "    SAVE_MODELS = True\n",
    "    SAVE_IMAGES = True\n",
    "    RUN_HYPERPARAMETERS = True\n",
    "    HYPERPARAMETERS_NJOBS = -1\n",
    "    UNDERSAMPLING_STRATEGY = 0.1\n",
    "    SHAP_PLOTS_MAXDISPLAY = 20\n",
    "\n",
    "    MODELS = {}\n",
    "    EXPLAINERS = {}\n",
    "    EVAL_RESULTS = {}\n",
    "    TUNED_RESULTS = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(Notebook.IMAGE_DIR)\n",
    "    os.makedirs(Notebook.MODEL_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore():\n",
    "    with open(f'{Notebook.MODEL_DIR}/models.bin', 'rb') as file:\n",
    "        Notebook.MODELS = pickle.load(file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/explainers.bin', 'rb') as file:\n",
    "        Notebook.EXPLAINERS = pickle.load(file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/eval_results.bin', 'rb') as file:\n",
    "        Notebook.EVAL_RESULTS = pickle.load(file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/tuned_results.bin', 'rb') as file:\n",
    "        Notebook.TUNED_RESULTS = pickle.load(file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/sets.bin', 'rb') as file:\n",
    "        sci_train_idx, sci_test_idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SCIData, SCICols\n",
    "%aimport dataset\n",
    "\n",
    "outcome_options = {\n",
    "    'CriticalEvent24': (lambda x: x.derive_critical_event(within=1), 'CriticalEvent'),\n",
    "    'CriticalEvent48': (lambda x: x.derive_critical_event(within=2), 'CriticalEvent'),\n",
    "    'CriticalEventAny': (lambda x: x.derive_critical_event(within=999), 'CriticalEvent'),\n",
    "    'CriticalCare24': (lambda x: x.derive_critical_care(within=1), 'CriticalCare'),\n",
    "    'CriticalCare48': (lambda x: x.derive_critical_care(within=2), 'CriticalCare'),\n",
    "    'CriticalCareAny': (lambda x: x.derive_critical_care(within=999), 'CriticalCare'),\n",
    "    'Death24': (lambda x: x.derive_death_within(within=1, col_name=\"DiedWithin24h\"), \"DiedWithin24h\"),\n",
    "    'Death48': (lambda x: x.derive_death_within(within=2, col_name=\"DiedWithin48h\"), \"DiedWithin48h\"),\n",
    "    'DeathAny': (lambda x: x, \"DiedDuringStay\"),\n",
    "    'Death30': (lambda x: x, 'DiedWithin30Days'),\n",
    "    'LOS24': (lambda x: x.derive_long_los(over=1), 'LongLOS'),\n",
    "    'LOS48': (lambda x: x.derive_long_los(over=2), 'LongLOS'),\n",
    "    'LOS7': (lambda x: x.derive_long_los(over=7), 'LongLOS'),\n",
    "}\n",
    "\n",
    "sci = SCIData.load('data/sci_processed.h5').fix_readmissionband()\n",
    "sci = outcome_options[Notebook.OUTCOME_PRESET][0](sci)\n",
    "Notebook.OUTCOME = outcome_options[Notebook.OUTCOME_PRESET][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_exclusive_cols(X1, X2):\n",
    "    exclusive_cols = set(X1.columns) ^ set(X2.columns)\n",
    "    X1.drop(exclusive_cols, axis=1, errors=\"ignore\", inplace=True)\n",
    "    X2.drop(exclusive_cols, axis=1, errors=\"ignore\", inplace=True)\n",
    "\n",
    "def ensure_categorical_overlap(X1, X2, cols_to_check):\n",
    "    for col in cols_to_check:\n",
    "        col = X1.columns[col]\n",
    "        X1_uniq, X2_uniq = X1[col].unique(), X2[col].unique()\n",
    "        to_remove = list(set(X1_uniq) ^ set(X2_uniq))\n",
    "        repl = list(set(X1_uniq) & set(X2_uniq))[0]\n",
    "        X1.loc[X1[col].isin(to_remove), col] = repl\n",
    "        X2.loc[X2[col].isin(to_remove), col] = repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scii = (\n",
    "    sci.omit_redundant()\n",
    "    .drop([\"ReadmissionBand\", \"AgeBand\"], axis=1)\n",
    "    .omit_ae()\n",
    "    .raw_news()\n",
    "    .mandate_news()\n",
    "    .mandate_blood()\n",
    "    .augment_hsmr()\n",
    ")\n",
    "\n",
    "sci_train, sci_test = train_test_split(\n",
    "    scii, test_size=0.33, random_state=42, stratify=scii[Notebook.OUTCOME]\n",
    ")\n",
    "sci_train, sci_test = SCIData(sci_train), SCIData(sci_test)\n",
    "\n",
    "# Drop HSMR_15 as there is only 1 in the entire dataset, making a split impossible\n",
    "(X_train, y_train), (X_test, y_test) = (\n",
    "    sci_train.encode_ccs_onehot().xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, dropna=False, fillna=True\n",
    "    ),\n",
    "    sci_test.encode_ccs_onehot().xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, dropna=False, fillna=True\n",
    "    ),\n",
    ")\n",
    "categorical_cols_idx, categorical_cols_dims = X_train.describe_categories()\n",
    "drop_exclusive_cols(X_train, X_test)\n",
    "ensure_categorical_overlap(X_train, X_test, categorical_cols_idx)\n",
    "\n",
    "# Mandated vitals, Categorical diagnoses (main only)\n",
    "(X_train_if, y_train_if), (X_test_if, y_test_if) = (\n",
    "    sci_train.drop(SCICols.diagnoses[1:], axis=1).xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, fillna=True\n",
    "    ),\n",
    "    sci_test.drop(SCICols.diagnoses[1:], axis=1).xy(\n",
    "        outcome=Notebook.OUTCOME, ordinal_encoding=True, fillna=True\n",
    "    ),\n",
    ")\n",
    "drop_exclusive_cols(X_train_if, X_test_if)\n",
    "\n",
    "(X_train_lgbm, y_train_lgbm), (X_test_lgbm, y_test_lgbm) = (\n",
    "    sci_train.encode_ccs_onehot().xy(outcome=Notebook.OUTCOME, fillna=True),\n",
    "    sci_test.encode_ccs_onehot().xy(outcome=Notebook.OUTCOME, fillna=True),\n",
    ")\n",
    "drop_exclusive_cols(X_train_lgbm, X_test_lgbm)\n",
    "ensure_categorical_overlap(X_train_lgbm, X_test_lgbm, categorical_cols_idx)\n",
    "\n",
    "(X_train_tn, X_valid_tn, y_train_tn, y_valid_tn) = train_test_split(\n",
    "    X_train.to_numpy(),\n",
    "    y_train.to_numpy(),\n",
    "    stratify=y_train,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "(X_train_news, y_train_news), (X_test_news, y_test_news) = (\n",
    "    sci_train.xy(\n",
    "        outcome=Notebook.OUTCOME, x=SCICols.news_data_raw, dtype=float, fillna=True\n",
    "    ),\n",
    "    sci_test.xy(\n",
    "        outcome=Notebook.OUTCOME, x=SCICols.news_data_raw, dtype=float, fillna=True\n",
    "    ),\n",
    ")\n",
    "drop_exclusive_cols(X_train_news, X_test_news)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "def get_threshold(y_train, y_pred_proba, target=0.85):\n",
    "    \"\"\" Given prediction probabilities, sets the prediction threshold to approach the given target recall\n",
    "    \"\"\"\n",
    "\n",
    "    # Get candidate thresholds from the model, and find the one that gives the best fbeta score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "    closest = thresholds[np.abs(recall - target).argmin()]\n",
    "\n",
    "    return closest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {\n",
    "    'Logistic Regression (NEWS only)': ('shap_swarm_logistic_regression_news.png', 'shap_bar_logistic_regression_news.png'),\n",
    "    'Logistic Regression': ('shap_swarm_logistic_regression.png', 'shap_bar_logistic_regression.png'),\n",
    "    'Random Forest': ('shap_swarm_random_forest.png', 'shap_bar_random_forest.png'),\n",
    "    'XGBoost': ('shap_swarm_xgboost.png', 'shap_bar_xgboost.png'),\n",
    "    'LightGBM': ('shap_swarm_lightgbm.png', 'shap_bar_lightgbm.png'),\n",
    "    'Isolation Forest': ('shap_swarm_isolation_forest.png', 'shap_bar_isolation_forest.png'),\n",
    "    'TabNet': ('shap_swarm_tabnet.png', 'shap_bar_tabnet.png')\n",
    "}\n",
    "\n",
    "import os\n",
    "for directory in os.listdir('models'):\n",
    "    Notebook.MODEL_DIR = f'models/{directory}'\n",
    "    Notebook.IMAGE_DIR = f'images/{directory}'\n",
    "    with open(f'{Notebook.MODEL_DIR}/explainers.bin', 'rb') as file:\n",
    "        Notebook.EXPLAINERS = pickle.load(file)\n",
    "\n",
    "    for modelkey, (explainer, shap_values) in Notebook.EXPLAINERS.items():\n",
    "        if modelkey != 'TabNet':\n",
    "            fig = shap.plots.beeswarm(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "            plt.title(modelkey)\n",
    "\n",
    "            if Notebook.SAVE_IMAGES:\n",
    "                plt.savefig(\n",
    "                    f\"{Notebook.IMAGE_DIR}/{filenames[modelkey][0]}\", bbox_inches=\"tight\"\n",
    "                )\n",
    "            plt.clf()\n",
    "            fig = shap.plots.bar(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "            plt.title(modelkey)\n",
    "\n",
    "            if Notebook.SAVE_IMAGES:\n",
    "                plt.savefig(\n",
    "                    f\"{Notebook.IMAGE_DIR}/{filenames[modelkey][1]}\", bbox_inches=\"tight\"\n",
    "                )\n",
    "            plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (NEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notebook.EVAL_RESULTS[\"Baseline (NEWS)\"] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred=(sci.loc[sci_test.index].c_NEWS_score >= 7),\n",
    "    y_pred_proba=(sci.loc[sci_test.index].c_NEWS_score),\n",
    "    plot_title=\"NEWS (Threshold = 7)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/baseline_news.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (NEWS only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelkey = \"Logistic Regression (NEWS only)\"\n",
    "model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42).fit(\n",
    "    X_train_news, y_train_news\n",
    ")\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_news,\n",
    "    y_test_news,\n",
    "    plot_title=\"Logistic Regression (NEWS only, non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train_news, model.predict_proba(X_train_news)[:, 1],)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test_news)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_news,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (NEWS only, tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_logistic_news.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, X_train_news, feature_perturbation='correlation_dependent')\n",
    "shap_values = explainer(X_test_news)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Logistic Regression (NEWS only)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_logistic_regression_news.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Logistic Regression (NEWS only)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_logistic_regression_news.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelkey = \"Logistic Regression\"\n",
    "model = LogisticRegression(max_iter=10000, class_weight=\"balanced\").fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    plot_title=\"Logistic Regression (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Logistic Regression (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_logistic_regression.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, X_train, feature_perturbation='correlation_dependent')\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_logistic_regression.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_logistic_regression.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"Random Forest\"\n",
    "model = ImbPipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"undersampling\",\n",
    "            RandomUnderSampler(sampling_strategy=Notebook.UNDERSAMPLING_STRATEGY),\n",
    "        ),\n",
    "        (\"randomforest\", RandomForestClassifier()),\n",
    "    ]\n",
    ").fit(X_train.to_numpy(), y_train)\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test.to_numpy(),\n",
    "    y_test,\n",
    "    plot_title=\"Random Forest (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train.to_numpy())[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred = np.where(y_pred_proba > 1 - threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Random Forest (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_random_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model[\"randomforest\"])\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Random Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_random_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Random Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_random_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"XGB__scale_pos_weight\": np.arange(1, 50, 10),\n",
    "    #  'undersampling__sampling_strategy': np.arange(0.1, 0.5, 0.1)\n",
    "}\n",
    "\n",
    "modelkey = 'XGBoost'\n",
    "model = ImbPipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"undersampling\",\n",
    "            RandomUnderSampler(sampling_strategy=Notebook.UNDERSAMPLING_STRATEGY),\n",
    "        ),\n",
    "        (\n",
    "            \"XGB\",\n",
    "            XGBClassifier(\n",
    "                tree_method=\"hist\",\n",
    "                enable_categorical=True,\n",
    "                subsample=0.85,\n",
    "                scale_pos_weight=31,\n",
    "                n_estimators=140,\n",
    "                max_depth=13,\n",
    "                learning_rate=0.05,\n",
    "                colsample_bytree=0.7,\n",
    "                colsample_bylevel=0.9,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if Notebook.RUN_HYPERPARAMETERS:\n",
    "    fitted = GridSearchCV(model, param_grid, n_jobs=Notebook.HYPERPARAMETERS_NJOBS, scoring='recall').fit(\n",
    "        X_train, y_train\n",
    "    )\n",
    "    model = fitted.best_estimator_\n",
    "    print(fitted.best_params_)\n",
    "else:\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"XGBoost (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_xgboost.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_train, model.predict_proba(X_train)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > 1 - threshold, 1, 0)\n",
    "\n",
    "# Produce scores\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"XGBoost (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_xgboost.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = model[\"XGB\"].feature_importances_.argsort()[::-1]\n",
    "fig = sns.barplot(\n",
    "    x=model[\"XGB\"].feature_importances_[sorted_idx],\n",
    "    y=X_train.columns[sorted_idx],\n",
    "    color=\"deepskyblue\",\n",
    ")\n",
    "fig.set_title(\"XGBoost - Global feature importance (gain)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/global_weights_xgboost.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model[\"XGB\"])\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"XGBoost\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_xgboost.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"XGBoost\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_xgboost.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "modelkey = \"LightGBM\"\n",
    "model = ImbPipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"undersampling\",\n",
    "            RandomUnderSampler(sampling_strategy=Notebook.UNDERSAMPLING_STRATEGY),\n",
    "        ),\n",
    "        (\"lightgbm\", LGBMClassifier(metric=[\"l2\", \"auc\"], is_unbalance=True)),\n",
    "    ]\n",
    ").fit(X_train_lgbm.copy(), y_train_lgbm)\n",
    "\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_lgbm.copy(),\n",
    "    y_test_lgbm,\n",
    "    plot_title=\"LightGBM (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_lightgbm.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(y_test_lgbm, model.predict_proba(X_test_lgbm)[:, 1],)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test_lgbm)[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_lgbm,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"LightGBM (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_lightgbm.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "fig = lgb.plot_importance(model[\"lightgbm\"])\n",
    "fig.set_title(\"LightGBM - Global feature importance (gain)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/global_weights_lightgbm.png\", bbox_inches=\"tight\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model[\"lightgbm\"])\n",
    "shap_values = explainer(X_test)\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"LightGBM\")\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_lightgbm.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values[:, :, 1], max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"LightGBM\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_bar_lightgbm.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelkey = \"Isolation Forest\"\n",
    "\n",
    "model = IsolationForestWrapper().fit(X_train_if[~y_train_if].to_numpy())\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test_if.to_numpy(),\n",
    "    y_test_if,\n",
    "    plot_title=\"Isolation Forest (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = model.decision_function(X_train_if)\n",
    "y_pred_proba_train -= y_pred_proba_train.min()\n",
    "\n",
    "threshold = get_threshold(y_train_if, y_pred_proba_train,)\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.decision_function(X_test_if)\n",
    "y_pred = np.where(y_pred_proba - y_pred_proba.min() > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test_if,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"Isolation Forest (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_isolation_forest.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_test_if)\n",
    "shap_values.values = -shap_values.values  # Fix for isolation forest's unique labelling\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "fig = shap.plots.beeswarm(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Isolation Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_swarm_isolation_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.plots.bar(shap_values, max_display=Notebook.SHAP_PLOTS_MAXDISPLAY, show=False)\n",
    "plt.title(\"Isolation Forest\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/shap_bar_isolation_forest.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "tabnet_params = dict(\n",
    "    n_a=24,\n",
    "    n_d=24,\n",
    "    cat_idxs=categorical_cols_idx,\n",
    "    cat_dims=categorical_cols_dims,\n",
    "    cat_emb_dim=1,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=0.1),\n",
    "    scheduler_params=dict(step_size=50, gamma=0.7),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type=\"entmax\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "modelkey = \"TabNet\"\n",
    "model = TabNetClassifier(**tabnet_params)\n",
    "model.fit(\n",
    "    X_train=X_train_tn,\n",
    "    y_train=y_train_tn,\n",
    "    eval_set=[(X_train_tn, y_train_tn), (X_valid_tn, y_valid_tn),],\n",
    "    eval_name=[\"train\", \"valid\"],\n",
    "    eval_metric=[F2TabNet],\n",
    "    max_epochs=300,\n",
    "    patience=50,\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "Notebook.MODELS[modelkey] = model\n",
    "\n",
    "Notebook.EVAL_RESULTS[modelkey] = evaluate(\n",
    "    model,\n",
    "    X_test.to_numpy(),\n",
    "    y_test,\n",
    "    \"TabNet (non-tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_tabnet.png\" if Notebook.SAVE_IMAGES else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = get_threshold(\n",
    "    y_test, model.predict_proba(X_test.to_numpy())[:, 1], target=0.785\n",
    ")\n",
    "\n",
    "# Create predictions on the test set, using this new threshold\n",
    "y_pred_proba = model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "\n",
    "Notebook.TUNED_RESULTS[modelkey] = evaluate_from_pred(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    plot_title=\"TabNet (tuned)\",\n",
    "    save=f\"{Notebook.IMAGE_DIR}/eval_thresholded_tabnet.png\"\n",
    "    if Notebook.SAVE_IMAGES\n",
    "    else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = model.feature_importances_.argsort()[::-1]\n",
    "fig = sns.barplot(\n",
    "    x=model.feature_importances_[sorted_idx],\n",
    "    y=X_train.columns[sorted_idx],\n",
    "    color=\"deepskyblue\",\n",
    ")\n",
    "fig.set_title(\"TabNet - Global feature importance\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/global_weights_tabnet.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tn_shap = shap.sample(X_test.to_numpy(), 5000)\n",
    "explainer = shap.KernelExplainer(model.predict_proba, shap.sample(X_train_tn, 100))\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    shap_values = explainer.shap_values(X_test_tn_shap, nsamples=50)\n",
    "\n",
    "Notebook.EXPLAINERS[modelkey] = (explainer, shap_values)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values[1],\n",
    "    X_test_tn_shap,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    plot_type='dot'\n",
    ")\n",
    "plt.title(\"TabNet (estimated)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_tabnet.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values[1],\n",
    "    X_test_tn_shap,\n",
    "    feature_names=X_test.columns,\n",
    "    show=False,\n",
    "    max_display=Notebook.SHAP_PLOTS_MAXDISPLAY,\n",
    "    plot_type='bar'\n",
    ")\n",
    "plt.title(\"TabNet (estimated)\")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/shap_swarm_tabnet.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Notebook.SAVE_MODELS:\n",
    "    with open(f'{Notebook.MODEL_DIR}/models.bin', 'wb') as file:\n",
    "        pickle.dump(Notebook.MODELS, file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/explainers.bin', 'wb') as file:\n",
    "        pickle.dump(Notebook.EXPLAINERS, file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/eval_results.bin', 'wb') as file:\n",
    "        pickle.dump(Notebook.EVAL_RESULTS, file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/tuned_results.bin', 'wb') as file:\n",
    "        pickle.dump(Notebook.TUNED_RESULTS, file)\n",
    "\n",
    "    with open(f'{Notebook.MODEL_DIR}/sets.bin', 'wb') as file:\n",
    "        pickle.dump((sci_train.index, sci_test.index), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (pre-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [results[0].assign(Model=key) for key, results in Notebook.EVAL_RESULTS.items()]\n",
    ").set_index(\"Model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores (post-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [results[0].assign(Model=key) for key, results in Notebook.TUNED_RESULTS.items()]\n",
    ").set_index(\"Model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_dict, pr_dict = (\n",
    "    {key: val[1] for key, val in Notebook.EVAL_RESULTS.items()},\n",
    "    {key: val[2] for key, val in Notebook.EVAL_RESULTS.items()},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_plot(\n",
    "    roc_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_roc_curve\" if Notebook.SAVE_IMAGES else None,\n",
    "    ax=None,\n",
    "    title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_plot(\n",
    "    pr_dict,\n",
    "    filename=f\"{Notebook.IMAGE_DIR}/combined_pr_curve\" if Notebook.SAVE_IMAGES else None,\n",
    "    ax=None,\n",
    "    title=\"Precision-Recall\",\n",
    "    legend_location=\"upper right\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict,\n",
    "    ax=ax[1],\n",
    "    title=\"Precision-Recall\",\n",
    "    legend_location=\"upper right\",\n",
    "    plot_baseline=False,\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict,\n",
    "    ax=ax[0],\n",
    "    title=\"Receiver Operating Characteristic (ROC)\",\n",
    "    plot_baseline=False,\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(\n",
    "        f\"{Notebook.IMAGE_DIR}/combined_curves_no_baseline.png\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "joint_plot(\n",
    "    pr_dict, ax=ax[1], title=\"Precision-Recall\", legend_location=\"upper right\",\n",
    ")\n",
    "joint_plot(\n",
    "    roc_dict, ax=ax[0], title=\"Receiver Operating Characteristic (ROC)\",\n",
    ")\n",
    "\n",
    "if Notebook.SAVE_IMAGES:\n",
    "    plt.savefig(f\"{Notebook.IMAGE_DIR}/combined_curves.png\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Explanations (Setup - skip to next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.DataFrame(\n",
    "    {\n",
    "        key: model.predict(\n",
    "            {\n",
    "                \"LightGBM\": X_test_lgbm,\n",
    "                \"Isolation Forest\": X_test_if,\n",
    "                \"TabNet\": X_test.to_numpy(),\n",
    "                \"XGBoost\": X_test,\n",
    "                \"Random Forest\": X_test,\n",
    "                \"Logistic Regression\": X_test,\n",
    "            }[key]\n",
    "        )\n",
    "        for key, model in Notebook.MODELS.items()\n",
    "        if key != \"Logistic Regression (NEWS only)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "candidates = y_preds[y_preds.all(axis=1)].index\n",
    "\n",
    "patient = candidates[0]\n",
    "patient_data = X_test_lgbm.iloc[patient].apply(\n",
    "    lambda x: f\"{x:.2f}\" if type(x) == np.float64 else x\n",
    ")\n",
    "patient_data_if = X_test_if.iloc[patient].copy()\n",
    "patient_data_if.update(X_test_lgbm.iloc[patient])\n",
    "\n",
    "explanations = {\n",
    "    modelkey: shap_values[patient]\n",
    "    for modelkey, (_, shap_values) in Notebook.EXPLAINERS.items()\n",
    "    if not modelkey in [\"TabNet\", \"Logistic Regression (NEWS only)\"]\n",
    "}\n",
    "for _ in explanations.keys():\n",
    "    if len(explanations[_].shape) > 1:\n",
    "        explanations[_] = explanations[_][:, 1]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    tabnet_explainer = Notebook.EXPLAINERS[\"TabNet\"][0]\n",
    "    explanations[\"TabNet\"] = shap.Explanation(\n",
    "        tabnet_explainer.shap_values(X_test.to_numpy()[patient])[1],\n",
    "        data=patient_data.values,\n",
    "        base_values=tabnet_explainer.expected_value[1],\n",
    "        feature_names=patient_data.index,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Force Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.rc(\"axes\", titlesize=16)\n",
    "for modelkey, explanation in explanations.items():\n",
    "    patient_to_use = patient_data if modelkey != \"Isolation Forest\" else patient_data_if\n",
    "\n",
    "    explanation = shap.Explanation(explanation)\n",
    "    explanation.data = patient_to_use.values\n",
    "\n",
    "    fig = shap.plots.force(\n",
    "        explanation,\n",
    "        feature_names=patient_to_use.index,\n",
    "        matplotlib=True,\n",
    "        contribution_threshold=0.08,\n",
    "        show=False,\n",
    "        text_rotation=15\n",
    "    )\n",
    "\n",
    "    plt.title(modelkey)\n",
    "    display(fig)\n",
    "\n",
    "    if Notebook.SAVE_IMAGES:\n",
    "        plt.savefig(\n",
    "            f\"{Notebook.IMAGE_DIR}/comaprison_force_plot_{modelkey.replace(' ','')}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "sns.set_style(\"darkgrid\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e35166262197b1ea9223463adaf11f6b58d81a82b7650a41ad4f3574b9c5682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
